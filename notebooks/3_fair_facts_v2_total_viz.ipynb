{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df759566-c4d8-4e9d-9cde-ac13f197dfb1",
   "metadata": {},
   "source": [
    "fair_facts_v2_viz_total:\n",
    "\n",
    "- This notebook visualizes Totaled outputs from the fair_fact_v2_total.ipynb notebook.\n",
    "- Ensemble means and aggregates of sealevel changes are compared and plotted.\n",
    "- These selected visualizations may be heavy-handed for the current workflow, but are intended to spur ideas for future illustrations also.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae7044-d103-45e3-a70d-756670304de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./data/output/fair:\n",
      "  - climate.nc (151.5 KB)\n",
      "  - oceantemp.nc (61.9 KB)\n",
      "  - gsat.nc (61.3 KB)\n",
      "  - ohc.nc (62.0 KB)\n",
      "\n",
      "./data/output/lws:\n",
      "  - gslr.nc (12.9 KB)\n",
      "  - lslr.nc (13.6 KB)\n",
      "\n",
      "./data/output/sterodynamics:\n",
      "  - gslr.nc (14.9 KB)\n",
      "  - lslr.nc (13.0 KB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def list_output_files():\n",
    "    \"\"\"List all output files from the workflow\"\"\"\n",
    "    output_dirs = [\n",
    "        './data/output/fair',\n",
    "        './data/output/lws',\n",
    "        './data/output/sterodynamics',\n",
    "        # './data/output/emulandice',\n",
    "        # './data/output/glacier'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in output_dirs:\n",
    "        print(f\"\\n{dir_path}:\")\n",
    "        if Path(dir_path).exists():\n",
    "            files = list(Path(dir_path).glob('*.nc'))\n",
    "            if files:\n",
    "                for f in files:\n",
    "                    print(f\"  - {f.name} ({f.stat().st_size / 1024:.1f} KB)\")\n",
    "            else:\n",
    "                print(\"  (no .nc files found)\")\n",
    "        else:\n",
    "            print(\"  (directory doesn't exist)\")\n",
    "\n",
    "list_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a78cc-c425-4a97-a2d4-475a3197cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading output files...\n",
      "  ✓ Loaded climate: climate.nc (group: ssp585)\n",
      "  ✓ Loaded gsat: gsat.nc\n",
      "  ✓ Loaded oceantemp: oceantemp.nc\n",
      "  ✓ Loaded ohc: ohc.nc\n",
      "  ✓ Loaded lws_gslr: gslr.nc\n",
      "  ✓ Loaded lws_lslr: lslr.nc\n",
      "  ✓ Loaded stereo_gslr: gslr.nc\n",
      "  ✓ Loaded stereo_lslr: lslr.nc\n",
      "\n",
      "============================================================\n",
      "DATASET DIAGNOSTICS\n",
      "============================================================\n",
      "\n",
      "climate:\n",
      "  Variables: ['surface_temperature', 'deep_ocean_temperature', 'ocean_heat_content']\n",
      "  Coordinates: ['years', 'samples']\n",
      "  Dimensions: {'years': 751, 'samples': 20}\n",
      "\n",
      "  surface_temperature:\n",
      "    Shape: (751, 20)\n",
      "    Dims: ('years', 'samples')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-0.576, 14.080]\n",
      "    Mean: 4.010\n",
      "\n",
      "  deep_ocean_temperature:\n",
      "    Shape: (751, 20)\n",
      "    Dims: ('years', 'samples')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-0.040, 12.841]\n",
      "    Mean: 2.617\n",
      "\n",
      "  ocean_heat_content:\n",
      "    Shape: (751, 20)\n",
      "    Dims: ('years', 'samples')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-79375934425205737259008.000, 21741853685794159829450752.000]\n",
      "    Mean: 5119441872428280167006208.000\n",
      "\n",
      "gsat:\n",
      "  Variables: ['surface_temperature', 'lat', 'lon']\n",
      "  Coordinates: ['years', 'locations', 'samples']\n",
      "  Dimensions: {'samples': 20, 'years': 751, 'locations': 1}\n",
      "\n",
      "  surface_temperature:\n",
      "    Shape: (20, 751, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-0.576, 14.080]\n",
      "    Mean: 4.010\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "oceantemp:\n",
      "  Variables: ['deep_ocean_temperature', 'lat', 'lon']\n",
      "  Coordinates: ['years', 'locations', 'samples']\n",
      "  Dimensions: {'samples': 20, 'years': 751, 'locations': 1}\n",
      "\n",
      "  deep_ocean_temperature:\n",
      "    Shape: (20, 751, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-0.040, 12.841]\n",
      "    Mean: 2.617\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "ohc:\n",
      "  Variables: ['ocean_heat_content', 'lat', 'lon']\n",
      "  Coordinates: ['years', 'locations', 'samples']\n",
      "  Dimensions: {'samples': 20, 'years': 751, 'locations': 1}\n",
      "\n",
      "  ocean_heat_content:\n",
      "    Shape: (20, 751, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/15020 (0.0%)\n",
      "    Range: [-79375934425205737259008.000, 21741853685794159829450752.000]\n",
      "    Mean: 5119441872428280167006208.000\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "lws_gslr:\n",
      "  Variables: ['lat', 'lon', 'sea_level_change']\n",
      "  Coordinates: ['years', 'samples', 'locations']\n",
      "  Dimensions: {'years': 11, 'samples': 20, 'locations': 1}\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  sea_level_change:\n",
      "    Shape: (20, 11, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/220 (0.0%)\n",
      "    Range: [-2.016, 55.750]\n",
      "    Mean: 14.520\n",
      "\n",
      "lws_lslr:\n",
      "  Variables: ['sea_level_change', 'lat', 'lon']\n",
      "  Coordinates: ['years', 'locations', 'samples']\n",
      "  Dimensions: {'samples': 20, 'years': 11, 'locations': 1}\n",
      "\n",
      "  sea_level_change:\n",
      "    Shape: (20, 11, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/220 (0.0%)\n",
      "    Range: [-2.018, 55.811]\n",
      "    Mean: 14.536\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [40.700, 40.700]\n",
      "    Mean: 40.700\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float64\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [-74.010, -74.010]\n",
      "    Mean: -74.010\n",
      "\n",
      "stereo_gslr:\n",
      "  Variables: ['lat', 'lon', 'sea_level_change']\n",
      "  Coordinates: ['years', 'samples', 'locations']\n",
      "  Dimensions: {'years': 29, 'samples': 20, 'locations': 1}\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [inf, inf]\n",
      "    Mean: inf\n",
      "\n",
      "  sea_level_change:\n",
      "    Shape: (20, 29, 1)\n",
      "    Dims: ('samples', 'years', 'locations')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/580 (0.0%)\n",
      "    Range: [20.267, 1787.672]\n",
      "    Mean: 550.641\n",
      "\n",
      "stereo_lslr:\n",
      "  Variables: ['sea_level_change', 'lat', 'lon']\n",
      "  Coordinates: ['samples', 'years', 'locations']\n",
      "  Dimensions: {'years': 29, 'locations': 1, 'samples': 20}\n",
      "\n",
      "  sea_level_change:\n",
      "    Shape: (29, 1, 20)\n",
      "    Dims: ('years', 'locations', 'samples')\n",
      "    Dtype: float32\n",
      "    NaN values: 0/580 (0.0%)\n",
      "    Range: [-33.523, 2985.854]\n",
      "    Mean: 883.334\n",
      "\n",
      "  lat:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [40.700, 40.700]\n",
      "    Mean: 40.700\n",
      "\n",
      "  lon:\n",
      "    Shape: (1,)\n",
      "    Dims: ('locations',)\n",
      "    Dtype: float32\n",
      "    NaN values: 0/1 (0.0%)\n",
      "    Range: [-74.010, -74.010]\n",
      "    Mean: -74.010\n",
      "\n",
      "============================================================\n",
      "Generating visualizations...\n",
      "============================================================\n",
      "\n",
      "12. Plotting GSLR maps...\n",
      "\n",
      "  Plotting lws GSLR...\n",
      "\n",
      "Analyzing lws_gslr:\n",
      "  Variables: ['lat', 'lon', 'sea_level_change']\n",
      "  Coordinates: ['years', 'samples', 'locations']\n",
      "  Dimensions: {'years': 11, 'samples': 20, 'locations': 1}\n",
      "  Using variable: sea_level_change\n",
      "  Shape: (20, 11, 1)\n",
      "  Dims: ('samples', 'years', 'locations')\n",
      "  ✓ This is Global SLR (uniform value worldwide)\n",
      "\n",
      " Raw mean gslr_value =  33.577369689941406 \n",
      "\n",
      "  GSLR value at 2100: 33.58 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfsm/dnb34/tdirs/batch/slurm.54096826.gtamkin/ipykernel_104639/2968227783.py:32: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"  Dimensions: {dict(ds.dims)}\")\n",
      "/gpfsm/dnb34/tdirs/batch/slurm.54096826.gtamkin/ipykernel_104639/2968227783.py:2151: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"  Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Saved: gslr_map_lws.png\n",
      "\n",
      "  Plotting stereo GSLR...\n",
      "\n",
      "Analyzing stereo_gslr:\n",
      "  Variables: ['lat', 'lon', 'sea_level_change']\n",
      "  Coordinates: ['years', 'samples', 'locations']\n",
      "  Dimensions: {'years': 29, 'samples': 20, 'locations': 1}\n",
      "  Using variable: sea_level_change\n",
      "  Shape: (20, 29, 1)\n",
      "  Dims: ('samples', 'years', 'locations')\n",
      "  ✓ This is Global SLR (uniform value worldwide)\n",
      "\n",
      " Raw mean gslr_value =  286.08575439453125 \n",
      "\n",
      "  GSLR value at 2100: 286.09 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfsm/dnb34/tdirs/batch/slurm.54096826.gtamkin/ipykernel_104639/2968227783.py:2151: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"  Dimensions: {dict(ds.dims)}\")\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# CRITICAL: Disable numbagg BEFORE any xarray operations\n",
    "xr.set_options(use_numbagg=False)\n",
    "\n",
    "# Suppress overflow warnings for large value calculations\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='overflow encountered')\n",
    "\n",
    "class FACTSeaLevelVisualizer:\n",
    "    \"\"\"Visualizer for FACT Sea Level Framework outputs\"\"\"\n",
    "    \n",
    "    def __init__(self, output_base_dir='./data/output'):\n",
    "        self.base_dir = Path(output_base_dir)\n",
    "        self.datasets = {}\n",
    "        self.scenario = 'ssp585'\n",
    "        \n",
    "    def diagnose_datasets(self):\n",
    "        \"\"\"Print detailed information about loaded datasets\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATASET DIAGNOSTICS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for key, ds in self.datasets.items():\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "            print(f\"  Coordinates: {list(ds.coords)}\")\n",
    "            print(f\"  Dimensions: {dict(ds.dims)}\")\n",
    "            \n",
    "            for var in ds.data_vars:\n",
    "                var_data = ds[var]\n",
    "                print(f\"\\n  {var}:\")\n",
    "                print(f\"    Shape: {var_data.shape}\")\n",
    "                print(f\"    Dims: {var_data.dims}\")\n",
    "                print(f\"    Dtype: {var_data.dtype}\")\n",
    "                \n",
    "                # Check for NaN values\n",
    "                if np.issubdtype(var_data.dtype, np.floating):\n",
    "                    values = var_data.values\n",
    "                    n_nan = np.sum(np.isnan(values))\n",
    "                    n_total = values.size\n",
    "                    print(f\"    NaN values: {n_nan}/{n_total} ({100*n_nan/n_total:.1f}%)\")\n",
    "                    \n",
    "                    if n_nan < n_total:\n",
    "                        valid_values = values[~np.isnan(values)]\n",
    "                        print(f\"    Range: [{np.min(valid_values):.3f}, {np.max(valid_values):.3f}]\")\n",
    "                        print(f\"    Mean: {np.mean(valid_values):.3f}\")\n",
    "                    \n",
    "    def load_outputs(self):\n",
    "        \"\"\"Load all available output files\"\"\"\n",
    "        print(\"Loading output files...\")\n",
    "        \n",
    "        output_files = {\n",
    "            'climate': self.base_dir / 'fair/climate.nc',\n",
    "            'gsat': self.base_dir / 'fair/gsat.nc',\n",
    "            'oceantemp': self.base_dir / 'fair/oceantemp.nc',\n",
    "            'ohc': self.base_dir / 'fair/ohc.nc',\n",
    "            'lws_gslr': self.base_dir / 'lws/gslr.nc',\n",
    "            'lws_lslr': self.base_dir / 'lws/lslr.nc',\n",
    "            'stereo_gslr': self.base_dir / 'sterodynamics/gslr.nc',\n",
    "            'stereo_lslr': self.base_dir / 'sterodynamics/lslr.nc',\n",
    "            # 'ice_gslr': self.base_dir / 'emulandice/gslr.nc',\n",
    "            # 'ice_lslr': self.base_dir / 'emulandice/lslr.nc'\n",
    "        }\n",
    "        \n",
    "        for key, filepath in output_files.items():\n",
    "            if filepath.exists():\n",
    "                try:\n",
    "                    if key == 'climate':\n",
    "                        self.datasets[key] = xr.open_dataset(filepath, group=self.scenario)\n",
    "                        print(f\"  ✓ Loaded {key}: {filepath.name} (group: {self.scenario})\")\n",
    "                    else:\n",
    "                        self.datasets[key] = xr.open_dataset(filepath)\n",
    "                        print(f\"  ✓ Loaded {key}: {filepath.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Error loading {key}: {e}\")\n",
    "            else:\n",
    "                print(f\"  - Not found: {filepath}\")\n",
    "        \n",
    "        return self.datasets\n",
    "    \n",
    "    def plot_climate_latest_snapshot(self, scenario='ssp585', figsize=(16, 10)):\n",
    "        \"\"\"Plot climate variables at the latest timestamp\"\"\"\n",
    "        \n",
    "        if 'climate' not in self.datasets:\n",
    "            print(\"Climate data not available\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets['climate']\n",
    "        \n",
    "        years = ds['years'].values\n",
    "        latest_year = years[-1]\n",
    "        latest_idx = -1\n",
    "        \n",
    "        print(f\"\\nPlotting climate snapshot at year {latest_year}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        \n",
    "        samples_dim = 'samples'\n",
    "        \n",
    "        variables = {\n",
    "            'surface_temperature': ('Surface Temperature', '°C', 'Reds'),\n",
    "            'deep_ocean_temperature': ('Deep Ocean Temperature', '°C', 'Blues'),\n",
    "            'ocean_heat_content': ('Ocean Heat Content', 'YJ (10²⁴ J)', 'Greens')\n",
    "        }\n",
    "        \n",
    "        for idx, (var_name, (title, unit, cmap)) in enumerate(variables.items()):\n",
    "            if var_name not in ds.data_vars:\n",
    "                print(f\"⚠ Variable '{var_name}' not found\")\n",
    "                continue\n",
    "            \n",
    "            var_data = ds[var_name]\n",
    "            \n",
    "            # Get data at latest timestamp\n",
    "            data_latest = var_data.isel(years=latest_idx).values\n",
    "            \n",
    "            # Scale ocean heat content\n",
    "            if var_name == 'ocean_heat_content':\n",
    "                data_latest = data_latest / 1e24\n",
    "            \n",
    "            print(f\"\\n{var_name}:\")\n",
    "            print(f\"  Shape at latest time: {data_latest.shape}\")\n",
    "            print(f\"  Range: [{np.min(data_latest):.3f}, {np.max(data_latest):.3f}] {unit}\")\n",
    "            print(f\"  Mean: {np.mean(data_latest):.3f} {unit}\")\n",
    "            print(f\"  Std: {np.std(data_latest):.3f} {unit}\")\n",
    "            \n",
    "            # Top row: Histogram\n",
    "            ax = axes[0, idx]\n",
    "            ax.hist(data_latest, bins=30, alpha=0.7, color=plt.cm.get_cmap(cmap)(0.6), edgecolor='black')\n",
    "            ax.axvline(np.mean(data_latest), color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Mean: {np.mean(data_latest):.2f} {unit}')\n",
    "            ax.axvline(np.median(data_latest), color='darkred', linestyle=':', linewidth=2,\n",
    "                       label=f'Median: {np.median(data_latest):.2f} {unit}')\n",
    "            ax.set_title(f'{title}\\nat {latest_year}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel(f'{title} ({unit})')\n",
    "            ax.set_ylabel('Frequency (Ensemble Members)')\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Bottom row: Box plot with individual points\n",
    "            ax = axes[1, idx]\n",
    "            \n",
    "            # Box plot\n",
    "            bp = ax.boxplot([data_latest], positions=[1], widths=0.6, patch_artist=True,\n",
    "                            showmeans=True, meanline=True,\n",
    "                            boxprops=dict(facecolor=plt.cm.get_cmap(cmap)(0.4), alpha=0.7),\n",
    "                            medianprops=dict(color='darkred', linewidth=2),\n",
    "                            meanprops=dict(color='red', linewidth=2, linestyle='--'),\n",
    "                            whiskerprops=dict(linewidth=1.5),\n",
    "                            capprops=dict(linewidth=1.5))\n",
    "            \n",
    "            # Scatter individual points\n",
    "            y_scatter = data_latest\n",
    "            x_scatter = np.random.normal(1, 0.04, size=len(data_latest))  # Add jitter\n",
    "            ax.scatter(x_scatter, y_scatter, alpha=0.5, s=50, \n",
    "                      c=plt.cm.get_cmap(cmap)(0.8), edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Add statistics text\n",
    "            stats_text = f'n = {len(data_latest)}\\n'\n",
    "            stats_text += f'μ = {np.mean(data_latest):.2f}\\n'\n",
    "            stats_text += f'σ = {np.std(data_latest):.2f}\\n'\n",
    "            stats_text += f'5th = {np.percentile(data_latest, 5):.2f}\\n'\n",
    "            stats_text += f'95th = {np.percentile(data_latest, 95):.2f}'\n",
    "            \n",
    "            ax.text(1.5, np.mean(data_latest), stats_text,\n",
    "                   fontsize=9, verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "            \n",
    "            ax.set_xlim([0.5, 2])\n",
    "            ax.set_xticks([1])\n",
    "            ax.set_xticklabels([f'{latest_year}'])\n",
    "            ax.set_ylabel(f'{title} ({unit})')\n",
    "            ax.set_title(f'{title} - Ensemble Spread', fontsize=12, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.suptitle(f'Climate Variables at Latest Timestamp ({latest_year}) - {scenario.upper()}',\n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_climate_evolution_to_latest(self, scenario='ssp585', figsize=(16, 12)):\n",
    "        \"\"\"Plot evolution of climate variables from start to latest timestamp\"\"\"\n",
    "        \n",
    "        if 'climate' not in self.datasets:\n",
    "            print(\"Climate data not available\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets['climate']\n",
    "        \n",
    "        years = ds['years'].values\n",
    "        latest_year = years[-1]\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 2, figsize=figsize)\n",
    "        \n",
    "        samples_dim = 'samples'\n",
    "        \n",
    "        variables = {\n",
    "            'surface_temperature': ('Surface Temperature', '°C', 'red'),\n",
    "            'deep_ocean_temperature': ('Deep Ocean Temperature', '°C', 'blue'),\n",
    "            'ocean_heat_content': ('Ocean Heat Content', 'YJ (10²⁴ J)', 'green')\n",
    "        }\n",
    "        \n",
    "        for idx, (var_name, (title, unit, color)) in enumerate(variables.items()):\n",
    "            if var_name not in ds.data_vars:\n",
    "                print(f\"⚠ Variable '{var_name}' not found\")\n",
    "                continue\n",
    "            \n",
    "            var_data = ds[var_name]\n",
    "            \n",
    "            # Scale ocean heat content\n",
    "            if var_name == 'ocean_heat_content':\n",
    "                var_data = var_data / 1e24\n",
    "            \n",
    "            # Left column: Time series with all ensemble members highlighted at end\n",
    "            ax = axes[idx, 0]\n",
    "            \n",
    "            # Plot all ensemble members\n",
    "            for i in range(var_data.sizes[samples_dim]):\n",
    "                member_data = var_data.isel(samples=i).values\n",
    "                ax.plot(years, member_data, alpha=0.3, color=color, linewidth=0.5)\n",
    "                \n",
    "                # Highlight endpoint\n",
    "                ax.scatter(years[-1], member_data[-1], s=50, color=color, \n",
    "                          alpha=0.6, edgecolors='black', linewidth=0.5, zorder=5)\n",
    "            \n",
    "            # Plot mean\n",
    "            mean = var_data.mean(dim=samples_dim)\n",
    "            ax.plot(years, mean, color='darkred', linewidth=2.5, label='Ensemble Mean')\n",
    "            ax.scatter(years[-1], mean.values[-1], s=100, color='darkred',\n",
    "                      marker='*', edgecolors='black', linewidth=1, zorder=10,\n",
    "                      label=f'Latest: {mean.values[-1]:.2f} {unit}')\n",
    "            \n",
    "            ax.set_title(f'{title} - Evolution', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel(f'{title} ({unit})')\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.axvline(x=latest_year, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            \n",
    "            # Right column: Latest value distribution with trend indication\n",
    "            ax = axes[idx, 1]\n",
    "            \n",
    "            data_latest = var_data.isel(years=-1).values\n",
    "            data_previous = var_data.isel(years=-2).values if len(years) > 1 else data_latest\n",
    "            \n",
    "            # Violin plot\n",
    "            parts = ax.violinplot([data_latest], positions=[1], widths=0.8,\n",
    "                                  showmeans=True, showmedians=True)\n",
    "            \n",
    "            # Color the violin plot\n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor(color)\n",
    "                pc.set_alpha(0.7)\n",
    "            \n",
    "            # Scatter points with color indicating change from previous\n",
    "            changes = data_latest - data_previous\n",
    "            colors_scatter = ['green' if c > 0 else 'red' if c < 0 else 'gray' for c in changes]\n",
    "            \n",
    "            x_scatter = np.random.normal(1, 0.04, size=len(data_latest))\n",
    "            ax.scatter(x_scatter, data_latest, c=colors_scatter, alpha=0.6, s=60,\n",
    "                      edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Statistics\n",
    "            mean_val = np.mean(data_latest)\n",
    "            std_val = np.std(data_latest)\n",
    "            \n",
    "            ax.axhline(y=mean_val, color='darkred', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            \n",
    "            # Add change indicator\n",
    "            mean_change = np.mean(changes)\n",
    "            change_symbol = '↑' if mean_change > 0 else '↓' if mean_change < 0 else '→'\n",
    "            change_color = 'green' if mean_change > 0 else 'red' if mean_change < 0 else 'gray'\n",
    "            \n",
    "            stats_text = f'{change_symbol} Δ = {mean_change:.3f} {unit}\\n'\n",
    "            stats_text += f'μ = {mean_val:.2f} {unit}\\n'\n",
    "            stats_text += f'σ = {std_val:.2f} {unit}\\n'\n",
    "            stats_text += f'Range: [{np.min(data_latest):.2f}, {np.max(data_latest):.2f}]'\n",
    "            \n",
    "            ax.text(1.5, mean_val, stats_text, fontsize=9, verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor=change_color, alpha=0.3))\n",
    "            \n",
    "            ax.set_xlim([0.5, 2.5])\n",
    "            ax.set_xticks([1])\n",
    "            ax.set_xticklabels([f'{latest_year}'])\n",
    "            ax.set_ylabel(f'{title} ({unit})')\n",
    "            ax.set_title(f'{title} at {latest_year}', fontsize=12, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.suptitle(f'Climate Variables Evolution to Latest ({latest_year}) - {scenario.upper()}',\n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_climate_heatmap_over_time(self, scenario='ssp585', figsize=(16, 10)):\n",
    "        \"\"\"Create heatmap showing ensemble spread over time\"\"\"\n",
    "        \n",
    "        if 'climate' not in self.datasets:\n",
    "            print(\"Climate data not available\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets['climate']\n",
    "        \n",
    "        years = ds['years'].values\n",
    "        samples_dim = 'samples'\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 1, figsize=figsize)\n",
    "        \n",
    "        variables = {\n",
    "            'surface_temperature': ('Surface Temperature', '°C', 'RdYlBu_r'),\n",
    "            'deep_ocean_temperature': ('Deep Ocean Temperature', '°C', 'RdYlBu_r'),\n",
    "            'ocean_heat_content': ('Ocean Heat Content', 'YJ (10²⁴ J)', 'YlOrRd')\n",
    "        }\n",
    "        \n",
    "        for idx, (var_name, (title, unit, cmap)) in enumerate(variables.items()):\n",
    "            if var_name not in ds.data_vars:\n",
    "                continue\n",
    "            \n",
    "            var_data = ds[var_name]\n",
    "            \n",
    "            # Scale ocean heat content\n",
    "            if var_name == 'ocean_heat_content':\n",
    "                var_data = var_data / 1e24\n",
    "            \n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Create 2D array: samples x years\n",
    "            data_2d = var_data.values.T  # Transpose to get (samples, years)\n",
    "            \n",
    "            # Create heatmap\n",
    "            im = ax.imshow(data_2d, aspect='auto', cmap=cmap, interpolation='nearest')\n",
    "            \n",
    "            # Set ticks\n",
    "            n_ticks = min(10, len(years))\n",
    "            tick_indices = np.linspace(0, len(years)-1, n_ticks, dtype=int)\n",
    "            ax.set_xticks(tick_indices)\n",
    "            ax.set_xticklabels([f'{years[i]:.0f}' for i in tick_indices])\n",
    "            \n",
    "            ax.set_yticks(range(data_2d.shape[0]))\n",
    "            ax.set_yticklabels([f'M{i+1}' for i in range(data_2d.shape[0])], fontsize=8)\n",
    "            \n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Ensemble Member')\n",
    "            ax.set_title(f'{title} - Ensemble Heatmap', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # Colorbar\n",
    "            cbar = plt.colorbar(im, ax=ax, orientation='vertical', pad=0.02)\n",
    "            cbar.set_label(unit, rotation=270, labelpad=20)\n",
    "            \n",
    "            # Mark latest year\n",
    "            ax.axvline(x=len(years)-1, color='white', linestyle='--', linewidth=2, alpha=0.8)\n",
    "        \n",
    "        plt.suptitle(f'Climate Variables Ensemble Heatmap - {scenario.upper()}',\n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def rolling_mean_numpy(self, data, window, axis=0):\n",
    "        \"\"\"Manual rolling mean calculation using numpy to avoid numbagg\"\"\"\n",
    "        pad_width = [(0, 0)] * data.ndim\n",
    "        pad_width[axis] = (window // 2, window // 2)\n",
    "        padded = np.pad(data, pad_width, mode='edge')\n",
    "        \n",
    "        cumsum = np.cumsum(padded, axis=axis)\n",
    "        cumsum_shifted = np.roll(cumsum, window, axis=axis)\n",
    "        cumsum_shifted[..., :window] = 0\n",
    "        \n",
    "        result = (cumsum - cumsum_shifted) / window\n",
    "        \n",
    "        slices = [slice(None)] * data.ndim\n",
    "        slices[axis] = slice(window // 2, -(window // 2) if window // 2 > 0 else None)\n",
    "        return result[tuple(slices)]\n",
    "    \n",
    "    def plot_climate_variables(self, scenario='ssp585', figsize=(16, 12)):\n",
    "        \"\"\"Plot FAIR climate model outputs with ensemble uncertainty\"\"\"\n",
    "        if 'climate' not in self.datasets:\n",
    "            print(\"Climate data not available\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets['climate']\n",
    "        fig, axes = plt.subplots(3, 2, figsize=figsize)\n",
    "        \n",
    "        years = ds['years'].values\n",
    "        samples_dim = 'samples'\n",
    "        \n",
    "        # 1. Surface Temperature - Individual trajectories\n",
    "        ax = axes[0, 0]\n",
    "        surf_temp = ds['surface_temperature']\n",
    "        for i in range(surf_temp.sizes[samples_dim]):\n",
    "            ax.plot(years, surf_temp.isel(samples=i), alpha=0.3, color='red', linewidth=0.5)\n",
    "        \n",
    "        mean_temp = surf_temp.mean(dim=samples_dim)\n",
    "        ax.plot(years, mean_temp, color='darkred', linewidth=2.5, label='Ensemble Mean')\n",
    "        ax.set_title('Surface Temperature - Individual Ensemble Members', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Temperature Anomaly (°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Surface Temperature - Percentile bands\n",
    "        ax = axes[0, 1]\n",
    "        mean = surf_temp.mean(dim=samples_dim)\n",
    "        p5 = surf_temp.quantile(0.05, dim=samples_dim)\n",
    "        p95 = surf_temp.quantile(0.95, dim=samples_dim)\n",
    "        p25 = surf_temp.quantile(0.25, dim=samples_dim)\n",
    "        p75 = surf_temp.quantile(0.75, dim=samples_dim)\n",
    "        \n",
    "        ax.fill_between(years, p5, p95, alpha=0.2, color='red', label='5-95th percentile')\n",
    "        ax.fill_between(years, p25, p75, alpha=0.4, color='red', label='25-75th percentile')\n",
    "        ax.plot(years, mean, color='darkred', linewidth=2.5, label='Mean')\n",
    "        ax.set_title('Surface Temperature - Uncertainty Ranges', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Temperature Anomaly (°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Deep Ocean Temperature\n",
    "        ax = axes[1, 0]\n",
    "        deep_temp = ds['deep_ocean_temperature']\n",
    "        mean_deep = deep_temp.mean(dim=samples_dim)\n",
    "        p5_deep = deep_temp.quantile(0.05, dim=samples_dim)\n",
    "        p95_deep = deep_temp.quantile(0.95, dim=samples_dim)\n",
    "        \n",
    "        ax.fill_between(years, p5_deep, p95_deep, alpha=0.3, color='blue')\n",
    "        ax.plot(years, mean_deep, color='darkblue', linewidth=2.5)\n",
    "        ax.set_title('Deep Ocean Temperature', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Temperature Anomaly (°C)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Ocean Heat Content\n",
    "        ax = axes[1, 1]\n",
    "        ohc = ds['ocean_heat_content']\n",
    "        mean_ohc = ohc.mean(dim=samples_dim) / 1e24\n",
    "        p5_ohc = ohc.quantile(0.05, dim=samples_dim) / 1e24\n",
    "        p95_ohc = ohc.quantile(0.95, dim=samples_dim) / 1e24\n",
    "        \n",
    "        ax.fill_between(years, p5_ohc, p95_ohc, alpha=0.3, color='green')\n",
    "        ax.plot(years, mean_ohc, color='darkgreen', linewidth=2.5)\n",
    "        ax.set_title('Ocean Heat Content', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Heat Content (YJ, 10²⁴ J)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Temperature distribution at 2100\n",
    "        ax = axes[2, 0]\n",
    "        year_2100_idx = np.argmin(np.abs(years - 2100))\n",
    "        temp_2100 = surf_temp.isel(years=year_2100_idx).values\n",
    "        \n",
    "        ax.hist(temp_2100, bins=15, alpha=0.7, color='red', edgecolor='black')\n",
    "        ax.axvline(np.mean(temp_2100), color='darkred', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {np.mean(temp_2100):.2f}°C')\n",
    "        ax.axvline(np.median(temp_2100), color='red', linestyle=':', linewidth=2,\n",
    "                   label=f'Median: {np.median(temp_2100):.2f}°C')\n",
    "        ax.set_title(f'Surface Temperature Distribution at 2100', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Temperature Anomaly (°C)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 6. Warming rate - using manual calculation\n",
    "        ax = axes[2, 1]\n",
    "        window = 10\n",
    "        \n",
    "        surf_temp_values = surf_temp.values\n",
    "        temp_diff = np.diff(surf_temp_values, axis=0)\n",
    "        \n",
    "        if temp_diff.shape[0] >= window:\n",
    "            smoothed_diff = self.rolling_mean_numpy(temp_diff, window, axis=0)\n",
    "            warming_rate_values = smoothed_diff * 10\n",
    "            \n",
    "            mean_rate = np.mean(warming_rate_values, axis=1)\n",
    "            p5_rate = np.percentile(warming_rate_values, 5, axis=1)\n",
    "            p95_rate = np.percentile(warming_rate_values, 95, axis=1)\n",
    "            \n",
    "            years_rate = years[1:len(mean_rate)+1]\n",
    "            \n",
    "            ax.fill_between(years_rate, p5_rate, p95_rate, alpha=0.3, color='orange')\n",
    "            ax.plot(years_rate, mean_rate, color='darkorange', linewidth=2.5)\n",
    "            ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "            ax.set_title(f'Decadal Warming Rate ({window}-year smoothed)', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Warming Rate (°C/decade)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'Insufficient data for warming rate', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "        \n",
    "        plt.suptitle(f'FAIR Climate Model Outputs - {scenario.upper()}', \n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_sea_level_components_comparison(self, year=2100, figsize=(16, 10)):\n",
    "        \"\"\"Compare sea level rise contributions from different components\"\"\"\n",
    "        \n",
    "        components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Sheets & Glaciers': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        available = {name: key for name, key in components.items() if key in self.datasets}\n",
    "        \n",
    "        if not available:\n",
    "            print(\"No sea level rise data available\")\n",
    "            return\n",
    "        \n",
    "        n_components = len(available)\n",
    "        fig, axes = plt.subplots(2, n_components + 1, figsize=figsize)\n",
    "        \n",
    "        all_time_series = []\n",
    "        all_time_axes = []\n",
    "        all_distributions = []\n",
    "        colors = ['blue', 'green', 'orange', 'purple']\n",
    "        \n",
    "        for idx, (name, key) in enumerate(available.items()):\n",
    "            ds = self.datasets[key]\n",
    "            \n",
    "            slr_vars = [v for v in ds.data_vars if 'slr' in v.lower() or 'sea' in v.lower()]\n",
    "            if not slr_vars:\n",
    "                print(f\"No SLR variable found in {key}\")\n",
    "                continue\n",
    "            \n",
    "            slr_var = slr_vars[0]\n",
    "            slr_data = ds[slr_var]\n",
    "            \n",
    "            time_dim = 'years' if 'years' in slr_data.dims else 'year' if 'year' in slr_data.dims else 'time'\n",
    "            sample_dim = 'samples' if 'samples' in slr_data.dims else 'sample' if 'sample' in slr_data.dims else 'ensemble'\n",
    "            \n",
    "            if time_dim not in slr_data.dims:\n",
    "                print(f\"Could not find time dimension in {key}\")\n",
    "                continue\n",
    "            \n",
    "            years_data = ds[time_dim].values\n",
    "            \n",
    "            # Time series plot\n",
    "            ax = axes[0, idx]\n",
    "            if sample_dim in slr_data.dims:\n",
    "                mean = slr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                p5 = slr_data.quantile(0.05, dim=sample_dim).values.squeeze()\n",
    "                p95 = slr_data.quantile(0.95, dim=sample_dim).values.squeeze()\n",
    "                \n",
    "                # Ensure 1D\n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "                if p5.ndim > 1:\n",
    "                    p5 = p5.flatten()\n",
    "                if p95.ndim > 1:\n",
    "                    p95 = p95.flatten()\n",
    "                \n",
    "                ax.fill_between(years_data, p5, p95, alpha=0.3, color=colors[idx])\n",
    "                ax.plot(years_data, mean, color=colors[idx], linewidth=2.5)\n",
    "                \n",
    "                all_time_series.append(mean)\n",
    "                all_time_axes.append(years_data)\n",
    "            else:\n",
    "                slr_values = slr_data.values.squeeze()\n",
    "                if slr_values.ndim > 1:\n",
    "                    slr_values = slr_values.flatten()\n",
    "                ax.plot(years_data, slr_values, color=colors[idx], linewidth=2.5)\n",
    "                all_time_series.append(slr_values)\n",
    "                all_time_axes.append(years_data)\n",
    "            \n",
    "            ax.set_title(name, fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('SLR (mm)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Distribution at target year\n",
    "            ax = axes[1, idx]\n",
    "            year_idx = np.argmin(np.abs(years_data - year))\n",
    "            \n",
    "            if sample_dim in slr_data.dims:\n",
    "                data_at_year = slr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                \n",
    "                ax.hist(data_at_year, bins=20, alpha=0.7, color=colors[idx], edgecolor='black')\n",
    "                ax.axvline(np.mean(data_at_year), color='darkred', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {np.mean(data_at_year):.1f} mm')\n",
    "                ax.axvline(np.percentile(data_at_year, 5), color='gray', linestyle=':', linewidth=1.5,\n",
    "                          label=f'5th: {np.percentile(data_at_year, 5):.1f} mm')\n",
    "                ax.axvline(np.percentile(data_at_year, 95), color='gray', linestyle=':', linewidth=1.5,\n",
    "                          label=f'95th: {np.percentile(data_at_year, 95):.1f} mm')\n",
    "                \n",
    "                all_distributions.append(data_at_year)\n",
    "            else:\n",
    "                data_at_year = slr_data.isel({time_dim: year_idx}).values.flatten()[0]\n",
    "                ax.axvline(data_at_year, color=colors[idx], linewidth=3)\n",
    "                all_distributions.append([data_at_year])\n",
    "            \n",
    "            ax.set_title(f'{name} at {year}', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('SLR (mm)')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Plot total - CHECK FOR CONSISTENT TIME AXES\n",
    "        if len(all_time_series) > 1:\n",
    "            # Check if all time axes are the same\n",
    "            time_lengths = [len(t) for t in all_time_axes]\n",
    "            \n",
    "            if len(set(time_lengths)) == 1:\n",
    "                # All same length, can sum directly\n",
    "                ax = axes[0, -1]\n",
    "                years_common = all_time_axes[0]\n",
    "                total_ts = np.sum(all_time_series, axis=0)\n",
    "                ax.plot(years_common, total_ts, color='red', linewidth=3)\n",
    "                ax.fill_between(years_common, 0, total_ts, alpha=0.2, color='red')\n",
    "                ax.set_title('Total SLR', fontsize=11, fontweight='bold')\n",
    "                ax.set_xlabel('Year')\n",
    "                ax.set_ylabel('Total SLR (mm)')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Distribution total\n",
    "                ax = axes[1, -1]\n",
    "                if all(len(d) > 1 for d in all_distributions):\n",
    "                    total_dist = np.sum(all_distributions, axis=0)\n",
    "                    ax.hist(total_dist, bins=25, alpha=0.7, color='red', edgecolor='black')\n",
    "                    ax.axvline(np.mean(total_dist), color='darkred', linestyle='--', linewidth=2,\n",
    "                              label=f'Mean: {np.mean(total_dist):.1f} mm')\n",
    "                    ax.axvline(np.percentile(total_dist, 5), color='gray', linestyle=':', linewidth=1.5,\n",
    "                              label=f'5th: {np.percentile(total_dist, 5):.1f} mm')\n",
    "                    ax.axvline(np.percentile(total_dist, 95), color='gray', linestyle=':', linewidth=1.5,\n",
    "                              label=f'95th: {np.percentile(total_dist, 95):.1f} mm')\n",
    "                    ax.set_title(f'Total SLR at {year}', fontsize=11, fontweight='bold')\n",
    "                    ax.set_xlabel('Total SLR (mm)')\n",
    "                    ax.set_ylabel('Frequency')\n",
    "                    ax.legend(fontsize=8)\n",
    "                    ax.grid(True, alpha=0.3, axis='y')\n",
    "            else:\n",
    "                # Different lengths - need to interpolate to common time axis\n",
    "                print(f\"⚠ Time axes differ: {time_lengths}. Interpolating to common axis.\")\n",
    "                \n",
    "                # Find the common time range\n",
    "                min_year = max([t[0] for t in all_time_axes])\n",
    "                max_year = min([t[-1] for t in all_time_axes])\n",
    "                \n",
    "                # Create common time axis\n",
    "                n_points = min(time_lengths)\n",
    "                years_common = np.linspace(min_year, max_year, n_points)\n",
    "                \n",
    "                # Interpolate all series to common axis\n",
    "                interpolated_series = []\n",
    "                for years_orig, data_orig in zip(all_time_axes, all_time_series):\n",
    "                    data_interp = np.interp(years_common, years_orig, data_orig)\n",
    "                    interpolated_series.append(data_interp)\n",
    "                \n",
    "                # Now sum\n",
    "                ax = axes[0, -1]\n",
    "                total_ts = np.sum(interpolated_series, axis=0)\n",
    "                ax.plot(years_common, total_ts, color='red', linewidth=3)\n",
    "                ax.fill_between(years_common, 0, total_ts, alpha=0.2, color='red')\n",
    "                ax.set_title('Total SLR (interpolated)', fontsize=11, fontweight='bold')\n",
    "                ax.set_xlabel('Year')\n",
    "                ax.set_ylabel('Total SLR (mm)')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Distribution total\n",
    "                ax = axes[1, -1]\n",
    "                if all(len(d) > 1 for d in all_distributions):\n",
    "                    total_dist = np.sum(all_distributions, axis=0)\n",
    "                    ax.hist(total_dist, bins=25, alpha=0.7, color='red', edgecolor='black')\n",
    "                    ax.axvline(np.mean(total_dist), color='darkred', linestyle='--', linewidth=2,\n",
    "                              label=f'Mean: {np.mean(total_dist):.1f} mm')\n",
    "                    ax.axvline(np.percentile(total_dist, 5), color='gray', linestyle=':', linewidth=1.5,\n",
    "                              label=f'5th: {np.percentile(total_dist, 5):.1f} mm')\n",
    "                    ax.axvline(np.percentile(total_dist, 95), color='gray', linestyle=':', linewidth=1.5,\n",
    "                              label=f'95th: {np.percentile(total_dist, 95):.1f} mm')\n",
    "                    ax.set_title(f'Total SLR at {year}', fontsize=11, fontweight='bold')\n",
    "                    ax.set_xlabel('Total SLR (mm)')\n",
    "                    ax.set_ylabel('Frequency')\n",
    "                    ax.legend(fontsize=8)\n",
    "                    ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.suptitle(f'Sea Level Rise Components - {self.scenario.upper()}',\n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_slr_stacked_contributions(self, figsize=(14, 8)):\n",
    "        \"\"\"Create stacked area plot showing relative contributions\"\"\"\n",
    "        \n",
    "        components = {\n",
    "            'Land Water Storage': ('lws_gslr', 'blue'),\n",
    "            'Sterodynamics': ('stereo_gslr', 'green'),\n",
    "            'Ice Sheets & Glaciers': ('ice_gslr', 'orange')\n",
    "        }\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize)\n",
    "        \n",
    "        data_dict = {}\n",
    "        years_list = []\n",
    "        \n",
    "        for name, (key, color) in components.items():\n",
    "            if key not in self.datasets:\n",
    "                continue\n",
    "            \n",
    "            ds = self.datasets[key]\n",
    "            slr_vars = [v for v in ds.data_vars if 'slr' in v.lower()]\n",
    "            if not slr_vars:\n",
    "                continue\n",
    "            \n",
    "            slr_var = slr_vars[0]\n",
    "            slr_data = ds[slr_var]\n",
    "            \n",
    "            time_dim = 'years' if 'years' in slr_data.dims else 'year' if 'year' in slr_data.dims else 'time'\n",
    "            sample_dim = 'samples' if 'samples' in slr_data.dims else 'sample' if 'sample' in slr_data.dims else None\n",
    "            \n",
    "            years_data = ds[time_dim].values\n",
    "            years_list.append(years_data)\n",
    "            \n",
    "            if sample_dim:\n",
    "                mean = slr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "            else:\n",
    "                mean = slr_data.values.squeeze()\n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "            \n",
    "            data_dict[name] = (years_data, mean, color)\n",
    "        \n",
    "        if not data_dict:\n",
    "            print(\"Not enough data for stacked plot\")\n",
    "            return\n",
    "        \n",
    "        # Check if all time axes are the same\n",
    "        time_lengths = [len(y) for y, _, _ in data_dict.values()]\n",
    "        \n",
    "        if len(set(time_lengths)) == 1:\n",
    "            # All same length\n",
    "            years_common = list(data_dict.values())[0][0]\n",
    "            \n",
    "            # Stacked area plot\n",
    "            cumsum = np.zeros_like(years_common, dtype=float)\n",
    "            for name, (_, data, color) in data_dict.items():\n",
    "                ax1.fill_between(years_common, cumsum, cumsum + data, alpha=0.7, color=color, label=name)\n",
    "                cumsum += data\n",
    "            \n",
    "            ax1.plot(years_common, cumsum, 'k-', linewidth=2, label='Total')\n",
    "            ax1.set_title('Stacked Sea Level Rise Contributions', fontsize=13, fontweight='bold')\n",
    "            ax1.set_xlabel('Year')\n",
    "            ax1.set_ylabel('Cumulative SLR (mm)')\n",
    "            ax1.legend(loc='upper left')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Relative contributions\n",
    "            total = cumsum\n",
    "            # Avoid division by zero\n",
    "            total_safe = np.where(total != 0, total, 1)\n",
    "            for name, (_, data, color) in data_dict.items():\n",
    "                percentage = (data / total_safe) * 100\n",
    "                ax2.plot(years_common, percentage, linewidth=2.5, color=color, label=name)\n",
    "            \n",
    "            ax2.set_title('Relative Contributions to Total SLR', fontsize=13, fontweight='bold')\n",
    "            ax2.set_xlabel('Year')\n",
    "            ax2.set_ylabel('Contribution (%)')\n",
    "            ax2.set_ylim([0, 100])\n",
    "            ax2.legend(loc='best')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            # Need to interpolate\n",
    "            print(f\"⚠ Time axes differ: {time_lengths}. Interpolating to common axis.\")\n",
    "            \n",
    "            # Find common time range\n",
    "            min_year = max([y[0] for y, _, _ in data_dict.values()])\n",
    "            max_year = min([y[-1] for y, _, _ in data_dict.values()])\n",
    "            n_points = min(time_lengths)\n",
    "            years_common = np.linspace(min_year, max_year, n_points)\n",
    "            \n",
    "            # Interpolate all series\n",
    "            interpolated_dict = {}\n",
    "            for name, (years_orig, data_orig, color) in data_dict.items():\n",
    "                data_interp = np.interp(years_common, years_orig, data_orig)\n",
    "                interpolated_dict[name] = (data_interp, color)\n",
    "            \n",
    "            # Stacked area plot\n",
    "            cumsum = np.zeros_like(years_common, dtype=float)\n",
    "            for name, (data, color) in interpolated_dict.items():\n",
    "                ax1.fill_between(years_common, cumsum, cumsum + data, alpha=0.7, color=color, label=name)\n",
    "                cumsum += data\n",
    "            \n",
    "            ax1.plot(years_common, cumsum, 'k-', linewidth=2, label='Total')\n",
    "            ax1.set_title('Stacked Sea Level Rise Contributions', fontsize=13, fontweight='bold')\n",
    "            ax1.set_xlabel('Year')\n",
    "            ax1.set_ylabel('Cumulative SLR (mm)')\n",
    "            ax1.legend(loc='upper left')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Relative contributions\n",
    "            total = cumsum\n",
    "            total_safe = np.where(total != 0, total, 1)\n",
    "            for name, (data, color) in interpolated_dict.items():\n",
    "                percentage = (data / total_safe) * 100\n",
    "                ax2.plot(years_common, percentage, linewidth=2.5, color=color, label=name)\n",
    "            \n",
    "            ax2.set_title('Relative Contributions to Total SLR', fontsize=13, fontweight='bold')\n",
    "            ax2.set_xlabel('Year')\n",
    "            ax2.set_ylabel('Contribution (%)')\n",
    "            ax2.set_ylim([0, 100])\n",
    "            ax2.legend(loc='best')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def create_summary_dashboard(self, year=2100, scenario='ssp585'):\n",
    "        \"\"\"Comprehensive summary dashboard\"\"\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 14))\n",
    "        gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)\n",
    "        \n",
    "        # 1. Temperature trajectory\n",
    "        if 'climate' in self.datasets:\n",
    "            ax = fig.add_subplot(gs[0, :])\n",
    "            ds = self.datasets['climate']\n",
    "            \n",
    "            years = ds['years'].values\n",
    "            surf_temp = ds['surface_temperature']\n",
    "            \n",
    "            mean = surf_temp.mean(dim='samples').values\n",
    "            p5 = surf_temp.quantile(0.05, dim='samples').values\n",
    "            p95 = surf_temp.quantile(0.95, dim='samples').values\n",
    "            \n",
    "            ax.fill_between(years, p5, p95, alpha=0.3, color='red', label='5-95% range')\n",
    "            ax.plot(years, mean, 'r-', linewidth=3, label='Mean')\n",
    "            \n",
    "            for temp_level in [1.5, 2.0, 3.0]:\n",
    "                idx = np.where(mean >= temp_level)[0]\n",
    "                if len(idx) > 0:\n",
    "                    ax.axhline(y=temp_level, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "                    ax.text(years[-1], temp_level, f'{temp_level}°C', va='center', ha='right', fontsize=9)\n",
    "            \n",
    "            ax.set_title('Global Surface Temperature Projection', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Temperature Anomaly (°C)')\n",
    "            ax.legend(loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2-4. Individual SLR components\n",
    "        components = [\n",
    "            ('Land Water\\nStorage', 'lws_gslr', gs[1, 0], 'blue'),\n",
    "            ('Sterodynamics', 'stereo_gslr', gs[1, 1], 'green'),\n",
    "            ('Ice Components', 'ice_gslr', gs[1, 2], 'orange')\n",
    "        ]\n",
    "        \n",
    "        all_means = []\n",
    "        for name, key, grid_spec, color in components:\n",
    "            if key in self.datasets:\n",
    "                ax = fig.add_subplot(grid_spec)\n",
    "                ds = self.datasets[key]\n",
    "                \n",
    "                slr_vars = [v for v in ds.data_vars if 'slr' in v.lower()]\n",
    "                if slr_vars:\n",
    "                    slr_data = ds[slr_vars[0]]\n",
    "                    time_dim = 'years' if 'years' in slr_data.dims else 'year' if 'year' in slr_data.dims else 'time'\n",
    "                    sample_dim = 'samples' if 'samples' in slr_data.dims else 'sample' if 'sample' in slr_data.dims else None\n",
    "                    \n",
    "                    years_slr = ds[time_dim].values\n",
    "                    \n",
    "                    if sample_dim:\n",
    "                        mean = slr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                        p5 = slr_data.quantile(0.05, dim=sample_dim).values.squeeze()\n",
    "                        p95 = slr_data.quantile(0.95, dim=sample_dim).values.squeeze()\n",
    "                        \n",
    "                        # Ensure 1D\n",
    "                        if mean.ndim > 1:\n",
    "                            mean = mean.flatten()\n",
    "                        if p5.ndim > 1:\n",
    "                            p5 = p5.flatten()\n",
    "                        if p95.ndim > 1:\n",
    "                            p95 = p95.flatten()\n",
    "                        \n",
    "                        ax.fill_between(years_slr, p5, p95, alpha=0.3, color=color)\n",
    "                        ax.plot(years_slr, mean, color=color, linewidth=2.5)\n",
    "                        \n",
    "                        all_means.append((years_slr, mean))\n",
    "                    \n",
    "                    ax.set_title(name, fontsize=12, fontweight='bold')\n",
    "                    ax.set_xlabel('Year', fontsize=10)\n",
    "                    ax.set_ylabel('SLR (mm)', fontsize=10)\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Total SLR over time\n",
    "        if len(all_means) > 0:\n",
    "            ax = fig.add_subplot(gs[2, :])\n",
    "            \n",
    "            # Check if interpolation needed\n",
    "            time_lengths = [len(y) for y, _ in all_means]\n",
    "            \n",
    "            if len(set(time_lengths)) == 1:\n",
    "                # All same length\n",
    "                years_common = all_means[0][0]\n",
    "                total = np.sum([data for _, data in all_means], axis=0)\n",
    "            else:\n",
    "                # Interpolate\n",
    "                min_year = max([y[0] for y, _ in all_means])\n",
    "                max_year = min([y[-1] for y, _ in all_means])\n",
    "                n_points = min(time_lengths)\n",
    "                years_common = np.linspace(min_year, max_year, n_points)\n",
    "                \n",
    "                interpolated = []\n",
    "                for years_orig, data_orig in all_means:\n",
    "                    data_interp = np.interp(years_common, years_orig, data_orig)\n",
    "                    interpolated.append(data_interp)\n",
    "                \n",
    "                total = np.sum(interpolated, axis=0)\n",
    "            \n",
    "            ax.plot(years_common, total, 'r-', linewidth=3)\n",
    "            ax.fill_between(years_common, 0, total, alpha=0.2, color='red')\n",
    "            \n",
    "            year_idx = np.argmin(np.abs(years_common - year))\n",
    "            total_at_year = total[year_idx]\n",
    "            ax.plot(year, total_at_year, 'ro', markersize=10, zorder=5)\n",
    "            ax.text(year, total_at_year, f'  {total_at_year:.0f} mm\\n  in {year}',\n",
    "                   fontsize=11, fontweight='bold', va='center')\n",
    "            \n",
    "            ax.set_title('Total Sea Level Rise', fontsize=14, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Total SLR (mm)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6-8. Distributions at target year\n",
    "        for idx, (name, key, _, color) in enumerate(components):\n",
    "            if key in self.datasets:\n",
    "                ax = fig.add_subplot(gs[3, idx])\n",
    "                ds = self.datasets[key]\n",
    "                \n",
    "                slr_vars = [v for v in ds.data_vars if 'slr' in v.lower()]\n",
    "                if slr_vars:\n",
    "                    slr_data = ds[slr_vars[0]]\n",
    "                    time_dim = 'years' if 'years' in slr_data.dims else 'year' if 'year' in slr_data.dims else 'time'\n",
    "                    sample_dim = 'samples' if 'samples' in slr_data.dims else 'sample' if 'sample' in slr_data.dims else None\n",
    "                    \n",
    "                    years_slr = ds[time_dim].values\n",
    "                    year_idx = np.argmin(np.abs(years_slr - year))\n",
    "                    \n",
    "                    if sample_dim:\n",
    "                        data_at_year = slr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                        \n",
    "                        ax.hist(data_at_year, bins=15, alpha=0.7, color=color, edgecolor='black')\n",
    "                        ax.axvline(np.mean(data_at_year), color='darkred', linestyle='--', linewidth=2)\n",
    "                        \n",
    "                        ax.set_title(f'{name.replace(chr(10), \" \")} - {year}', fontsize=11, fontweight='bold')\n",
    "                        ax.set_xlabel('SLR (mm)', fontsize=10)\n",
    "                        ax.set_ylabel('Count', fontsize=10)\n",
    "                        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.suptitle(f'FACT Sea Level Framework - Summary Dashboard ({scenario.upper()})',\n",
    "                     fontsize=18, fontweight='bold', y=0.998)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def export_statistics(self, year=2100, scenario='ssp585', output_file='slr_statistics.csv'):\n",
    "        \"\"\"Export detailed statistics to CSV\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Climate statistics\n",
    "        if 'climate' in self.datasets:\n",
    "            ds = self.datasets['climate']\n",
    "            years = ds['years'].values\n",
    "            year_idx = np.argmin(np.abs(years - year))\n",
    "            \n",
    "            for var in ['surface_temperature', 'deep_ocean_temperature', 'ocean_heat_content']:\n",
    "                if var in ds.data_vars:\n",
    "                    data = ds[var].isel(years=year_idx).values\n",
    "                    \n",
    "                    # For ocean_heat_content, scale down to avoid overflow in std calculation\n",
    "                    if var == 'ocean_heat_content':\n",
    "                        data_scaled = data / 1e24  # Convert to YJ\n",
    "                        results.append({\n",
    "                            'Component': 'FAIR',\n",
    "                            'Variable': var,\n",
    "                            'Unit': 'YJ (10²⁴ J)',\n",
    "                            'Year': year,\n",
    "                            'Mean': np.mean(data_scaled),\n",
    "                            'Median': np.median(data_scaled),\n",
    "                            'Std': np.std(data_scaled),\n",
    "                            'P5': np.percentile(data_scaled, 5),\n",
    "                            'P25': np.percentile(data_scaled, 25),\n",
    "                            'P75': np.percentile(data_scaled, 75),\n",
    "                            'P95': np.percentile(data_scaled, 95),\n",
    "                            'Min': np.min(data_scaled),\n",
    "                            'Max': np.max(data_scaled)\n",
    "                        })\n",
    "                    else:\n",
    "                        results.append({\n",
    "                            'Component': 'FAIR',\n",
    "                            'Variable': var,\n",
    "                            'Unit': '°C',\n",
    "                            'Year': year,\n",
    "                            'Mean': np.mean(data),\n",
    "                            'Median': np.median(data),\n",
    "                            'Std': np.std(data),\n",
    "                            'P5': np.percentile(data, 5),\n",
    "                            'P25': np.percentile(data, 25),\n",
    "                            'P75': np.percentile(data, 75),\n",
    "                            'P95': np.percentile(data, 95),\n",
    "                            'Min': np.min(data),\n",
    "                            'Max': np.max(data)\n",
    "                        })\n",
    "        \n",
    "        # Sea level statistics\n",
    "        slr_components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Components': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        for comp_name, key in slr_components.items():\n",
    "            if key in self.datasets:\n",
    "                ds = self.datasets[key]\n",
    "                \n",
    "                slr_vars = [v for v in ds.data_vars if 'slr' in v.lower()]\n",
    "                for var in slr_vars:\n",
    "                    slr_data = ds[var]\n",
    "                    time_dim = 'years' if 'years' in slr_data.dims else 'year' if 'year' in slr_data.dims else 'time'\n",
    "                    sample_dim = 'samples' if 'samples' in slr_data.dims else 'sample' if 'sample' in slr_data.dims else None\n",
    "                    \n",
    "                    years_slr = ds[time_dim].values\n",
    "                    year_idx = np.argmin(np.abs(years_slr - year))\n",
    "                    \n",
    "                    if sample_dim:\n",
    "                        data = slr_data.isel({time_dim: year_idx}).values\n",
    "                        \n",
    "                        results.append({\n",
    "                            'Component': comp_name,\n",
    "                            'Variable': var,\n",
    "                            'Unit': 'mm',\n",
    "                            'Year': year,\n",
    "                            'Mean': np.mean(data),\n",
    "                            'Median': np.median(data),\n",
    "                            'Std': np.std(data),\n",
    "                            'P5': np.percentile(data, 5),\n",
    "                            'P25': np.percentile(data, 25),\n",
    "                            'P75': np.percentile(data, 75),\n",
    "                            'P95': np.percentile(data, 95),\n",
    "                            'Min': np.min(data),\n",
    "                            'Max': np.max(data)\n",
    "                        })\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nStatistics exported to {output_file}\")\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(df[['Component', 'Variable', 'Unit', 'Mean', 'P5', 'P95']].to_string(index=False))\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def plot_individual_gslr_components(self, year=2100, figsize=(18, 12)):\n",
    "        \"\"\"Plot each individual GSLR component in detail with ensemble uncertainty\"\"\"\n",
    "        \n",
    "        gslr_components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Sheets & Glaciers': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        available = {name: key for name, key in gslr_components.items() if key in self.datasets}\n",
    "        \n",
    "        if not available:\n",
    "            print(\"No GSLR data available\")\n",
    "            return\n",
    "        \n",
    "        n_components = len(available)\n",
    "        fig, axes = plt.subplots(n_components, 3, figsize=figsize)\n",
    "        \n",
    "        if n_components == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        colors = ['blue', 'green', 'orange']\n",
    "        \n",
    "        plot_idx = 0\n",
    "        for idx, (name, key) in enumerate(available.items()):\n",
    "            ds = self.datasets[key]\n",
    "            \n",
    "            # Find GSLR variable - check all possible names\n",
    "            gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            if not gslr_vars:\n",
    "                print(f\"⚠ No SLR variable found in {key}. Available variables: {list(ds.data_vars)}\")\n",
    "                # Mark plots as unavailable\n",
    "                for col in range(3):\n",
    "                    axes[idx, col].text(0.5, 0.5, f'No data available\\nfor {name}',\n",
    "                                       ha='center', va='center', transform=axes[idx, col].transAxes)\n",
    "                    axes[idx, col].set_title(f'{name} - No Data', fontsize=12, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            gslr_var = gslr_vars[0]\n",
    "            print(f\"  Using variable '{gslr_var}' from {key}\")\n",
    "            gslr_data = ds[gslr_var]\n",
    "            \n",
    "            print(f\"    Shape: {gslr_data.shape}, Dims: {gslr_data.dims}\")\n",
    "            \n",
    "            # Determine dimensions\n",
    "            time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "            sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else 'ensemble'\n",
    "            \n",
    "            if time_dim not in gslr_data.dims:\n",
    "                print(f\"⚠ Could not find time dimension in {key}. Available dims: {gslr_data.dims}\")\n",
    "                for col in range(3):\n",
    "                    axes[idx, col].text(0.5, 0.5, f'No time dimension\\nfor {name}',\n",
    "                                       ha='center', va='center', transform=axes[idx, col].transAxes)\n",
    "                    axes[idx, col].set_title(f'{name} - No Time Data', fontsize=12, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            years_data = ds[time_dim].values\n",
    "            print(f\"    Years: {years_data[0]} to {years_data[-1]} ({len(years_data)} points)\")\n",
    "            \n",
    "            # Check if sample dimension exists\n",
    "            has_samples = sample_dim in gslr_data.dims\n",
    "            if has_samples:\n",
    "                print(f\"    Samples: {gslr_data.sizes[sample_dim]}\")\n",
    "            \n",
    "            # Plot 1: Time series with uncertainty\n",
    "            ax = axes[idx, 0]\n",
    "            \n",
    "            if has_samples:\n",
    "                # Individual ensemble members (plot a few)\n",
    "                n_plot = min(10, gslr_data.sizes[sample_dim])\n",
    "                for i in range(n_plot):\n",
    "                    sample_data = gslr_data.isel({sample_dim: i}).values.squeeze()\n",
    "                    if sample_data.ndim > 1:\n",
    "                        sample_data = sample_data.flatten()\n",
    "                    ax.plot(years_data, sample_data, alpha=0.2, color=colors[idx], linewidth=0.5)\n",
    "                \n",
    "                # Statistics\n",
    "                mean = gslr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                p5 = gslr_data.quantile(0.05, dim=sample_dim).values.squeeze()\n",
    "                p95 = gslr_data.quantile(0.95, dim=sample_dim).values.squeeze()\n",
    "                p25 = gslr_data.quantile(0.25, dim=sample_dim).values.squeeze()\n",
    "                p75 = gslr_data.quantile(0.75, dim=sample_dim).values.squeeze()\n",
    "                \n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "                if p5.ndim > 1:\n",
    "                    p5 = p5.flatten()\n",
    "                if p95.ndim > 1:\n",
    "                    p95 = p95.flatten()\n",
    "                if p25.ndim > 1:\n",
    "                    p25 = p25.flatten()\n",
    "                if p75.ndim > 1:\n",
    "                    p75 = p75.flatten()\n",
    "                \n",
    "                print(f\"    Mean range: {np.min(mean):.2f} to {np.max(mean):.2f}\")\n",
    "                \n",
    "                ax.fill_between(years_data, p5, p95, alpha=0.2, color=colors[idx], label='5-95th percentile')\n",
    "                ax.fill_between(years_data, p25, p75, alpha=0.3, color=colors[idx], label='25-75th percentile')\n",
    "                ax.plot(years_data, mean, color=colors[idx], linewidth=2.5, label='Mean')\n",
    "            else:\n",
    "                gslr_values = gslr_data.values.squeeze()\n",
    "                if gslr_values.ndim > 1:\n",
    "                    gslr_values = gslr_values.flatten()\n",
    "                print(f\"    Value range: {np.min(gslr_values):.2f} to {np.max(gslr_values):.2f}\")\n",
    "                ax.plot(years_data, gslr_values, color=colors[idx], linewidth=2.5)\n",
    "            \n",
    "            ax.set_title(f'{name} - Time Series', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Global SLR (mm)')\n",
    "            if has_samples:\n",
    "                ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 2: Distribution at target year\n",
    "            ax = axes[idx, 1]\n",
    "            \n",
    "            try:\n",
    "                year_idx = np.argmin(np.abs(years_data - year))\n",
    "                actual_year = years_data[year_idx]\n",
    "                print(f\"    Target year {year}, using data from {actual_year}\")\n",
    "                \n",
    "                if has_samples:\n",
    "                    data_at_year = gslr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                    \n",
    "                    if len(data_at_year) > 0:\n",
    "                        ax.hist(data_at_year, bins=20, alpha=0.7, color=colors[idx], edgecolor='black')\n",
    "                        ax.axvline(np.mean(data_at_year), color='darkred', linestyle='--', linewidth=2,\n",
    "                                  label=f'Mean: {np.mean(data_at_year):.1f} mm')\n",
    "                        ax.axvline(np.median(data_at_year), color='red', linestyle=':', linewidth=2,\n",
    "                                  label=f'Median: {np.median(data_at_year):.1f} mm')\n",
    "                        ax.axvline(np.percentile(data_at_year, 5), color='gray', linestyle=':', linewidth=1.5,\n",
    "                                  label=f'5th: {np.percentile(data_at_year, 5):.1f} mm')\n",
    "                        ax.axvline(np.percentile(data_at_year, 95), color='gray', linestyle=':', linewidth=1.5,\n",
    "                                  label=f'95th: {np.percentile(data_at_year, 95):.1f} mm')\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "                else:\n",
    "                    data_at_year = gslr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                    if len(data_at_year) > 0:\n",
    "                        ax.axvline(data_at_year[0], color=colors[idx], linewidth=3)\n",
    "                        ax.text(0.5, 0.5, f'Value: {data_at_year[0]:.1f} mm',\n",
    "                               ha='center', va='center', transform=ax.transAxes)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "                \n",
    "                ax.set_title(f'{name} - Distribution at {actual_year}', fontsize=12, fontweight='bold')\n",
    "                ax.set_xlabel('SLR (mm)')\n",
    "                ax.set_ylabel('Frequency')\n",
    "                if has_samples:\n",
    "                    ax.legend(fontsize=8)\n",
    "                ax.grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠ Error plotting distribution: {e}\")\n",
    "                ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=ax.transAxes)\n",
    "            \n",
    "            # Plot 3: Rate of change (decadal trend)\n",
    "            ax = axes[idx, 2]\n",
    "            \n",
    "            try:\n",
    "                if has_samples:\n",
    "                    mean = gslr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                    if mean.ndim > 1:\n",
    "                        mean = mean.flatten()\n",
    "                else:\n",
    "                    mean = gslr_data.values.squeeze()\n",
    "                    if mean.ndim > 1:\n",
    "                        mean = mean.flatten()\n",
    "                \n",
    "                # Calculate decadal rate\n",
    "                if len(mean) > 1 and len(years_data) > 1:\n",
    "                    # Calculate rate\n",
    "                    year_diff = np.diff(years_data)\n",
    "                    mean_diff = np.diff(mean)\n",
    "                    rate = mean_diff / year_diff * 10  # mm per decade\n",
    "                    years_rate = years_data[:-1] + year_diff / 2  # Use midpoint\n",
    "                    \n",
    "                    print(f\"    Rate range: {np.min(rate):.2f} to {np.max(rate):.2f} mm/decade\")\n",
    "                    \n",
    "                    # Smooth the rate if we have enough points\n",
    "                    if len(rate) >= 10:\n",
    "                        window = 10\n",
    "                        # Use valid mode\n",
    "                        rate_smoothed = np.convolve(rate, np.ones(window)/window, mode='valid')\n",
    "                        # Calculate corresponding years\n",
    "                        years_smoothed = years_rate[window//2:window//2+len(rate_smoothed)]\n",
    "                        \n",
    "                        ax.plot(years_smoothed, rate_smoothed, color=colors[idx], linewidth=2.5, label='Smoothed (10yr)')\n",
    "                        ax.plot(years_rate, rate, color=colors[idx], linewidth=1, alpha=0.3, label='Annual')\n",
    "                        ax.legend(fontsize=8)\n",
    "                    else:\n",
    "                        ax.plot(years_rate, rate, color=colors[idx], linewidth=2.5)\n",
    "                    \n",
    "                    ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "                    ax.set_title(f'{name} - Rate of Change', fontsize=12, fontweight='bold')\n",
    "                    ax.set_xlabel('Year')\n",
    "                    ax.set_ylabel('SLR Rate (mm/decade)')\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Insufficient data\\nfor rate calculation',\n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_title(f'{name} - Rate of Change', fontsize=12, fontweight='bold')\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠ Error plotting rate: {e}\")\n",
    "                ax.text(0.5, 0.5, f'Error: {str(e)}', ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{name} - Rate of Change', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            plot_idx += 1\n",
    "        \n",
    "        plt.suptitle('Individual GSLR Component Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "    def _plot_individual_gslr_components(self, year=2100, figsize=(18, 12)):\n",
    "        \"\"\"Plot each individual GSLR component in detail with ensemble uncertainty\"\"\"\n",
    "        \n",
    "        gslr_components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Sheets & Glaciers': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        available = {name: key for name, key in gslr_components.items() if key in self.datasets}\n",
    "        \n",
    "        if not available:\n",
    "            print(\"No GSLR data available\")\n",
    "            return\n",
    "        \n",
    "        n_components = len(available)\n",
    "        fig, axes = plt.subplots(n_components, 3, figsize=figsize)\n",
    "        \n",
    "        if n_components == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        colors = ['blue', 'green', 'orange']\n",
    "        \n",
    "        for idx, (name, key) in enumerate(available.items()):\n",
    "            ds = self.datasets[key]\n",
    "            \n",
    "            # Find GSLR variable - check all possible names\n",
    "            gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            if not gslr_vars:\n",
    "                print(f\"No SLR variable found in {key}. Available variables: {list(ds.data_vars)}\")\n",
    "                continue\n",
    "            \n",
    "            gslr_var = gslr_vars[0]\n",
    "            print(f\"  Using variable '{gslr_var}' from {key}\")\n",
    "            gslr_data = ds[gslr_var]\n",
    "            \n",
    "            # Determine dimensions\n",
    "            time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "            sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else 'ensemble'\n",
    "            \n",
    "            if time_dim not in gslr_data.dims:\n",
    "                print(f\"Could not find time dimension in {key}. Available dims: {gslr_data.dims}\")\n",
    "                continue\n",
    "            \n",
    "            years_data = ds[time_dim].values\n",
    "            \n",
    "            # Plot 1: Time series with uncertainty\n",
    "            ax = axes[idx, 0]\n",
    "            \n",
    "            if sample_dim in gslr_data.dims:\n",
    "                # Individual ensemble members\n",
    "                for i in range(min(10, gslr_data.sizes[sample_dim])):  # Plot max 10 members\n",
    "                    sample_data = gslr_data.isel({sample_dim: i}).values.squeeze()\n",
    "                    if sample_data.ndim > 1:\n",
    "                        sample_data = sample_data.flatten()\n",
    "                    ax.plot(years_data, sample_data, alpha=0.2, color=colors[idx], linewidth=0.5)\n",
    "                \n",
    "                # Statistics\n",
    "                mean = gslr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                p5 = gslr_data.quantile(0.05, dim=sample_dim).values.squeeze()\n",
    "                p95 = gslr_data.quantile(0.95, dim=sample_dim).values.squeeze()\n",
    "                p25 = gslr_data.quantile(0.25, dim=sample_dim).values.squeeze()\n",
    "                p75 = gslr_data.quantile(0.75, dim=sample_dim).values.squeeze()\n",
    "                \n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "                if p5.ndim > 1:\n",
    "                    p5 = p5.flatten()\n",
    "                if p95.ndim > 1:\n",
    "                    p95 = p95.flatten()\n",
    "                if p25.ndim > 1:\n",
    "                    p25 = p25.flatten()\n",
    "                if p75.ndim > 1:\n",
    "                    p75 = p75.flatten()\n",
    "                \n",
    "                ax.fill_between(years_data, p5, p95, alpha=0.2, color=colors[idx], label='5-95th percentile')\n",
    "                ax.fill_between(years_data, p25, p75, alpha=0.3, color=colors[idx], label='25-75th percentile')\n",
    "                ax.plot(years_data, mean, color=colors[idx], linewidth=2.5, label='Mean')\n",
    "            else:\n",
    "                gslr_values = gslr_data.values.squeeze()\n",
    "                if gslr_values.ndim > 1:\n",
    "                    gslr_values = gslr_values.flatten()\n",
    "                ax.plot(years_data, gslr_values, color=colors[idx], linewidth=2.5)\n",
    "            \n",
    "            ax.set_title(f'{name} - Time Series', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Global SLR (mm)')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 2: Distribution at target year\n",
    "            ax = axes[idx, 1]\n",
    "            year_idx = np.argmin(np.abs(years_data - year))\n",
    "            \n",
    "            if sample_dim in gslr_data.dims:\n",
    "                data_at_year = gslr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                \n",
    "                ax.hist(data_at_year, bins=20, alpha=0.7, color=colors[idx], edgecolor='black')\n",
    "                ax.axvline(np.mean(data_at_year), color='darkred', linestyle='--', linewidth=2,\n",
    "                          label=f'Mean: {np.mean(data_at_year):.1f} mm')\n",
    "                ax.axvline(np.median(data_at_year), color='red', linestyle=':', linewidth=2,\n",
    "                          label=f'Median: {np.median(data_at_year):.1f} mm')\n",
    "                ax.axvline(np.percentile(data_at_year, 5), color='gray', linestyle=':', linewidth=1.5,\n",
    "                          label=f'5th: {np.percentile(data_at_year, 5):.1f} mm')\n",
    "                ax.axvline(np.percentile(data_at_year, 95), color='gray', linestyle=':', linewidth=1.5,\n",
    "                          label=f'95th: {np.percentile(data_at_year, 95):.1f} mm')\n",
    "            else:\n",
    "                data_at_year = gslr_data.isel({time_dim: year_idx}).values.flatten()[0]\n",
    "                ax.axvline(data_at_year, color=colors[idx], linewidth=3)\n",
    "            \n",
    "            ax.set_title(f'{name} - Distribution at {year}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('SLR (mm)')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Plot 3: Rate of change (decadal trend)\n",
    "            ax = axes[idx, 2]\n",
    "            \n",
    "            if sample_dim in gslr_data.dims:\n",
    "                mean = gslr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                if mean.ndim > 1:\n",
    "                    mean = mean.flatten()\n",
    "                \n",
    "            # Calculate decadal rate\n",
    "            if len(mean) > 1 and len(years_data) > 1:\n",
    "                rate = np.diff(mean) / np.diff(years_data) * 10  # mm per decade\n",
    "                years_rate = years_data[:-1]\n",
    "                \n",
    "                # Smooth the rate\n",
    "                if len(rate) >= 10:\n",
    "                    window = 10\n",
    "                    # Use valid mode which returns len(rate) - window + 1 points\n",
    "                    rate_smoothed = np.convolve(rate, np.ones(window)/window, mode='valid')\n",
    "                    # Adjust years to match: take the middle of the window\n",
    "                    years_smoothed = years_rate[(window-1)//2:len(rate_smoothed)+(window-1)//2]\n",
    "                    \n",
    "                    # Ensure they match\n",
    "                    if len(years_smoothed) != len(rate_smoothed):\n",
    "                        years_smoothed = years_smoothed[:len(rate_smoothed)]\n",
    "                    \n",
    "                    ax.plot(years_smoothed, rate_smoothed, color=colors[idx], linewidth=2.5, label='Smoothed (10yr)')\n",
    "                    ax.plot(years_rate, rate, color=colors[idx], linewidth=1, alpha=0.3, label='Annual')\n",
    "                else:\n",
    "                    ax.plot(years_rate, rate, color=colors[idx], linewidth=2.5)\n",
    "                \n",
    "                ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "                ax.set_title(f'{name} - Rate of Change', fontsize=12, fontweight='bold')\n",
    "                ax.set_xlabel('Year')\n",
    "                ax.set_ylabel('SLR Rate (mm/decade)')\n",
    "                if len(rate) >= 10:\n",
    "                    ax.legend(fontsize=8)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'Insufficient data\\nfor rate calculation',\n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "        plt.suptitle('Individual GSLR Component Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_gslr_differences(self, year=2100, figsize=(18, 10)):\n",
    "        \"\"\"Plot differences between GSLR components\"\"\"\n",
    "        \n",
    "        gslr_components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Sheets & Glaciers': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        available = {name: key for name, key in gslr_components.items() if key in self.datasets}\n",
    "        \n",
    "        if len(available) < 2:\n",
    "            print(\"Need at least 2 GSLR components for difference plots\")\n",
    "            return\n",
    "        \n",
    "        # Validate that datasets have SLR variables\n",
    "        valid_components = {}\n",
    "        for name, key in available.items():\n",
    "            ds = self.datasets[key]\n",
    "            slr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            if slr_vars:\n",
    "                valid_components[name] = key\n",
    "            else:\n",
    "                print(f\"⚠ Skipping {name}: no SLR variable found. Available: {list(ds.data_vars)}\")\n",
    "        \n",
    "        if len(valid_components) < 2:\n",
    "            print(\"Need at least 2 valid GSLR components for difference plots\")\n",
    "            return\n",
    "        \n",
    "        # Get all pairwise combinations\n",
    "        from itertools import combinations\n",
    "        pairs = list(combinations(valid_components.items(), 2))\n",
    "        \n",
    "        n_pairs = len(pairs)\n",
    "        fig, axes = plt.subplots(n_pairs, 3, figsize=(figsize[0], figsize[1] * n_pairs / 3))\n",
    "        \n",
    "        if n_pairs == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for idx, ((name1, key1), (name2, key2)) in enumerate(pairs):\n",
    "            ds1 = self.datasets[key1]\n",
    "            ds2 = self.datasets[key2]\n",
    "            \n",
    "            # Get GSLR data with better error handling\n",
    "            gslr_vars1 = [v for v in ds1.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            gslr_vars2 = [v for v in ds2.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            \n",
    "            if not gslr_vars1 or not gslr_vars2:\n",
    "                print(f\"⚠ Skipping {name1} vs {name2}: missing variables\")\n",
    "                continue\n",
    "            \n",
    "            gslr_var1 = gslr_vars1[0]\n",
    "            gslr_var2 = gslr_vars2[0]\n",
    "            \n",
    "            print(f\"  Comparing {name1} ({gslr_var1}) vs {name2} ({gslr_var2})\")\n",
    "            \n",
    "            gslr_data1 = ds1[gslr_var1]\n",
    "            gslr_data2 = ds2[gslr_var2]\n",
    "            \n",
    "            # Determine dimensions\n",
    "            time_dim1 = 'years' if 'years' in gslr_data1.dims else 'year' if 'year' in gslr_data1.dims else 'time'\n",
    "            time_dim2 = 'years' if 'years' in gslr_data2.dims else 'year' if 'year' in gslr_data2.dims else 'time'\n",
    "            sample_dim1 = 'samples' if 'samples' in gslr_data1.dims else 'sample' if 'sample' in gslr_data1.dims else 'ensemble'\n",
    "            sample_dim2 = 'samples' if 'samples' in gslr_data2.dims else 'sample' if 'sample' in gslr_data2.dims else 'ensemble'\n",
    "            \n",
    "            years_data1 = ds1[time_dim1].values\n",
    "            years_data2 = ds2[time_dim2].values\n",
    "            \n",
    "            # Get mean values\n",
    "            if sample_dim1 in gslr_data1.dims:\n",
    "                mean1 = gslr_data1.mean(dim=sample_dim1).values.squeeze()\n",
    "                if mean1.ndim > 1:\n",
    "                    mean1 = mean1.flatten()\n",
    "            else:\n",
    "                mean1 = gslr_data1.values.squeeze()\n",
    "                if mean1.ndim > 1:\n",
    "                    mean1 = mean1.flatten()\n",
    "            \n",
    "            if sample_dim2 in gslr_data2.dims:\n",
    "                mean2 = gslr_data2.mean(dim=sample_dim2).values.squeeze()\n",
    "                if mean2.ndim > 1:\n",
    "                    mean2 = mean2.flatten()\n",
    "            else:\n",
    "                mean2 = gslr_data2.values.squeeze()\n",
    "                if mean2.ndim > 1:\n",
    "                    mean2 = mean2.flatten()\n",
    "            \n",
    "            # Check if need to interpolate\n",
    "            if len(years_data1) != len(years_data2) or not np.allclose(years_data1, years_data2):\n",
    "                print(f\"  ⚠ Interpolating {name1} and {name2} to common time axis\")\n",
    "                min_year = max(years_data1[0], years_data2[0])\n",
    "                max_year = min(years_data1[-1], years_data2[-1])\n",
    "                n_points = min(len(years_data1), len(years_data2))\n",
    "                years_common = np.linspace(min_year, max_year, n_points)\n",
    "                \n",
    "                mean1_interp = np.interp(years_common, years_data1, mean1)\n",
    "                mean2_interp = np.interp(years_common, years_data2, mean2)\n",
    "                \n",
    "                years_data = years_common\n",
    "                mean1 = mean1_interp\n",
    "                mean2 = mean2_interp\n",
    "            else:\n",
    "                years_data = years_data1\n",
    "            \n",
    "            # Calculate difference\n",
    "            diff = mean1 - mean2\n",
    "            \n",
    "            # Plot 1: Both time series\n",
    "            ax = axes[idx, 0]\n",
    "            ax.plot(years_data, mean1, linewidth=2.5, label=name1, color='blue')\n",
    "            ax.plot(years_data, mean2, linewidth=2.5, label=name2, color='red')\n",
    "            ax.set_title(f'{name1} vs {name2}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Global SLR (mm)')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 2: Difference time series\n",
    "            ax = axes[idx, 1]\n",
    "            ax.plot(years_data, diff, linewidth=2.5, color='purple')\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "            ax.fill_between(years_data, 0, diff, alpha=0.3, color='purple')\n",
    "            ax.set_title(f'Difference: {name1} - {name2}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Difference (mm)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics annotation\n",
    "            mean_diff = np.mean(diff)\n",
    "            std_diff = np.std(diff)\n",
    "            max_diff = np.max(np.abs(diff))\n",
    "            ax.text(0.05, 0.95, f'Mean: {mean_diff:.1f} mm\\nStd: {std_diff:.1f} mm\\nMax: {max_diff:.1f} mm',\n",
    "                   transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            # Plot 3: Relative difference (percentage)\n",
    "            ax = axes[idx, 2]\n",
    "            # Avoid division by zero\n",
    "            mean2_safe = np.where(np.abs(mean2) > 1e-6, mean2, 1)\n",
    "            rel_diff = (diff / mean2_safe) * 100\n",
    "            \n",
    "            # Remove infinities\n",
    "            rel_diff = np.where(np.isinf(rel_diff), np.nan, rel_diff)\n",
    "            \n",
    "            ax.plot(years_data, rel_diff, linewidth=2.5, color='green')\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "            ax.fill_between(years_data, 0, rel_diff, alpha=0.3, color='green')\n",
    "            ax.set_title(f'Relative Difference (%)', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Year')\n",
    "            ax.set_ylabel('Relative Difference (%)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_rel = np.nanmean(rel_diff)\n",
    "            ax.text(0.05, 0.95, f'Mean: {mean_rel:.1f}%',\n",
    "                   transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.suptitle('GSLR Component Differences', fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_gslr_correlation_matrix(self, year=2100, figsize=(12, 10)):\n",
    "        \"\"\"Create correlation matrix between GSLR components at specific year\"\"\"\n",
    "        \n",
    "        gslr_components = {\n",
    "            'Land Water Storage': 'lws_gslr',\n",
    "            'Sterodynamics': 'stereo_gslr',\n",
    "            'Ice Sheets & Glaciers': 'ice_gslr'\n",
    "        }\n",
    "        \n",
    "        available = {name: key for name, key in gslr_components.items() if key in self.datasets}\n",
    "        \n",
    "        if len(available) < 2:\n",
    "            print(\"Need at least 2 GSLR components for correlation analysis\")\n",
    "            return\n",
    "        \n",
    "        # Collect ensemble data at target year\n",
    "        ensemble_data = {}\n",
    "        \n",
    "        for name, key in available.items():\n",
    "            ds = self.datasets[key]\n",
    "            \n",
    "            # Find SLR variable\n",
    "            gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "            if not gslr_vars:\n",
    "                print(f\"⚠ Skipping {name}: no SLR variable found\")\n",
    "                continue\n",
    "            \n",
    "            gslr_var = gslr_vars[0]\n",
    "            gslr_data = ds[gslr_var]\n",
    "            \n",
    "            time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "            sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else 'ensemble'\n",
    "            \n",
    "            if time_dim not in gslr_data.dims:\n",
    "                print(f\"⚠ Skipping {name}: no time dimension found\")\n",
    "                continue\n",
    "            \n",
    "            years_data = ds[time_dim].values\n",
    "            year_idx = np.argmin(np.abs(years_data - year))\n",
    "            \n",
    "            if sample_dim in gslr_data.dims:\n",
    "                data_at_year = gslr_data.isel({time_dim: year_idx}).values.flatten()\n",
    "                ensemble_data[name] = data_at_year\n",
    "            else:\n",
    "                print(f\"⚠ Skipping {name}: no ensemble dimension for correlation\")\n",
    "        \n",
    "        if len(ensemble_data) < 2:\n",
    "            print(\"Need at least 2 components with ensemble data for correlation analysis\")\n",
    "            return\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(ensemble_data)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr_matrix = df.corr()\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # Plot 1: Correlation heatmap\n",
    "        try:\n",
    "            import seaborn as sns\n",
    "            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "                        square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax1,\n",
    "                        vmin=-1, vmax=1)\n",
    "        except ImportError:\n",
    "            # Fallback if seaborn not available\n",
    "            im = ax1.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
    "            ax1.set_xticks(range(len(corr_matrix.columns)))\n",
    "            ax1.set_yticks(range(len(corr_matrix.columns)))\n",
    "            ax1.set_xticklabels(corr_matrix.columns, rotation=45, ha='right')\n",
    "            ax1.set_yticklabels(corr_matrix.columns)\n",
    "            \n",
    "            # Add text annotations\n",
    "            for i in range(len(corr_matrix)):\n",
    "                for j in range(len(corr_matrix)):\n",
    "                    text = ax1.text(j, i, f'{corr_matrix.iloc[i, j]:.3f}',\n",
    "                                   ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "            \n",
    "            plt.colorbar(im, ax=ax1)\n",
    "        \n",
    "        ax1.set_title(f'Correlation Matrix at {year}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Plot 2: Scatter matrix (for first pair)\n",
    "        if len(ensemble_data) >= 2:\n",
    "            names = list(ensemble_data.keys())\n",
    "            data1 = ensemble_data[names[0]]\n",
    "            data2 = ensemble_data[names[1]]\n",
    "            \n",
    "            ax2.scatter(data1, data2, alpha=0.6, s=100, edgecolors='black')\n",
    "            ax2.set_xlabel(f'{names[0]} (mm)', fontsize=11)\n",
    "            ax2.set_ylabel(f'{names[1]} (mm)', fontsize=11)\n",
    "            ax2.set_title(f'{names[0]} vs {names[1]} at {year}', fontsize=12, fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add correlation coefficient\n",
    "            corr_val = corr_matrix.loc[names[0], names[1]]\n",
    "            ax2.text(0.05, 0.95, f'r = {corr_val:.3f}',\n",
    "                    transform=ax2.transAxes, fontsize=11, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            # Add best fit line\n",
    "            z = np.polyfit(data1, data2, 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax2.plot(data1, p(data1), \"r--\", alpha=0.8, linewidth=2, label=f'y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "            ax2.legend()\n",
    "        \n",
    "        plt.suptitle('GSLR Component Correlations', fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "    def plot_lslr_location_points(self, component='lws', year=2100, sample_idx=None, figsize=(16, 12)):\n",
    "        \"\"\"Plot LSLR for specific location points (when no spatial grid available)\"\"\"\n",
    "        \n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        \n",
    "        lslr_key = f'{component}_lslr'\n",
    "        \n",
    "        if lslr_key not in self.datasets:\n",
    "            print(f\"Dataset '{lslr_key}' not found\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets[lslr_key]\n",
    "        \n",
    "        print(f\"\\nAnalyzing location-based {lslr_key}:\")\n",
    "        print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "        print(f\"  Dimensions: {dict(ds.dims)}\")\n",
    "        \n",
    "        # Check if we have location dimension\n",
    "        loc_dim = None\n",
    "        for name in ['location', 'locations', 'site', 'sites', 'point', 'points']:\n",
    "            if name in ds.dims:\n",
    "                loc_dim = name\n",
    "                break\n",
    "        \n",
    "        if loc_dim is None:\n",
    "            print(\"⚠ No location dimension found\")\n",
    "            return\n",
    "        \n",
    "        print(f\"  Location dimension: {loc_dim}\")\n",
    "        n_locations = ds.dims[loc_dim]\n",
    "        print(f\"  Number of locations: {n_locations}\")\n",
    "        \n",
    "        # Try to find lat/lon coordinates\n",
    "        lat_coord = None\n",
    "        lon_coord = None\n",
    "        \n",
    "        for name in ['lat', 'latitude']:\n",
    "            if name in ds.coords or name in ds.data_vars:\n",
    "                lat_coord = name\n",
    "                break\n",
    "        \n",
    "        for name in ['lon', 'longitude']:\n",
    "            if name in ds.coords or name in ds.data_vars:\n",
    "                lon_coord = name\n",
    "                break\n",
    "        \n",
    "        if lat_coord is None or lon_coord is None:\n",
    "            print(f\"⚠ No lat/lon coordinates found\")\n",
    "            print(f\"  Available coords: {list(ds.coords)}\")\n",
    "            return\n",
    "        \n",
    "        lats = ds[lat_coord].values\n",
    "        lons = ds[lon_coord].values\n",
    "        \n",
    "        print(f\"  Coordinates found: {len(lats)} locations\")\n",
    "        print(f\"  Lat range: [{np.min(lats):.2f}, {np.max(lats):.2f}]\")\n",
    "        print(f\"  Lon range: [{np.min(lons):.2f}, {np.max(lons):.2f}]\")\n",
    "        \n",
    "        # Get LSLR data\n",
    "        lslr_vars = [v for v in ds.data_vars if 'lslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "        if not lslr_vars:\n",
    "            print(\"No LSLR variable found\")\n",
    "            return\n",
    "        \n",
    "        lslr_var = lslr_vars[0]\n",
    "        lslr_data = ds[lslr_var]\n",
    "        \n",
    "        # Get time and sample dimensions\n",
    "        time_dim = 'years' if 'years' in lslr_data.dims else 'year' if 'year' in lslr_data.dims else 'time'\n",
    "        sample_dim = 'samples' if 'samples' in lslr_data.dims else 'sample' if 'sample' in lslr_data.dims else None\n",
    "        \n",
    "        # Select data for target year\n",
    "        if time_dim in lslr_data.dims:\n",
    "            years = ds[time_dim].values\n",
    "            year_idx = np.argmin(np.abs(years - year))\n",
    "            actual_year = years[year_idx]\n",
    "            print(f\"  Using year: {actual_year}\")\n",
    "            lslr_at_year = lslr_data.isel({time_dim: year_idx})\n",
    "        else:\n",
    "            actual_year = year\n",
    "            lslr_at_year = lslr_data\n",
    "        \n",
    "        # Handle samples\n",
    "        if sample_dim and sample_dim in lslr_at_year.dims:\n",
    "            if sample_idx is None:\n",
    "                lslr_values = lslr_at_year.mean(dim=sample_dim).values\n",
    "                title_suffix = \"Mean across samples\"\n",
    "            else:\n",
    "                lslr_values = lslr_at_year.isel({sample_dim: sample_idx}).values\n",
    "                title_suffix = f\"Sample {sample_idx}\"\n",
    "        else:\n",
    "            lslr_values = lslr_at_year.values\n",
    "            title_suffix = \"Single value\"\n",
    "        \n",
    "        # Flatten if needed\n",
    "        if lslr_values.ndim > 1:\n",
    "            lslr_values = lslr_values.flatten()\n",
    "        \n",
    "        print(f\"  SLR range: [{np.min(lslr_values):.2f}, {np.max(lslr_values):.2f}] mm\")\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Main map\n",
    "        ax_map = fig.add_subplot(gs[0, :], projection=ccrs.PlateCarree())\n",
    "        \n",
    "        # Add geographic features\n",
    "        ax_map.coastlines(resolution='50m', linewidth=1)\n",
    "        ax_map.add_feature(cfeature.BORDERS, linewidth=0.5, alpha=0.5)\n",
    "        ax_map.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3)\n",
    "        ax_map.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "        \n",
    "        # Plot points colored by SLR value\n",
    "        scatter = ax_map.scatter(lons, lats, c=lslr_values, s=100, \n",
    "                                cmap='RdYlBu_r', edgecolors='black', linewidth=0.5,\n",
    "                                transform=ccrs.PlateCarree(), zorder=5)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax_map, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "        cbar.set_label('Local Sea Level Rise (mm)', fontsize=12)\n",
    "        \n",
    "        # Label some key points\n",
    "        for i in range(min(10, len(lats))):  # Label first 10 points\n",
    "            ax_map.text(lons[i], lats[i]+1, f'{i+1}', transform=ccrs.PlateCarree(),\n",
    "                       fontsize=8, ha='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        # Grid lines\n",
    "        gl = ax_map.gridlines(draw_labels=True, linewidth=0.5, alpha=0.5, linestyle='--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        # Set extent with padding\n",
    "        extent = [np.min(lons)-5, np.max(lons)+5, np.min(lats)-5, np.max(lats)+5]\n",
    "        ax_map.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        component_name = component.upper()\n",
    "        ax_map.set_title(f'{component_name} Local SLR at {actual_year} - {title_suffix}',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Histogram\n",
    "        ax_hist = fig.add_subplot(gs[1, 0])\n",
    "        ax_hist.hist(lslr_values, bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        ax_hist.axvline(np.mean(lslr_values), color='red', linestyle='--', linewidth=2,\n",
    "                        label=f'Mean: {np.mean(lslr_values):.1f} mm')\n",
    "        ax_hist.set_xlabel('Local SLR (mm)')\n",
    "        ax_hist.set_ylabel('Frequency')\n",
    "        ax_hist.set_title('Distribution Across Locations', fontsize=12, fontweight='bold')\n",
    "        ax_hist.legend()\n",
    "        ax_hist.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Top locations table\n",
    "        ax_table = fig.add_subplot(gs[1, 1])\n",
    "        ax_table.axis('off')\n",
    "        \n",
    "        # Sort and get top/bottom locations\n",
    "        sorted_idx = np.argsort(lslr_values)\n",
    "        \n",
    "        table_text = \"Top 5 Highest SLR Locations:\\n\\n\"\n",
    "        for i in range(min(5, len(sorted_idx))):\n",
    "            idx = sorted_idx[-(i+1)]\n",
    "            table_text += f\"{i+1}. Loc {idx+1}: {lslr_values[idx]:.1f} mm\\n\"\n",
    "            table_text += f\"   ({lats[idx]:.2f}°, {lons[idx]:.2f}°)\\n\"\n",
    "        \n",
    "        table_text += \"\\nBottom 5 Lowest SLR Locations:\\n\\n\"\n",
    "        for i in range(min(5, len(sorted_idx))):\n",
    "            idx = sorted_idx[i]\n",
    "            table_text += f\"{i+1}. Loc {idx+1}: {lslr_values[idx]:.1f} mm\\n\"\n",
    "            table_text += f\"   ({lats[idx]:.2f}°, {lons[idx]:.2f}°)\\n\"\n",
    "        \n",
    "        ax_table.text(0.1, 0.9, table_text, transform=ax_table.transAxes,\n",
    "                      fontsize=9, verticalalignment='top', family='monospace',\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        \n",
    "        plt.suptitle(f'Local Sea Level Rise - {component_name} ({n_locations} locations)',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def plot_lslr_spatial_map(self, component='lws', year=2100, sample_idx=None, figsize=(18, 12)):\n",
    "        \"\"\"Plot spatial map of Local SLR with sample locations highlighted\"\"\"\n",
    "        \n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        \n",
    "        # Get the LSLR dataset\n",
    "        lslr_key = f'{component}_lslr'\n",
    "        \n",
    "        if lslr_key not in self.datasets:\n",
    "            print(f\"Dataset '{lslr_key}' not found. Available: {list(self.datasets.keys())}\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets[lslr_key]\n",
    "        \n",
    "        print(f\"\\nAnalyzing {lslr_key}:\")\n",
    "        print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "        print(f\"  Coordinates: {list(ds.coords)}\")\n",
    "        print(f\"  Dimensions: {dict(ds.dims)}\")\n",
    "        \n",
    "        # Find LSLR variable\n",
    "        lslr_vars = [v for v in ds.data_vars if 'lslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "        if not lslr_vars:\n",
    "            print(f\"No LSLR variable found. Available variables: {list(ds.data_vars)}\")\n",
    "            return\n",
    "        \n",
    "        lslr_var = lslr_vars[0]\n",
    "        print(f\"  Using variable: {lslr_var}\")\n",
    "        lslr_data = ds[lslr_var]\n",
    "        print(f\"  Shape: {lslr_data.shape}\")\n",
    "        print(f\"  Dims: {lslr_data.dims}\")\n",
    "        \n",
    "        # Check for spatial dimensions\n",
    "        lat_names = ['lat', 'latitude', 'y']\n",
    "        lon_names = ['lon', 'longitude', 'x']\n",
    "        \n",
    "        lat_dim = None\n",
    "        lon_dim = None\n",
    "        \n",
    "        for name in lat_names:\n",
    "            if name in lslr_data.dims or name in ds.coords:\n",
    "                lat_dim = name\n",
    "                break\n",
    "        \n",
    "        for name in lon_names:\n",
    "            if name in lslr_data.dims or name in ds.coords:\n",
    "                lon_dim = name\n",
    "                break\n",
    "        \n",
    "        if lat_dim is None or lon_dim is None:\n",
    "            print(f\"⚠ No spatial dimensions found (lat/lon)\")\n",
    "            print(f\"  This dataset appears to be for specific locations only\")\n",
    "            \n",
    "            # Try to read location file if referenced\n",
    "            if 'location' in ds.dims or 'locations' in ds.dims:\n",
    "                return self.plot_lslr_location_points(component, year, sample_idx, figsize)\n",
    "            \n",
    "            return\n",
    "        \n",
    "        print(f\"  Spatial dims: lat={lat_dim}, lon={lon_dim}\")\n",
    "        \n",
    "        # Get coordinates\n",
    "        lats = ds[lat_dim].values\n",
    "        lons = ds[lon_dim].values\n",
    "        \n",
    "        print(f\"  Lat range: [{np.min(lats):.2f}, {np.max(lats):.2f}]\")\n",
    "        print(f\"  Lon range: [{np.min(lons):.2f}, {np.max(lons):.2f}]\")\n",
    "        \n",
    "        # Get time dimension\n",
    "        time_dim = 'years' if 'years' in lslr_data.dims else 'year' if 'year' in lslr_data.dims else 'time'\n",
    "        sample_dim = 'samples' if 'samples' in lslr_data.dims else 'sample' if 'sample' in lslr_data.dims else 'ensemble'\n",
    "        \n",
    "        # Find target year\n",
    "        if time_dim in lslr_data.dims:\n",
    "            years = ds[time_dim].values\n",
    "            year_idx = np.argmin(np.abs(years - year))\n",
    "            actual_year = years[year_idx]\n",
    "            print(f\"  Using year: {actual_year} (requested: {year})\")\n",
    "        else:\n",
    "            year_idx = 0\n",
    "            actual_year = year\n",
    "        \n",
    "        # Determine which sample to plot\n",
    "        if sample_dim in lslr_data.dims:\n",
    "            n_samples = lslr_data.sizes[sample_dim]\n",
    "            print(f\"  Number of samples: {n_samples}\")\n",
    "            \n",
    "            if sample_idx is None:\n",
    "                # Use mean across samples\n",
    "                if time_dim in lslr_data.dims:\n",
    "                    data_to_plot = lslr_data.isel({time_dim: year_idx}).mean(dim=sample_dim)\n",
    "                else:\n",
    "                    data_to_plot = lslr_data.mean(dim=sample_dim)\n",
    "                title_suffix = \"Mean\"\n",
    "            else:\n",
    "                # Use specific sample\n",
    "                if time_dim in lslr_data.dims:\n",
    "                    data_to_plot = lslr_data.isel({time_dim: year_idx, sample_dim: sample_idx})\n",
    "                else:\n",
    "                    data_to_plot = lslr_data.isel({sample_dim: sample_idx})\n",
    "                title_suffix = f\"Sample {sample_idx}\"\n",
    "        else:\n",
    "            if time_dim in lslr_data.dims:\n",
    "                data_to_plot = lslr_data.isel({time_dim: year_idx})\n",
    "            else:\n",
    "                data_to_plot = lslr_data\n",
    "            title_suffix = \"Single Value\"\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3, height_ratios=[2, 1])\n",
    "        \n",
    "        # Main map\n",
    "        ax_map = fig.add_subplot(gs[0, :], projection=ccrs.PlateCarree())\n",
    "        \n",
    "        # Plot the data\n",
    "        data_values = data_to_plot.values\n",
    "        \n",
    "        # Handle different data shapes\n",
    "        if data_values.ndim > 2:\n",
    "            data_values = data_values.squeeze()\n",
    "        \n",
    "        print(f\"  Plotting data shape: {data_values.shape}\")\n",
    "        print(f\"  Data range: [{np.nanmin(data_values):.2f}, {np.nanmax(data_values):.2f}] mm\")\n",
    "        \n",
    "        # Create mesh for plotting\n",
    "        if len(lats.shape) == 1 and len(lons.shape) == 1:\n",
    "            # 1D coordinates - create meshgrid\n",
    "            lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "        else:\n",
    "            # Already 2D\n",
    "            lon_grid, lat_grid = lons, lats\n",
    "        \n",
    "        # Plot filled contours\n",
    "        levels = np.linspace(np.nanmin(data_values), np.nanmax(data_values), 20)\n",
    "        cf = ax_map.contourf(lon_grid, lat_grid, data_values, levels=levels,\n",
    "                             cmap='RdYlBu_r', transform=ccrs.PlateCarree(),\n",
    "                             extend='both')\n",
    "        \n",
    "        # Add contour lines\n",
    "        cs = ax_map.contour(lon_grid, lat_grid, data_values, levels=10,\n",
    "                            colors='black', linewidths=0.5, alpha=0.3,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "        ax_map.clabel(cs, inline=True, fontsize=8, fmt='%1.0f')\n",
    "        \n",
    "        # Add geographic features\n",
    "        ax_map.coastlines(resolution='50m', linewidth=1)\n",
    "        ax_map.add_feature(cfeature.BORDERS, linewidth=0.5, alpha=0.5)\n",
    "        ax_map.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3, zorder=0)\n",
    "        \n",
    "        # Grid lines\n",
    "        gl = ax_map.gridlines(draw_labels=True, linewidth=0.5, alpha=0.5, linestyle='--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(cf, ax=ax_map, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "        cbar.set_label('Local Sea Level Rise (mm)', fontsize=12)\n",
    "        \n",
    "        # Set extent\n",
    "        extent = [np.min(lons)-5, np.max(lons)+5, np.min(lats)-5, np.max(lats)+5]\n",
    "        ax_map.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        component_name = component.upper()\n",
    "        ax_map.set_title(f'{component_name} Local SLR at {actual_year} ({title_suffix})',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Histogram of values\n",
    "        ax_hist = fig.add_subplot(gs[1, 0])\n",
    "        valid_data = data_values[~np.isnan(data_values)].flatten()\n",
    "        ax_hist.hist(valid_data, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        ax_hist.axvline(np.mean(valid_data), color='red', linestyle='--', linewidth=2,\n",
    "                        label=f'Mean: {np.mean(valid_data):.1f} mm')\n",
    "        ax_hist.axvline(np.median(valid_data), color='darkred', linestyle=':', linewidth=2,\n",
    "                        label=f'Median: {np.median(valid_data):.1f} mm')\n",
    "        ax_hist.set_xlabel('Local SLR (mm)')\n",
    "        ax_hist.set_ylabel('Frequency')\n",
    "        ax_hist.set_title('Distribution of SLR Values', fontsize=12, fontweight='bold')\n",
    "        ax_hist.legend()\n",
    "        ax_hist.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Statistics box\n",
    "        ax_stats = fig.add_subplot(gs[1, 1])\n",
    "        ax_stats.axis('off')\n",
    "        \n",
    "        stats_text = f\"\"\"\n",
    "        Statistics for {actual_year}:\n",
    "        \n",
    "        Mean:     {np.mean(valid_data):.2f} mm\n",
    "        Median:   {np.median(valid_data):.2f} mm\n",
    "        Std Dev:  {np.std(valid_data):.2f} mm\n",
    "        Min:      {np.min(valid_data):.2f} mm\n",
    "        Max:      {np.max(valid_data):.2f} mm\n",
    "        \n",
    "        5th %ile: {np.percentile(valid_data, 5):.2f} mm\n",
    "        95th %ile:{np.percentile(valid_data, 95):.2f} mm\n",
    "        \n",
    "        Grid points: {len(valid_data)}\n",
    "        Lat range: [{np.min(lats):.1f}°, {np.max(lats):.1f}°]\n",
    "        Lon range: [{np.min(lons):.1f}°, {np.max(lons):.1f}°]\n",
    "        \"\"\"\n",
    "        \n",
    "        ax_stats.text(0.1, 0.9, stats_text, transform=ax_stats.transAxes,\n",
    "                      fontsize=10, verticalalignment='top', family='monospace',\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "        \n",
    "        plt.suptitle(f'Local Sea Level Rise - {component_name}',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    \n",
    "    def plot_lslr_all_components_map(self, year=2100, figsize=(18, 14)):\n",
    "        \"\"\"Plot maps for all available LSLR components\"\"\"\n",
    "        \n",
    "        components = ['lws', 'stereo', 'ice']\n",
    "        available = []\n",
    "        \n",
    "        for comp in components:\n",
    "            key = f'{comp}_lslr'\n",
    "            if key in self.datasets:\n",
    "                available.append(comp)\n",
    "        \n",
    "        if not available:\n",
    "            print(\"No LSLR components available\")\n",
    "            return\n",
    "        \n",
    "        n_comp = len(available)\n",
    "        fig, axes = plt.subplots(n_comp, 1, figsize=(figsize[0], figsize[1]*n_comp/3),\n",
    "                                subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        \n",
    "        if n_comp == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, comp in enumerate(available):\n",
    "            print(f\"\\nPlotting {comp}...\")\n",
    "            # This is a simplified version - you'd need to adapt based on your data structure\n",
    "            ax = axes[idx]\n",
    "            ax.text(0.5, 0.5, f'{comp.upper()} LSLR - See individual plots',\n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=14)\n",
    "            ax.set_title(f'{comp.upper()} Component', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    def plot_gslr_map(self, component='lws', year=2100, sample_idx=None, figsize=(16, 12)):\n",
    "        \"\"\"Plot GSLR data - if it has spatial structure, otherwise show global value\"\"\"\n",
    "        \n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        \n",
    "        gslr_key = f'{component}_gslr'\n",
    "        \n",
    "        if gslr_key not in self.datasets:\n",
    "            print(f\"Dataset '{gslr_key}' not found. Available: {list(self.datasets.keys())}\")\n",
    "            return\n",
    "        \n",
    "        ds = self.datasets[gslr_key]\n",
    "        \n",
    "        print(f\"\\nAnalyzing {gslr_key}:\")\n",
    "        print(f\"  Variables: {list(ds.data_vars)}\")\n",
    "        print(f\"  Coordinates: {list(ds.coords)}\")\n",
    "        print(f\"  Dimensions: {dict(ds.dims)}\")\n",
    "        \n",
    "        # Find GSLR variable\n",
    "        gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "        if not gslr_vars:\n",
    "            print(f\"No GSLR variable found. Available variables: {list(ds.data_vars)}\")\n",
    "            return\n",
    "        \n",
    "        gslr_var = gslr_vars[0]\n",
    "        print(f\"  Using variable: {gslr_var}\")\n",
    "        gslr_data = ds[gslr_var]\n",
    "        print(f\"  Shape: {gslr_data.shape}\")\n",
    "        print(f\"  Dims: {gslr_data.dims}\")\n",
    "        \n",
    "        # Check for spatial dimensions\n",
    "        lat_names = ['lat', 'latitude', 'y']\n",
    "        lon_names = ['lon', 'longitude', 'x']\n",
    "        \n",
    "        lat_dim = None\n",
    "        lon_dim = None\n",
    "        \n",
    "        for name in lat_names:\n",
    "            if name in gslr_data.dims or name in ds.coords:\n",
    "                lat_dim = name\n",
    "                break\n",
    "        \n",
    "        for name in lon_names:\n",
    "            if name in gslr_data.dims or name in ds.coords:\n",
    "                lon_dim = name\n",
    "                break\n",
    "        \n",
    "        # GSLR is typically global (no spatial variation)\n",
    "        if lat_dim is None and lon_dim is None:\n",
    "            print(f\"  ✓ This is Global SLR (uniform value worldwide)\")\n",
    "            return self.plot_gslr_global_value(component, year, sample_idx, figsize)\n",
    "        else:\n",
    "            print(f\"  ✓ This GSLR has spatial structure\")\n",
    "            print(f\"    Spatial dims: lat={lat_dim}, lon={lon_dim}\")\n",
    "            # Continue with spatial plotting below\n",
    "            \n",
    "        # Get coordinates\n",
    "        lats = ds[lat_dim].values\n",
    "        lons = ds[lon_dim].values\n",
    "        \n",
    "        print(f\"  Lat range: [{np.min(lats):.2f}, {np.max(lats):.2f}]\")\n",
    "        print(f\"  Lon range: [{np.min(lons):.2f}, {np.max(lons):.2f}]\")\n",
    "        \n",
    "        # Get time and sample dimensions\n",
    "        time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "        sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else 'ensemble'\n",
    "        \n",
    "        # Find target year\n",
    "        if time_dim in gslr_data.dims:\n",
    "            years = ds[time_dim].values\n",
    "            year_idx = np.argmin(np.abs(years - year))\n",
    "            actual_year = years[year_idx]\n",
    "            print(f\"  Using year: {actual_year} (requested: {year})\")\n",
    "        else:\n",
    "            year_idx = 0\n",
    "            actual_year = year\n",
    "        \n",
    "        # Determine which sample to plot\n",
    "        if sample_dim in gslr_data.dims:\n",
    "            n_samples = gslr_data.sizes[sample_dim]\n",
    "            print(f\"  Number of samples: {n_samples}\")\n",
    "            \n",
    "            if sample_idx is None:\n",
    "                # Use mean across samples\n",
    "                if time_dim in gslr_data.dims:\n",
    "                    data_to_plot = gslr_data.isel({time_dim: year_idx}).mean(dim=sample_dim)\n",
    "                else:\n",
    "                    data_to_plot = gslr_data.mean(dim=sample_dim)\n",
    "                title_suffix = \"Mean\"\n",
    "            else:\n",
    "                # Use specific sample\n",
    "                if time_dim in gslr_data.dims:\n",
    "                    data_to_plot = gslr_data.isel({time_dim: year_idx, sample_dim: sample_idx})\n",
    "                else:\n",
    "                    data_to_plot = gslr_data.isel({sample_dim: sample_idx})\n",
    "                title_suffix = f\"Sample {sample_idx}\"\n",
    "        else:\n",
    "            if time_dim in gslr_data.dims:\n",
    "                data_to_plot = gslr_data.isel({time_dim: year_idx})\n",
    "            else:\n",
    "                data_to_plot = gslr_data\n",
    "            title_suffix = \"Single Value\"\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3, height_ratios=[2, 1])\n",
    "        \n",
    "        # Main map\n",
    "        ax_map = fig.add_subplot(gs[0, :], projection=ccrs.PlateCarree())\n",
    "        \n",
    "        # Plot the data\n",
    "        data_values = data_to_plot.values\n",
    "        \n",
    "        if data_values.ndim > 2:\n",
    "            data_values = data_values.squeeze()\n",
    "        \n",
    "        print(f\"  Plotting data shape: {data_values.shape}\")\n",
    "        print(f\"  Data range: [{np.nanmin(data_values):.2f}, {np.nanmax(data_values):.2f}] mm\")\n",
    "        \n",
    "        # Create mesh for plotting\n",
    "        if len(lats.shape) == 1 and len(lons.shape) == 1:\n",
    "            lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "        else:\n",
    "            lon_grid, lat_grid = lons, lats\n",
    "        \n",
    "        # Plot filled contours\n",
    "        levels = np.linspace(np.nanmin(data_values), np.nanmax(data_values), 20)\n",
    "        cf = ax_map.contourf(lon_grid, lat_grid, data_values, levels=levels,\n",
    "                             cmap='RdYlBu_r', transform=ccrs.PlateCarree(),\n",
    "                             extend='both')\n",
    "        \n",
    "        # Add contour lines\n",
    "        cs = ax_map.contour(lon_grid, lat_grid, data_values, levels=10,\n",
    "                            colors='black', linewidths=0.5, alpha=0.3,\n",
    "                            transform=ccrs.PlateCarree())\n",
    "        ax_map.clabel(cs, inline=True, fontsize=8, fmt='%1.0f')\n",
    "        \n",
    "        # Add geographic features\n",
    "        ax_map.coastlines(resolution='50m', linewidth=1)\n",
    "        ax_map.add_feature(cfeature.BORDERS, linewidth=0.5, alpha=0.5)\n",
    "        ax_map.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.2, zorder=0)\n",
    "        \n",
    "        # Grid lines\n",
    "        gl = ax_map.gridlines(draw_labels=True, linewidth=0.5, alpha=0.5, linestyle='--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(cf, ax=ax_map, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "        cbar.set_label('Global Sea Level Rise (mm)', fontsize=12)\n",
    "        \n",
    "        # Set extent\n",
    "        ax_map.set_global()\n",
    "        \n",
    "        component_name = component.upper()\n",
    "        ax_map.set_title(f'{component_name} Global SLR at {actual_year} ({title_suffix})',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Histogram\n",
    "        ax_hist = fig.add_subplot(gs[1, 0])\n",
    "        valid_data = data_values[~np.isnan(data_values)].flatten()\n",
    "        ax_hist.hist(valid_data, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        ax_hist.axvline(np.mean(valid_data), color='red', linestyle='--', linewidth=2,\n",
    "                        label=f'Mean: {np.mean(valid_data):.1f} mm')\n",
    "        ax_hist.set_xlabel('Global SLR (mm)')\n",
    "        ax_hist.set_ylabel('Frequency')\n",
    "        ax_hist.set_title('Distribution', fontsize=12, fontweight='bold')\n",
    "        ax_hist.legend()\n",
    "        ax_hist.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Statistics\n",
    "        ax_stats = fig.add_subplot(gs[1, 1])\n",
    "        ax_stats.axis('off')\n",
    "        \n",
    "        stats_text = f\"\"\"\n",
    "        Global SLR Statistics ({actual_year}):\n",
    "        \n",
    "        Mean:     {np.mean(valid_data):.2f} mm\n",
    "        Std Dev:  {np.std(valid_data):.2f} mm\n",
    "        Min:      {np.min(valid_data):.2f} mm\n",
    "        Max:      {np.max(valid_data):.2f} mm\n",
    "        \n",
    "        5th %ile: {np.percentile(valid_data, 5):.2f} mm\n",
    "        95th %ile:{np.percentile(valid_data, 95):.2f} mm\n",
    "        \n",
    "        Grid points: {len(valid_data)}\n",
    "        \"\"\"\n",
    "        \n",
    "        ax_stats.text(0.1, 0.9, stats_text, transform=ax_stats.transAxes,\n",
    "                      fontsize=10, verticalalignment='top', family='monospace',\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "        \n",
    "        plt.suptitle(f'Global Sea Level Rise - {component_name}',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def plot_gslr_global_value(self, component='lws', year=2100, sample_idx=None, figsize=(16, 10)):\n",
    "        \"\"\"Plot GSLR as a global uniform value (typical case)\"\"\"\n",
    "        \n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        \n",
    "        gslr_key = f'{component}_gslr'\n",
    "        ds = self.datasets[gslr_key]\n",
    "        \n",
    "        # Find GSLR variable\n",
    "        gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "        gslr_var = gslr_vars[0]\n",
    "        gslr_data = ds[gslr_var]\n",
    "        \n",
    "        # Get time and sample dimensions\n",
    "        time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "        sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else 'ensemble'\n",
    "        \n",
    "        # Find target year\n",
    "        if time_dim in gslr_data.dims:\n",
    "            years = ds[time_dim].values\n",
    "            year_idx = np.argmin(np.abs(years - year))\n",
    "            actual_year = years[year_idx]\n",
    "            gslr_at_year = gslr_data.isel({time_dim: year_idx})\n",
    "        else:\n",
    "            actual_year = year\n",
    "            gslr_at_year = gslr_data\n",
    "        \n",
    "        # Handle samples\n",
    "        if sample_dim in gslr_at_year.dims:\n",
    "            n_samples = gslr_at_year.sizes[sample_dim]\n",
    "            \n",
    "            if sample_idx is None:\n",
    "                gslr_value = gslr_at_year.mean(dim=sample_dim).values.item()\n",
    "                print (\"\\n Raw mean gslr_value = \", gslr_value, \"\\n\")\n",
    "                gslr_ensemble = gslr_at_year.values.flatten()\n",
    "                title_suffix = \"Ensemble Mean\"\n",
    "            else:\n",
    "                gslr_value = gslr_at_year.isel({sample_dim: sample_idx}).values.item()\n",
    "                gslr_ensemble = gslr_at_year.values.flatten()\n",
    "                title_suffix = f\"Sample {sample_idx}\"\n",
    "        else:\n",
    "            gslr_value = gslr_at_year.values.item()\n",
    "            gslr_ensemble = None\n",
    "            title_suffix = \"Single Value\"\n",
    "        \n",
    "        print(f\"  GSLR value at {actual_year}: {gslr_value:.2f} mm\")\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.3)\n",
    "        \n",
    "        # World map showing uniform value\n",
    "        ax_map = fig.add_subplot(gs[0, :], projection=ccrs.Robinson())\n",
    "        ax_map.set_global()\n",
    "        \n",
    "        # Create a uniform field for visualization\n",
    "        lons = np.linspace(-180, 180, 360)\n",
    "        lats = np.linspace(-90, 90, 180)\n",
    "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "        uniform_field = np.ones_like(lon_grid) * gslr_value\n",
    "        \n",
    "        # Plot uniform value\n",
    "        cf = ax_map.contourf(lon_grid, lat_grid, uniform_field,\n",
    "                             levels=np.linspace(gslr_value*0.95, gslr_value*1.05, 10),\n",
    "                             cmap='RdYlBu_r', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        # Add geographic features\n",
    "        ax_map.coastlines(resolution='110m', linewidth=1)\n",
    "        ax_map.add_feature(cfeature.BORDERS, linewidth=0.5, alpha=0.5)\n",
    "        ax_map.add_feature(cfeature.LAND, edgecolor='black', facecolor='none', linewidth=0.5)\n",
    "        \n",
    "        # Colorbar\n",
    "        cbar = plt.colorbar(cf, ax=ax_map, orientation='horizontal', pad=0.05, shrink=0.6)\n",
    "        cbar.set_label('Global Sea Level Rise (mm)', fontsize=12)\n",
    "        \n",
    "        # Add text annotation\n",
    "        ax_map.text(0.5, 0.5, f'GSLR: {gslr_value:.1f} mm', transform=ax_map.transAxes,\n",
    "                   fontsize=24, fontweight='bold', ha='center', va='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8, edgecolor='black', linewidth=2))\n",
    "        \n",
    "        component_name = component.upper()\n",
    "        ax_map.set_title(f'{component_name} Global SLR at {actual_year} ({title_suffix})\\n(Uniform worldwide value)',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Time series\n",
    "        ax_ts = fig.add_subplot(gs[1, 0])\n",
    "        \n",
    "        if time_dim in gslr_data.dims:\n",
    "            years_all = ds[time_dim].values\n",
    "            \n",
    "            if sample_dim in gslr_data.dims:\n",
    "                # Plot ensemble members\n",
    "                for i in range(min(10, gslr_data.sizes[sample_dim])):\n",
    "                    sample_data = gslr_data.isel({sample_dim: i}).values.squeeze()\n",
    "                    ax_ts.plot(years_all, sample_data, alpha=0.3, color='blue', linewidth=0.5)\n",
    "                \n",
    "                mean = gslr_data.mean(dim=sample_dim).values.squeeze()\n",
    "                ax_ts.plot(years_all, mean, color='darkblue', linewidth=2.5, label='Ensemble Mean')\n",
    "            else:\n",
    "                values = gslr_data.values.squeeze()\n",
    "                ax_ts.plot(years_all, values, color='darkblue', linewidth=2.5)\n",
    "            \n",
    "            # Mark current year\n",
    "            ax_ts.axvline(x=actual_year, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            ax_ts.plot(actual_year, gslr_value, 'r*', markersize=20, markeredgecolor='black', \n",
    "                      markeredgewidth=1.5, zorder=5)\n",
    "            \n",
    "            ax_ts.set_xlabel('Year')\n",
    "            ax_ts.set_ylabel('Global SLR (mm)')\n",
    "            ax_ts.set_title('Time Series Evolution', fontsize=12, fontweight='bold')\n",
    "            ax_ts.legend()\n",
    "            ax_ts.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax_ts.text(0.5, 0.5, 'No time series available', ha='center', va='center',\n",
    "                      transform=ax_ts.transAxes)\n",
    "        \n",
    "        # Ensemble distribution (if available)\n",
    "        ax_dist = fig.add_subplot(gs[1, 1])\n",
    "        \n",
    "        if gslr_ensemble is not None and len(gslr_ensemble) > 1:\n",
    "            ax_dist.hist(gslr_ensemble, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "            ax_dist.axvline(gslr_value, color='red', linestyle='--', linewidth=2,\n",
    "                           label=f'Mean: {gslr_value:.1f} mm')\n",
    "            ax_dist.axvline(np.median(gslr_ensemble), color='darkred', linestyle=':', linewidth=2,\n",
    "                           label=f'Median: {np.median(gslr_ensemble):.1f} mm')\n",
    "            \n",
    "            ax_dist.set_xlabel('Global SLR (mm)')\n",
    "            ax_dist.set_ylabel('Frequency')\n",
    "            ax_dist.set_title(f'Ensemble Distribution at {actual_year}', fontsize=12, fontweight='bold')\n",
    "            ax_dist.legend()\n",
    "            ax_dist.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistics text\n",
    "            stats_text = f\"\"\"\n",
    "            Statistics:\n",
    "            \n",
    "            Mean:   {np.mean(gslr_ensemble):.2f} mm\n",
    "            Median: {np.median(gslr_ensemble):.2f} mm\n",
    "            Std:    {np.std(gslr_ensemble):.2f} mm\n",
    "            Min:    {np.min(gslr_ensemble):.2f} mm\n",
    "            Max:    {np.max(gslr_ensemble):.2f} mm\n",
    "            \n",
    "            5th:    {np.percentile(gslr_ensemble, 5):.2f} mm\n",
    "            95th:   {np.percentile(gslr_ensemble, 95):.2f} mm\n",
    "            \n",
    "            N samples: {len(gslr_ensemble)}\n",
    "            \"\"\"\n",
    "            \n",
    "            ax_dist.text(1.05, 0.5, stats_text, transform=ax_dist.transAxes,\n",
    "                        fontsize=9, verticalalignment='center', family='monospace',\n",
    "                        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        else:\n",
    "            ax_dist.text(0.5, 0.5, f'Single value:\\n{gslr_value:.2f} mm',\n",
    "                        ha='center', va='center', transform=ax_dist.transAxes,\n",
    "                        fontsize=16, fontweight='bold',\n",
    "                        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "            ax_dist.set_title('Value at Target Year', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(f'Global Sea Level Rise - {component_name}\\n(Note: GSLR is globally uniform - same value everywhere)',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_gslr_all_components(self, year=2100, figsize=(18, 12)):\n",
    "        \"\"\"Plot GSLR for all available components on one figure\"\"\"\n",
    "        \n",
    "        import cartopy.crs as ccrs\n",
    "        import cartopy.feature as cfeature\n",
    "        \n",
    "        components = ['lws', 'stereo', 'ice']\n",
    "        available = []\n",
    "        gslr_values = {}\n",
    "        \n",
    "        for comp in components:\n",
    "            key = f'{comp}_gslr'\n",
    "            if key in self.datasets:\n",
    "                ds = self.datasets[key]\n",
    "                gslr_vars = [v for v in ds.data_vars if 'gslr' in v.lower() or 'slr' in v.lower() or 'sea_level' in v.lower()]\n",
    "                if gslr_vars:\n",
    "                    available.append(comp)\n",
    "                    \n",
    "                    # Get value at target year\n",
    "                    gslr_var = gslr_vars[0]\n",
    "                    gslr_data = ds[gslr_var]\n",
    "                    \n",
    "                    time_dim = 'years' if 'years' in gslr_data.dims else 'year' if 'year' in gslr_data.dims else 'time'\n",
    "                    sample_dim = 'samples' if 'samples' in gslr_data.dims else 'sample' if 'sample' in gslr_data.dims else None\n",
    "                    \n",
    "                    if time_dim in gslr_data.dims:\n",
    "                        years = ds[time_dim].values\n",
    "                        year_idx = np.argmin(np.abs(years - year))\n",
    "                        gslr_at_year = gslr_data.isel({time_dim: year_idx})\n",
    "                    else:\n",
    "                        gslr_at_year = gslr_data\n",
    "                    \n",
    "                    if sample_dim and sample_dim in gslr_at_year.dims:\n",
    "                        value = gslr_at_year.mean(dim=sample_dim).values.item()\n",
    "                        ensemble = gslr_at_year.values.flatten()\n",
    "                    else:\n",
    "                        value = gslr_at_year.values.item()\n",
    "                        ensemble = None\n",
    "                    \n",
    "                    gslr_values[comp] = (value, ensemble)\n",
    "        \n",
    "        if not available:\n",
    "            print(\"No GSLR data available\")\n",
    "            return\n",
    "        \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # World map with all components\n",
    "        ax_map = fig.add_subplot(gs[0, :], projection=ccrs.Robinson())\n",
    "        ax_map.set_global()\n",
    "        ax_map.coastlines(resolution='110m', linewidth=1)\n",
    "        ax_map.add_feature(cfeature.BORDERS, linewidth=0.5, alpha=0.5)\n",
    "        ax_map.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.2)\n",
    "        \n",
    "        # Display values\n",
    "        colors = ['blue', 'green', 'orange']\n",
    "        y_pos = 0.7\n",
    "        \n",
    "        for idx, comp in enumerate(available):\n",
    "            value, _ = gslr_values[comp]\n",
    "            comp_name = comp.upper()\n",
    "            ax_map.text(0.5, y_pos, f'{comp_name}: {value:.1f} mm',\n",
    "                       transform=ax_map.transAxes, fontsize=16, fontweight='bold',\n",
    "                       ha='center', color=colors[idx],\n",
    "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor=colors[idx], linewidth=2))\n",
    "            y_pos -= 0.15\n",
    "        \n",
    "        # Total\n",
    "        total_value = sum([v[0] for v in gslr_values.values()])\n",
    "        ax_map.text(0.5, y_pos, f'TOTAL: {total_value:.1f} mm',\n",
    "                   transform=ax_map.transAxes, fontsize=18, fontweight='bold',\n",
    "                   ha='center', color='red',\n",
    "                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.9, edgecolor='red', linewidth=3))\n",
    "        \n",
    "        ax_map.set_title(f'Global Sea Level Rise Components at {year}',\n",
    "                         fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Bar chart comparison\n",
    "        ax_bar = fig.add_subplot(gs[1, 0])\n",
    "        \n",
    "        comp_names = [c.upper() for c in available] + ['TOTAL']\n",
    "        values = [gslr_values[c][0] for c in available] + [total_value]\n",
    "        colors_bar = colors[:len(available)] + ['red']\n",
    "        \n",
    "        bars = ax_bar.bar(comp_names, values, color=colors_bar, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            ax_bar.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{val:.1f} mm', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        ax_bar.set_ylabel('Sea Level Rise (mm)', fontsize=12)\n",
    "        ax_bar.set_title('Component Comparison', fontsize=12, fontweight='bold')\n",
    "        ax_bar.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Pie chart of contributions\n",
    "        ax_pie = fig.add_subplot(gs[1, 1])\n",
    "        \n",
    "        contrib_values = [gslr_values[c][0] for c in available]\n",
    "        contrib_labels = [f'{c.upper()}\\n{v:.1f} mm\\n({v/total_value*100:.1f}%)' \n",
    "                         for c, v in zip(available, contrib_values)]\n",
    "        \n",
    "        ax_pie.pie(contrib_values, labels=contrib_labels, colors=colors[:len(available)],\n",
    "                  autopct='', startangle=90, textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "        ax_pie.set_title(f'Relative Contributions\\n(Total: {total_value:.1f} mm)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(f'Global Sea Level Rise - All Components',\n",
    "                     fontsize=18, fontweight='bold')\n",
    "        \n",
    "        return fig    \n",
    "# ==================== USAGE ====================\n",
    "\n",
    "# Initialize visualizer\n",
    "viz = FACTSeaLevelVisualizer('./data/output')\n",
    "\n",
    "# Load all datasets\n",
    "datasets = viz.load_outputs()\n",
    "\n",
    "if datasets:\n",
    "    viz.diagnose_datasets()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Generating visualizations...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 12. Plot GSLR maps\n",
    "    print(\"\\n12. Plotting GSLR maps...\")\n",
    "    \n",
    "    # Individual components\n",
    "    for component in ['lws', 'stereo', 'ice']:\n",
    "        key = f'{component}_gslr'\n",
    "        if key in viz.datasets:\n",
    "            print(f\"\\n  Plotting {component} GSLR...\")\n",
    "            fig12 = viz.plot_gslr_map(component=component, year=2100, sample_idx=None)\n",
    "            if fig12:\n",
    "                plt.savefig(f'gslr_map_{component}.png', dpi=300, bbox_inches='tight')\n",
    "                print(f\"   ✓ Saved: gslr_map_{component}.png\")\n",
    "    \n",
    "    # All components together\n",
    "    print(\"\\n  Plotting all GSLR components together...\")\n",
    "    fig12_all = viz.plot_gslr_all_components(year=2100)\n",
    "    if fig12_all:\n",
    "        plt.savefig('gslr_all_components.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"   ✓ Saved: gslr_all_components.png\")\n",
    "    \n",
    "    # 11. Plot LSLR spatial maps\n",
    "    print(\"\\n11. Plotting LSLR spatial maps...\")\n",
    "    \n",
    "    # Try each component\n",
    "    for component in ['lws', 'stereo', 'ice']:\n",
    "        print(f\"\\n  Plotting {component} LSLR...\")\n",
    "        fig11 = viz.plot_lslr_spatial_map(component=component, year=2100, sample_idx=None)\n",
    "        if fig11:\n",
    "            plt.savefig(f'lslr_map_{component}.png', dpi=300, bbox_inches='tight')\n",
    "            print(f\"   ✓ Saved: lslr_map_{component}.png\")\n",
    "    # exit()\n",
    "    \n",
    "    # # 1. Climate variables\n",
    "    # print(\"\\n1. Plotting climate variables...\")\n",
    "    # fig1 = viz.plot_climate_variables(scenario='ssp585')\n",
    "    # if fig1:\n",
    "    #     plt.savefig('climate_outputs.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: climate_outputs.png\")\n",
    "    \n",
    "    # # 1b. Latest climate snapshot\n",
    "    # print(\"\\n1b. Plotting climate latest snapshot...\")\n",
    "    # fig1b = viz.plot_climate_latest_snapshot(scenario='ssp585')\n",
    "    # if fig1b:\n",
    "    #     plt.savefig('climate_latest_snapshot.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: climate_latest_snapshot.png\")\n",
    "    \n",
    "    # # 1c. Climate evolution to latest\n",
    "    # print(\"\\n1c. Plotting climate evolution to latest...\")\n",
    "    # fig1c = viz.plot_climate_evolution_to_latest(scenario='ssp585')\n",
    "    # if fig1c:\n",
    "    #     plt.savefig('climate_evolution_to_latest.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: climate_evolution_to_latest.png\")\n",
    "    \n",
    "    # # 1d. Climate heatmap\n",
    "    # print(\"\\n1d. Plotting climate heatmap...\")\n",
    "    # fig1d = viz.plot_climate_heatmap_over_time(scenario='ssp585')\n",
    "    # if fig1d:\n",
    "    #     plt.savefig('climate_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: climate_heatmap.png\")\n",
    "\n",
    "    # # 2. Sea level components comparison\n",
    "    # print(\"\\n2. Plotting sea level components...\")\n",
    "    # fig2 = viz.plot_sea_level_components_comparison(year=2100)\n",
    "    # if fig2:\n",
    "    #     plt.savefig('slr_components_2100.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: slr_components_2100.png\")\n",
    "    \n",
    "    # # 3. Stacked contributions\n",
    "    # print(\"\\n3. Plotting stacked contributions...\")\n",
    "    # fig3 = viz.plot_slr_stacked_contributions()\n",
    "    # if fig3:\n",
    "    #     plt.savefig('slr_stacked.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: slr_stacked.png\")\n",
    "    \n",
    "    # # 4. Summary dashboard\n",
    "    # print(\"\\n4. Creating summary dashboard...\")\n",
    "    # fig4 = viz.create_summary_dashboard(year=2100, scenario='ssp585')\n",
    "    # if fig4:\n",
    "    #     plt.savefig('summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: summary_dashboard.png\")\n",
    "    \n",
    "    # # 5. Individual GSLR components\n",
    "    # print(\"\\n5. Plotting individual GSLR components...\")\n",
    "    # fig5 = viz.plot_individual_gslr_components(year=2100)\n",
    "    # if fig5:\n",
    "    #     plt.savefig('individual_gslr_components.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: individual_gslr_components.png\")\n",
    "    \n",
    "    # # 6. GSLR differences\n",
    "    # print(\"\\n6. Plotting GSLR differences...\")\n",
    "    # fig6 = viz.plot_gslr_differences(year=2100)\n",
    "    # if fig6:\n",
    "    #     plt.savefig('gslr_differences.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: gslr_differences.png\")\n",
    "    \n",
    "    # # 7. GSLR correlation matrix\n",
    "    # print(\"\\n7. Plotting GSLR correlation matrix...\")\n",
    "    # fig7 = viz.plot_gslr_correlation_matrix(year=2100)\n",
    "    # if fig7:\n",
    "    #     plt.savefig('gslr_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    #     print(\"   ✓ Saved: gslr_correlation.png\")\n",
    "    \n",
    "    # # 8. Export statistics\n",
    "    # print(\"\\n8. Exporting statistics...\")\n",
    "    # stats_df = viz.export_statistics(year=2100, scenario='ssp585')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"All visualizations complete!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n⚠ No datasets loaded. Please run the workflow first to generate outputs.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885afb2-70c0-440c-96cd-56e8e8e2d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0a9a2-dd4b-4ced-ae43-e3418409eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable numbagg to avoid NumPy compatibility issues\n",
    "xr.set_options(use_bottleneck=False, use_numbagg=False)\n",
    "\n",
    "def load_sea_level_data(filepath):\n",
    "    \"\"\"Load sea level data from NetCDF file, handling different structures\"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Find the sea level variable (different files may use different names)\n",
    "    possible_names = ['sea_level_change', 'sealevel_change', 'slr', 'sea_level']\n",
    "    var_name = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name in ds.data_vars:\n",
    "            var_name = name\n",
    "            break\n",
    "    \n",
    "    if var_name is None:\n",
    "        # Just take the first non-coordinate variable\n",
    "        data_vars = [v for v in ds.data_vars if v not in ['lat', 'lon']]\n",
    "        if data_vars:\n",
    "            var_name = data_vars[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find sea level variable in {filepath}\")\n",
    "    \n",
    "    data = ds[var_name]\n",
    "    years = ds['years'].values if 'years' in ds else None\n",
    "    \n",
    "    return data, years, ds\n",
    "\n",
    "def align_to_common_years(data_dict, total_years):\n",
    "    \"\"\"\n",
    "    Align all datasets to common years using interpolation or subset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dict : dict\n",
    "        Dictionary with component data and years\n",
    "    total_years : array\n",
    "        Years from the total file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    aligned_dict : dict\n",
    "        Dictionary with aligned data\n",
    "    \"\"\"\n",
    "    aligned = {}\n",
    "    \n",
    "    for comp_name, comp_info in data_dict.items():\n",
    "        comp_data = comp_info['data']\n",
    "        comp_years = comp_info['years']\n",
    "        \n",
    "        print(f\"  Aligning {comp_name}: {len(comp_years)} years -> {len(total_years)} years\")\n",
    "        print(f\"    Component years: {comp_years[0]} to {comp_years[-1]}\")\n",
    "        print(f\"    Total years: {total_years[0]} to {total_years[-1]}\")\n",
    "        \n",
    "        # Check if years match exactly\n",
    "        if len(comp_years) == len(total_years) and np.all(comp_years == total_years):\n",
    "            aligned[comp_name] = comp_info\n",
    "            print(f\"    ✓ Years already match\")\n",
    "            continue\n",
    "        \n",
    "        # Find common years (intersection)\n",
    "        common_years = np.intersect1d(comp_years, total_years)\n",
    "        \n",
    "        if len(common_years) > 0:\n",
    "            # Subset both datasets to common years\n",
    "            comp_year_indices = [np.where(comp_years == y)[0][0] for y in common_years]\n",
    "            \n",
    "            # Get the year dimension name\n",
    "            year_dim = None\n",
    "            for dim in comp_data.dims:\n",
    "                if 'year' in dim.lower():\n",
    "                    year_dim = dim\n",
    "                    break\n",
    "            \n",
    "            if year_dim:\n",
    "                aligned_data = comp_data.isel({year_dim: comp_year_indices})\n",
    "                aligned[comp_name] = {\n",
    "                    'data': aligned_data,\n",
    "                    'years': common_years,\n",
    "                    'ds': comp_info['ds']\n",
    "                }\n",
    "                print(f\"    ✓ Aligned to {len(common_years)} common years\")\n",
    "            else:\n",
    "                print(f\"    ✗ Could not find year dimension\")\n",
    "                aligned[comp_name] = comp_info\n",
    "        else:\n",
    "            print(f\"    ⚠ No common years found, using interpolation\")\n",
    "            # Use xarray interpolation if no common years\n",
    "            aligned[comp_name] = comp_info\n",
    "    \n",
    "    return aligned\n",
    "\n",
    "def verify_totals(output_dir='./data/output', file_type='lslr'):\n",
    "    \"\"\"\n",
    "    Verify that totaled_output_all_{file_type}.nc = sum of individual component files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_dir : str\n",
    "        Directory containing the output files\n",
    "    file_type : str\n",
    "        Either 'lslr' or 'gslr'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"VERIFYING {file_type.upper()} TOTALS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load the totaled file\n",
    "    total_file = Path(output_dir) / f'totaled_output_all_{file_type}.nc'\n",
    "    total_data, total_years, total_ds = load_sea_level_data(total_file)\n",
    "    \n",
    "    print(f\"Loaded total file: {total_file.name}\")\n",
    "    print(f\"  Shape: {total_data.shape}\")\n",
    "    print(f\"  Dimensions: {total_data.dims}\")\n",
    "    print(f\"  Years: {len(total_years)} points from {total_years[0]} to {total_years[-1]}\")\n",
    "    \n",
    "    # Load individual component files\n",
    "    components = ['lws', 'sterodynamics']  # Add 'ice' if you have it\n",
    "    component_data = {}\n",
    "    \n",
    "    for comp in components:\n",
    "        comp_file = Path(output_dir) / comp / f'{file_type}.nc'\n",
    "        if comp_file.exists():\n",
    "            data, years, ds = load_sea_level_data(comp_file)\n",
    "            component_data[comp] = {'data': data, 'years': years, 'ds': ds}\n",
    "            print(f\"Loaded {comp}: {comp_file.name}\")\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dimensions: {data.dims}\")\n",
    "            print(f\"  Years: {len(years)} points from {years[0]} to {years[-1]}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Component file not found: {comp_file}\")\n",
    "    \n",
    "    # Align all data to common years\n",
    "    print(\"\\nAligning data to common years...\")\n",
    "    component_data = align_to_common_years(component_data, total_years)\n",
    "    \n",
    "    # Find actual common years across all datasets\n",
    "    all_years = [total_years]\n",
    "    for comp_info in component_data.values():\n",
    "        all_years.append(comp_info['years'])\n",
    "    \n",
    "    common_years = all_years[0]\n",
    "    for years in all_years[1:]:\n",
    "        common_years = np.intersect1d(common_years, years)\n",
    "    \n",
    "    print(f\"\\nCommon years across all files: {len(common_years)} years\")\n",
    "    print(f\"  Range: {common_years[0]} to {common_years[-1]}\")\n",
    "    \n",
    "    # Subset total data to common years\n",
    "    total_year_indices = [np.where(total_years == y)[0][0] for y in common_years]\n",
    "    \n",
    "    # Squeeze out location dimension if present\n",
    "    if 'locations' in total_data.dims:\n",
    "        total_data_subset = total_data.squeeze('locations')\n",
    "    else:\n",
    "        total_data_subset = total_data\n",
    "    \n",
    "    # Find year dimension in total data\n",
    "    year_dim = None\n",
    "    for dim in total_data_subset.dims:\n",
    "        if 'year' in dim.lower():\n",
    "            year_dim = dim\n",
    "            break\n",
    "    \n",
    "    if year_dim:\n",
    "        total_data_subset = total_data_subset.isel({year_dim: total_year_indices})\n",
    "    \n",
    "    print(f\"Total data subset shape: {total_data_subset.shape}\")\n",
    "    \n",
    "    # Sum components, handling dimension alignment\n",
    "    print(\"\\nCalculating sum of components...\")\n",
    "    manual_sum = None\n",
    "    \n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        comp_years = comp_dict['years']\n",
    "        \n",
    "        # Subset to common years\n",
    "        comp_year_indices = [np.where(comp_years == y)[0][0] for y in common_years]\n",
    "        \n",
    "        # Squeeze locations if present\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        # Find year dimension\n",
    "        year_dim_comp = None\n",
    "        for dim in comp_data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim_comp = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim_comp:\n",
    "            comp_data = comp_data.isel({year_dim_comp: comp_year_indices})\n",
    "        \n",
    "        # Ensure dimensions match total\n",
    "        if comp_data.dims != total_data_subset.dims:\n",
    "            try:\n",
    "                comp_data = comp_data.transpose(*total_data_subset.dims)\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Could not transpose {comp_name}: {e}\")\n",
    "        \n",
    "        if manual_sum is None:\n",
    "            manual_sum = comp_data.copy()\n",
    "        else:\n",
    "            manual_sum = manual_sum + comp_data\n",
    "        \n",
    "        print(f\"  Added {comp_name}: shape {comp_data.shape}\")\n",
    "    \n",
    "    print(f\"Manual sum shape: {manual_sum.shape}\")\n",
    "    print(f\"Total data shape: {total_data_subset.shape}\")\n",
    "    \n",
    "    # Calculate difference\n",
    "    difference = total_data_subset - manual_sum\n",
    "    max_diff = float(np.nanmax(np.abs(difference.values)))\n",
    "    mean_diff = float(np.nanmean(np.abs(difference.values)))\n",
    "    \n",
    "    print(f\"\\nDifference Statistics:\")\n",
    "    print(f\"  Max absolute difference: {max_diff:.6e} mm\")\n",
    "    print(f\"  Mean absolute difference: {mean_diff:.6e} mm\")\n",
    "    \n",
    "    if max_diff < 1e-3:  # Less than 0.001 mm difference\n",
    "        print(\"  ✅ VERIFICATION PASSED: Total matches sum of components\")\n",
    "    else:\n",
    "        print(\"  ⚠️  WARNING: Significant differences detected\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Get sample indices for plotting\n",
    "    n_samples = total_data_subset.shape[0] if 'samples' in total_data_subset.dims else total_data_subset.shape[1]\n",
    "    sample_indices = [0, n_samples//2, n_samples-1]  # First, middle, last\n",
    "    \n",
    "    # Determine dimension order\n",
    "    samples_first = 'samples' == list(total_data_subset.dims)[0]\n",
    "    \n",
    "    # Plot 1: Time series for selected samples\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    for idx in sample_indices:\n",
    "        if samples_first:\n",
    "            ax1.plot(common_years, total_data_subset[idx, :], \n",
    "                    label=f'Total (sample {idx})', linewidth=2)\n",
    "        else:\n",
    "            ax1.plot(common_years, total_data_subset[:, idx], \n",
    "                    label=f'Total (sample {idx})', linewidth=2)\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Sea Level Change (mm)')\n",
    "    ax1.set_title(f'Total {file_type.upper()}: Selected Samples')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Individual components for one sample\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    sample_to_plot = 0\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        comp_years_local = comp_dict['years']\n",
    "        \n",
    "        # Subset to common years\n",
    "        comp_year_indices = [np.where(comp_years_local == y)[0][0] for y in common_years]\n",
    "        \n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        year_dim_comp = None\n",
    "        for dim in comp_data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim_comp = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim_comp:\n",
    "            comp_data = comp_data.isel({year_dim_comp: comp_year_indices})\n",
    "        \n",
    "        if comp_data.dims != total_data_subset.dims:\n",
    "            try:\n",
    "                comp_data = comp_data.transpose(*total_data_subset.dims)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if samples_first:\n",
    "            y_data = comp_data[sample_to_plot, :].values\n",
    "        else:\n",
    "            y_data = comp_data[:, sample_to_plot].values\n",
    "            \n",
    "        ax2.plot(common_years, y_data, \n",
    "                label=comp_name, linewidth=2, marker='o', markersize=4)\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Sea Level Change (mm)')\n",
    "    ax2.set_title(f'Individual Components (sample {sample_to_plot})')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Manual sum vs Total for one sample\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    if samples_first:\n",
    "        total_y = total_data_subset[sample_to_plot, :].values\n",
    "        sum_y = manual_sum[sample_to_plot, :].values\n",
    "    else:\n",
    "        total_y = total_data_subset[:, sample_to_plot].values\n",
    "        sum_y = manual_sum[:, sample_to_plot].values\n",
    "        \n",
    "    ax3.plot(common_years, total_y, \n",
    "            label='Total (from file)', linewidth=2, marker='o')\n",
    "    ax3.plot(common_years, sum_y, \n",
    "            label='Manual sum', linewidth=2, marker='s', linestyle='--')\n",
    "    ax3.set_xlabel('Year')\n",
    "    ax3.set_ylabel('Sea Level Change (mm)')\n",
    "    ax3.set_title(f'Verification: Total vs Sum (sample {sample_to_plot})')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Ensemble mean comparison\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    total_mean = total_data_subset.mean(dim='samples')\n",
    "    manual_sum_mean = manual_sum.mean(dim='samples')\n",
    "    ax4.plot(common_years, total_mean, label='Total mean', linewidth=3)\n",
    "    ax4.plot(common_years, manual_sum_mean, label='Sum mean', \n",
    "            linewidth=3, linestyle='--')\n",
    "    \n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        comp_years_local = comp_dict['years']\n",
    "        \n",
    "        comp_year_indices = [np.where(comp_years_local == y)[0][0] for y in common_years]\n",
    "        \n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        year_dim_comp = None\n",
    "        for dim in comp_data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim_comp = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim_comp:\n",
    "            comp_data = comp_data.isel({year_dim_comp: comp_year_indices})\n",
    "        \n",
    "        if comp_data.dims != total_data_subset.dims:\n",
    "            try:\n",
    "                comp_data = comp_data.transpose(*total_data_subset.dims)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        comp_mean = comp_data.mean(dim='samples')\n",
    "        ax4.plot(common_years, comp_mean, label=f'{comp_name} mean', \n",
    "                linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax4.set_xlabel('Year')\n",
    "    ax4.set_ylabel('Sea Level Change (mm)')\n",
    "    ax4.set_title('Ensemble Means')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Ensemble spread (percentiles)\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    total_p50 = total_data_subset.quantile(0.5, dim='samples').values.flatten()\n",
    "    total_p05 = total_data_subset.quantile(0.05, dim='samples').values.flatten()\n",
    "    total_p95 = total_data_subset.quantile(0.95, dim='samples').values.flatten()\n",
    "    ax5.fill_between(common_years, total_p05, total_p95, alpha=0.3, label='Total 5-95%')\n",
    "    ax5.plot(common_years, total_p50, label='Total median', linewidth=2)\n",
    "    \n",
    "    sum_p50 = manual_sum.quantile(0.5, dim='samples').values.flatten()\n",
    "    sum_p05 = manual_sum.quantile(0.05, dim='samples').values.flatten()\n",
    "    sum_p95 = manual_sum.quantile(0.95, dim='samples').values.flatten()\n",
    "    ax5.plot(common_years, sum_p50, label='Sum median', \n",
    "            linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Sea Level Change (mm)')\n",
    "    ax5.set_title('Ensemble Spread (5th-95th percentile)')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Absolute difference\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    abs_diff = np.abs(difference.values)\n",
    "    for idx in sample_indices:\n",
    "        if samples_first:\n",
    "            y_diff = abs_diff[idx, :]\n",
    "        else:\n",
    "            y_diff = abs_diff[:, idx]\n",
    "        ax6.plot(common_years, y_diff, \n",
    "                label=f'Sample {idx}', linewidth=2)\n",
    "    ax6.set_xlabel('Year')\n",
    "    ax6.set_ylabel('Absolute Difference (mm)')\n",
    "    ax6.set_title('|Total - Sum| by Sample')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    # Only set log scale if max difference is significant\n",
    "    if max_diff > 1e-10:\n",
    "        ax6.set_yscale('log')\n",
    "    \n",
    "    # Plot 7: Contribution by component (stacked area)\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    stack_data = []\n",
    "    labels = []\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        comp_years_local = comp_dict['years']\n",
    "        \n",
    "        comp_year_indices = [np.where(comp_years_local == y)[0][0] for y in common_years]\n",
    "        \n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        year_dim_comp = None\n",
    "        for dim in comp_data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim_comp = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim_comp:\n",
    "            comp_data = comp_data.isel({year_dim_comp: comp_year_indices})\n",
    "        \n",
    "        if comp_data.dims != total_data_subset.dims:\n",
    "            try:\n",
    "                comp_data = comp_data.transpose(*total_data_subset.dims)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        comp_mean = comp_data.mean(dim='samples').values\n",
    "        stack_data.append(comp_mean)\n",
    "        labels.append(comp_name)\n",
    "    \n",
    "    ax7.stackplot(common_years, *stack_data, labels=labels, alpha=0.7)\n",
    "    ax7.set_xlabel('Year')\n",
    "    ax7.set_ylabel('Sea Level Change (mm)')\n",
    "    ax7.set_title('Component Contributions (Stacked, Ensemble Mean)')\n",
    "    ax7.legend(loc='upper left')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 8: Relative contribution by component\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    total_abs_mean = np.abs(total_mean.values)\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        comp_years_local = comp_dict['years']\n",
    "        \n",
    "        comp_year_indices = [np.where(comp_years_local == y)[0][0] for y in common_years]\n",
    "        \n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        year_dim_comp = None\n",
    "        for dim in comp_data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim_comp = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim_comp:\n",
    "            comp_data = comp_data.isel({year_dim_comp: comp_year_indices})\n",
    "        \n",
    "        if comp_data.dims != total_data_subset.dims:\n",
    "            try:\n",
    "                comp_data = comp_data.transpose(*total_data_subset.dims)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        comp_mean = comp_data.mean(dim='samples').values\n",
    "        # Avoid division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            rel_contrib = 100 * comp_mean / total_abs_mean\n",
    "            rel_contrib[~np.isfinite(rel_contrib)] = 0\n",
    "        ax8.plot(common_years, rel_contrib, label=comp_name, \n",
    "                linewidth=2, marker='o')\n",
    "    ax8.set_xlabel('Year')\n",
    "    ax8.set_ylabel('Relative Contribution (%)')\n",
    "    ax8.set_title('Relative Component Contributions')\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    ax8.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Plot 9: Heatmap of differences across all samples\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    # Ensure proper orientation for heatmap\n",
    "    if not samples_first:\n",
    "        abs_diff = abs_diff.T\n",
    "    im = ax9.imshow(abs_diff, aspect='auto', cmap='viridis', \n",
    "                    interpolation='nearest')\n",
    "    ax9.set_xlabel('Year Index')\n",
    "    ax9.set_ylabel('Sample Index')\n",
    "    ax9.set_title('Heatmap: |Total - Sum| (all samples)')\n",
    "    plt.colorbar(im, ax=ax9, label='Absolute Difference (mm)')\n",
    "    \n",
    "    plt.suptitle(f'{file_type.upper()} Verification: Total vs Sum of Components\\n' + \n",
    "                 f'Max diff: {max_diff:.2e} mm, Mean diff: {mean_diff:.2e} mm',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_file = Path(output_dir) / f'verification_{file_type}_totals.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved verification plot to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'max_difference': max_diff,\n",
    "        'mean_difference': mean_diff,\n",
    "        'total_data': total_data_subset,\n",
    "        'manual_sum': manual_sum,\n",
    "        'difference': difference,\n",
    "        'common_years': common_years\n",
    "    }\n",
    "\n",
    "# Run verification for both LSLR and GSLR\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING SEA LEVEL TOTALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify LSLR\n",
    "lslr_results = verify_totals(output_dir='./data/output', file_type='lslr')\n",
    "\n",
    "# Verify GSLR\n",
    "gslr_results = verify_totals(output_dir='./data/output', file_type='gslr')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"LSLR Max Difference: {lslr_results['max_difference']:.6e} mm\")\n",
    "print(f\"GSLR Max Difference: {gslr_results['max_difference']:.6e} mm\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2d32b-fcef-4abd-9e41-c52f9a070b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable numbagg to avoid NumPy compatibility issues\n",
    "xr.set_options(use_bottleneck=False, use_numbagg=False)\n",
    "\n",
    "def load_gslr_file(filepath):\n",
    "    \"\"\"Load GSLR data from NetCDF file\"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Find the sea level variable\n",
    "    possible_names = ['sea_level_change', 'sealevel_change', 'slr', 'sea_level']\n",
    "    var_name = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name in ds.data_vars:\n",
    "            var_name = name\n",
    "            break\n",
    "    \n",
    "    if var_name is None:\n",
    "        data_vars = [v for v in ds.data_vars if v not in ['lat', 'lon']]\n",
    "        if data_vars:\n",
    "            var_name = data_vars[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find sea level variable in {filepath}\")\n",
    "    \n",
    "    data = ds[var_name]\n",
    "    years = ds['years'].values if 'years' in ds else None\n",
    "    \n",
    "    # Squeeze out locations dimension if present\n",
    "    if 'locations' in data.dims:\n",
    "        data = data.squeeze('locations')\n",
    "    \n",
    "    return data, years, ds, var_name\n",
    "\n",
    "def compare_gslr_files_barchart(output_dir='./data/output'):\n",
    "    \"\"\"\n",
    "    Create bar chart comparisons of totaled GSLR files\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING GSLR FILES FOR BAR CHART COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Define files to compare\n",
    "    files_to_load = {\n",
    "        'All (Total)': 'totaled_output_all_gslr.nc',\n",
    "        'LWS': 'totaled_output_lws_gslr.nc',\n",
    "        'Sterodynamics': 'totaled_output_sterodynamics_gslr.nc'\n",
    "    }\n",
    "    \n",
    "    # Load all files\n",
    "    data_dict = {}\n",
    "    for label, filename in files_to_load.items():\n",
    "        filepath = Path(output_dir) / filename\n",
    "        if filepath.exists():\n",
    "            data, years, ds, var_name = load_gslr_file(filepath)\n",
    "            data_dict[label] = {\n",
    "                'data': data,\n",
    "                'years': years,\n",
    "                'ds': ds,\n",
    "                'var_name': var_name\n",
    "            }\n",
    "            print(f\"\\n{label}: {filename}\")\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dimensions: {data.dims}\")\n",
    "            print(f\"  Years: {len(years)} points from {years[0]} to {years[-1]}\")\n",
    "        else:\n",
    "            print(f\"\\nWARNING: File not found: {filepath}\")\n",
    "    \n",
    "    if len(data_dict) == 0:\n",
    "        print(\"ERROR: No files could be loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Find common years across all datasets\n",
    "    all_years = [info['years'] for info in data_dict.values()]\n",
    "    common_years = all_years[0]\n",
    "    for years in all_years[1:]:\n",
    "        common_years = np.intersect1d(common_years, years)\n",
    "    \n",
    "    print(f\"\\nCommon years: {len(common_years)} years from {common_years[0]} to {common_years[-1]}\")\n",
    "    \n",
    "    # Calculate statistics for each file at common years\n",
    "    stats_dict = {}\n",
    "    for label, info in data_dict.items():\n",
    "        data = info['data']\n",
    "        years = info['years']\n",
    "        \n",
    "        # Subset to common years\n",
    "        year_indices = [np.where(years == y)[0][0] for y in common_years]\n",
    "        \n",
    "        # Find year dimension\n",
    "        year_dim = None\n",
    "        for dim in data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim:\n",
    "            data_subset = data.isel({year_dim: year_indices})\n",
    "        else:\n",
    "            data_subset = data\n",
    "        \n",
    "        # Calculate statistics across samples\n",
    "        mean_timeseries = data_subset.mean(dim='samples').values\n",
    "        std_timeseries = data_subset.std(dim='samples').values\n",
    "        p05_timeseries = data_subset.quantile(0.05, dim='samples').values\n",
    "        p95_timeseries = data_subset.quantile(0.95, dim='samples').values\n",
    "        median_timeseries = data_subset.quantile(0.5, dim='samples').values\n",
    "        \n",
    "        stats_dict[label] = {\n",
    "            'mean': mean_timeseries,\n",
    "            'std': std_timeseries,\n",
    "            'p05': p05_timeseries,\n",
    "            'p95': p95_timeseries,\n",
    "            'median': median_timeseries,\n",
    "            'data_subset': data_subset\n",
    "        }\n",
    "    \n",
    "    # Create comprehensive bar chart visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Define colors for each dataset\n",
    "    colors = {\n",
    "        'All (Total)': '#2E86AB',\n",
    "        'LWS': '#A23B72',\n",
    "        'Sterodynamics': '#F18F01'\n",
    "    }\n",
    "    \n",
    "    labels_list = list(stats_dict.keys())\n",
    "    n_labels = len(labels_list)\n",
    "    \n",
    "    # Plot 1: Mean values by year (grouped bar chart)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    x = np.arange(len(common_years))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax1.bar(x + offset, stats_dict[label]['mean'], width, \n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Mean GSLR (mm)')\n",
    "    ax1.set_title('Mean Global Sea Level Rise by Year')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(common_years, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Final year comparison (mean ± std)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    final_means = [stats_dict[label]['mean'][-1] for label in labels_list]\n",
    "    final_stds = [stats_dict[label]['std'][-1] for label in labels_list]\n",
    "    \n",
    "    x_pos = np.arange(n_labels)\n",
    "    bars = ax2.bar(x_pos, final_means, yerr=final_stds, \n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax2.set_ylabel('GSLR (mm)')\n",
    "    ax2.set_title(f'Final Year ({common_years[-1]}) Comparison\\n(Mean ± Std Dev)')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, mean, std) in enumerate(zip(bars, final_means, final_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{mean:.1f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 3: First year comparison\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    first_means = [stats_dict[label]['mean'][0] for label in labels_list]\n",
    "    first_stds = [stats_dict[label]['std'][0] for label in labels_list]\n",
    "    \n",
    "    bars = ax3.bar(x_pos, first_means, yerr=first_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax3.set_ylabel('GSLR (mm)')\n",
    "    ax3.set_title(f'First Year ({common_years[0]}) Comparison\\n(Mean ± Std Dev)')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (bar, mean, std) in enumerate(zip(bars, first_means, first_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{mean:.1f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 4: Total change (final - first year)\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    total_changes = [stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0] \n",
    "                     for label in labels_list]\n",
    "    \n",
    "    bars = ax4.bar(x_pos, total_changes,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax4.set_ylabel('Total Change (mm)')\n",
    "    ax4.set_title(f'Total GSLR Change\\n({common_years[0]} to {common_years[-1]})')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, change in zip(bars, total_changes):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{change:.1f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 5: Standard deviation by year\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax5.bar(x + offset, stats_dict[label]['std'], width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Std Dev (mm)')\n",
    "    ax5.set_title('Ensemble Spread (Std Dev) by Year')\n",
    "    ax5.set_xticks(x)\n",
    "    ax5.set_xticklabels(common_years, rotation=45)\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 6: Uncertainty range (P95 - P05) by year\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        uncertainty = stats_dict[label]['p95'] - stats_dict[label]['p05']\n",
    "        ax6.bar(x + offset, uncertainty, width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax6.set_xlabel('Year')\n",
    "    ax6.set_ylabel('Uncertainty Range (mm)')\n",
    "    ax6.set_title('90% Confidence Interval (P95-P05) by Year')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(common_years, rotation=45)\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 7: Average across all years\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    avg_means = [np.mean(stats_dict[label]['mean']) for label in labels_list]\n",
    "    avg_stds = [np.mean(stats_dict[label]['std']) for label in labels_list]\n",
    "    \n",
    "    bars = ax7.bar(x_pos, avg_means, yerr=avg_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax7.set_ylabel('Average GSLR (mm)')\n",
    "    ax7.set_title(f'Average Across All Years\\n({common_years[0]}-{common_years[-1]})')\n",
    "    ax7.set_xticks(x_pos)\n",
    "    ax7.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, avg_means):\n",
    "        height = bar.get_height()\n",
    "        ax7.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{mean:.1f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 8: Contribution percentages (relative to total at final year)\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if 'All (Total)' in stats_dict:\n",
    "        total_final = stats_dict['All (Total)']['mean'][-1]\n",
    "        contributions = []\n",
    "        contrib_labels = []\n",
    "        \n",
    "        for label in labels_list:\n",
    "            if label != 'All (Total)':\n",
    "                final_val = stats_dict[label]['mean'][-1]\n",
    "                pct = (final_val / total_final) * 100 if total_final != 0 else 0\n",
    "                contributions.append(pct)\n",
    "                contrib_labels.append(label)\n",
    "        \n",
    "        bars = ax8.bar(range(len(contributions)), contributions,\n",
    "                       color=[colors[label] for label in contrib_labels],\n",
    "                       alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax8.set_ylabel('Contribution (%)')\n",
    "        ax8.set_title(f'Component Contribution to Total\\n(Final Year: {common_years[-1]})')\n",
    "        ax8.set_xticks(range(len(contributions)))\n",
    "        ax8.set_xticklabels(contrib_labels, rotation=15, ha='right')\n",
    "        ax8.grid(True, alpha=0.3, axis='y')\n",
    "        ax8.axhline(y=100, color='red', linestyle='--', linewidth=2, alpha=0.5, label='100%')\n",
    "        \n",
    "        for bar, pct in zip(bars, contributions):\n",
    "            height = bar.get_height()\n",
    "            ax8.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{pct:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 9: Rate of change (difference between consecutive years)\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    for label in labels_list:\n",
    "        mean_vals = stats_dict[label]['mean']\n",
    "        rates = np.diff(mean_vals) / np.diff(common_years)\n",
    "        ax9.plot(common_years[:-1], rates, marker='o', linewidth=2,\n",
    "                label=label, color=colors[label])\n",
    "    \n",
    "    ax9.set_xlabel('Year')\n",
    "    ax9.set_ylabel('Rate of Change (mm/year)')\n",
    "    ax9.set_title('Rate of GSLR Change')\n",
    "    ax9.legend()\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    ax9.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.suptitle('GSLR Comparison: All vs Components\\n' +\n",
    "                 f'({len(common_years)} years from {common_years[0]} to {common_years[-1]})',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_file = Path(output_dir) / 'gslr_barchart_comparison.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved bar chart comparison to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for label in labels_list:\n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  First year ({common_years[0]}): {stats_dict[label]['mean'][0]:.2f} ± {stats_dict[label]['std'][0]:.2f} mm\")\n",
    "        print(f\"  Final year ({common_years[-1]}): {stats_dict[label]['mean'][-1]:.2f} ± {stats_dict[label]['std'][-1]:.2f} mm\")\n",
    "        print(f\"  Total change: {stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0]:.2f} mm\")\n",
    "        print(f\"  Average: {np.mean(stats_dict[label]['mean']):.2f} mm\")\n",
    "        print(f\"  Average rate: {(stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0]) / (common_years[-1] - common_years[0]):.2f} mm/year\")\n",
    "    \n",
    "    # Verification: Check if All = LWS + Sterodynamics\n",
    "    if 'All (Total)' in stats_dict and 'LWS' in stats_dict and 'Sterodynamics' in stats_dict:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VERIFICATION: All = LWS + Sterodynamics\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_mean = stats_dict['All (Total)']['mean']\n",
    "        lws_mean = stats_dict['LWS']['mean']\n",
    "        stereo_mean = stats_dict['Sterodynamics']['mean']\n",
    "        sum_mean = lws_mean + stereo_mean\n",
    "        \n",
    "        diff = all_mean - sum_mean\n",
    "        max_diff = np.max(np.abs(diff))\n",
    "        mean_diff = np.mean(np.abs(diff))\n",
    "        \n",
    "        print(f\"Max absolute difference: {max_diff:.6e} mm\")\n",
    "        print(f\"Mean absolute difference: {mean_diff:.6e} mm\")\n",
    "        \n",
    "        if max_diff < 1e-3:\n",
    "            print(\"✅ VERIFICATION PASSED: All = LWS + Sterodynamics\")\n",
    "        else:\n",
    "            print(\"⚠️  WARNING: Significant differences detected\")\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "# Run the comparison\n",
    "compare_gslr_files_barchart(output_dir='./data/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff58d50-5929-44de-9bc5-464af5e8bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable numbagg to avoid NumPy compatibility issues\n",
    "xr.set_options(use_bottleneck=False, use_numbagg=False)\n",
    "\n",
    "def load_lslr_file(filepath):\n",
    "    \"\"\"Load LSLR data from NetCDF file\"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Find the sea level variable\n",
    "    possible_names = ['sea_level_change', 'sealevel_change', 'slr', 'sea_level']\n",
    "    var_name = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name in ds.data_vars:\n",
    "            var_name = name\n",
    "            break\n",
    "    \n",
    "    if var_name is None:\n",
    "        data_vars = [v for v in ds.data_vars if v not in ['lat', 'lon']]\n",
    "        if data_vars:\n",
    "            var_name = data_vars[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find sea level variable in {filepath}\")\n",
    "    \n",
    "    data = ds[var_name]\n",
    "    years = ds['years'].values if 'years' in ds else None\n",
    "    \n",
    "    # Squeeze out locations dimension if present\n",
    "    if 'locations' in data.dims:\n",
    "        data = data.squeeze('locations')\n",
    "    \n",
    "    return data, years, ds, var_name\n",
    "\n",
    "def compare_lslr_files_barchart(output_dir='./data/output'):\n",
    "    \"\"\"\n",
    "    Create bar chart comparisons of totaled LSLR files\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING LSLR FILES FOR BAR CHART COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Define files to compare\n",
    "    files_to_load = {\n",
    "        'All (Total)': 'totaled_output_all_lslr.nc',\n",
    "        'LWS': 'totaled_output_lws_lslr.nc',\n",
    "        'Sterodynamics': 'totaled_output_sterodynamics_lslr.nc'\n",
    "    }\n",
    "    \n",
    "    # Load all files\n",
    "    data_dict = {}\n",
    "    for label, filename in files_to_load.items():\n",
    "        filepath = Path(output_dir) / filename\n",
    "        if filepath.exists():\n",
    "            data, years, ds, var_name = load_lslr_file(filepath)\n",
    "            data_dict[label] = {\n",
    "                'data': data,\n",
    "                'years': years,\n",
    "                'ds': ds,\n",
    "                'var_name': var_name\n",
    "            }\n",
    "            print(f\"\\n{label}: {filename}\")\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dimensions: {data.dims}\")\n",
    "            print(f\"  Years: {len(years)} points from {years[0]} to {years[-1]}\")\n",
    "        else:\n",
    "            print(f\"\\nWARNING: File not found: {filepath}\")\n",
    "    \n",
    "    if len(data_dict) == 0:\n",
    "        print(\"ERROR: No files could be loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Find common years across all datasets\n",
    "    all_years = [info['years'] for info in data_dict.values()]\n",
    "    common_years = all_years[0]\n",
    "    for years in all_years[1:]:\n",
    "        common_years = np.intersect1d(common_years, years)\n",
    "    \n",
    "    print(f\"\\nCommon years: {len(common_years)} years from {common_years[0]} to {common_years[-1]}\")\n",
    "    \n",
    "    # Calculate statistics for each file at common years\n",
    "    stats_dict = {}\n",
    "    for label, info in data_dict.items():\n",
    "        data = info['data']\n",
    "        years = info['years']\n",
    "        \n",
    "        # Subset to common years\n",
    "        year_indices = [np.where(years == y)[0][0] for y in common_years]\n",
    "        \n",
    "        # Find year dimension\n",
    "        year_dim = None\n",
    "        for dim in data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim:\n",
    "            data_subset = data.isel({year_dim: year_indices})\n",
    "        else:\n",
    "            data_subset = data\n",
    "        \n",
    "        # Calculate statistics across samples\n",
    "        mean_timeseries = data_subset.mean(dim='samples').values\n",
    "        std_timeseries = data_subset.std(dim='samples').values\n",
    "        p05_timeseries = data_subset.quantile(0.05, dim='samples').values\n",
    "        p95_timeseries = data_subset.quantile(0.95, dim='samples').values\n",
    "        median_timeseries = data_subset.quantile(0.5, dim='samples').values\n",
    "        \n",
    "        stats_dict[label] = {\n",
    "            'mean': mean_timeseries,\n",
    "            'std': std_timeseries,\n",
    "            'p05': p05_timeseries,\n",
    "            'p95': p95_timeseries,\n",
    "            'median': median_timeseries,\n",
    "            'data_subset': data_subset\n",
    "        }\n",
    "    \n",
    "    # Create comprehensive bar chart visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Define colors for each dataset\n",
    "    colors = {\n",
    "        'All (Total)': '#2E86AB',\n",
    "        'LWS': '#A23B72',\n",
    "        'Sterodynamics': '#F18F01'\n",
    "    }\n",
    "    \n",
    "    labels_list = list(stats_dict.keys())\n",
    "    n_labels = len(labels_list)\n",
    "    \n",
    "    # Plot 1: Mean values by year (grouped bar chart)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    x = np.arange(len(common_years))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax1.bar(x + offset, stats_dict[label]['mean'], width, \n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Mean LSLR (mm)')\n",
    "    ax1.set_title('Mean Local Sea Level Rise by Year')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(common_years, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Final year comparison (mean ± std)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    final_means = [stats_dict[label]['mean'][-1] for label in labels_list]\n",
    "    final_stds = [stats_dict[label]['std'][-1] for label in labels_list]\n",
    "    \n",
    "    x_pos = np.arange(n_labels)\n",
    "    bars = ax2.bar(x_pos, final_means, yerr=final_stds, \n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax2.set_ylabel('LSLR (mm)')\n",
    "    ax2.set_title(f'Final Year ({common_years[-1]}) Comparison\\n(Mean ± Std Dev)')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, mean, std) in enumerate(zip(bars, final_means, final_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{mean:.1f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 3: First year comparison\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    first_means = [stats_dict[label]['mean'][0] for label in labels_list]\n",
    "    first_stds = [stats_dict[label]['std'][0] for label in labels_list]\n",
    "    \n",
    "    bars = ax3.bar(x_pos, first_means, yerr=first_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax3.set_ylabel('LSLR (mm)')\n",
    "    ax3.set_title(f'First Year ({common_years[0]}) Comparison\\n(Mean ± Std Dev)')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (bar, mean, std) in enumerate(zip(bars, first_means, first_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{mean:.1f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 4: Total change (final - first year)\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    total_changes = [stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0] \n",
    "                     for label in labels_list]\n",
    "    \n",
    "    bars = ax4.bar(x_pos, total_changes,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax4.set_ylabel('Total Change (mm)')\n",
    "    ax4.set_title(f'Total LSLR Change\\n({common_years[0]} to {common_years[-1]})')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, change in zip(bars, total_changes):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{change:.1f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 5: Standard deviation by year\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax5.bar(x + offset, stats_dict[label]['std'], width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Std Dev (mm)')\n",
    "    ax5.set_title('Ensemble Spread (Std Dev) by Year')\n",
    "    ax5.set_xticks(x)\n",
    "    ax5.set_xticklabels(common_years, rotation=45)\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 6: Uncertainty range (P95 - P05) by year\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        uncertainty = stats_dict[label]['p95'] - stats_dict[label]['p05']\n",
    "        ax6.bar(x + offset, uncertainty, width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax6.set_xlabel('Year')\n",
    "    ax6.set_ylabel('Uncertainty Range (mm)')\n",
    "    ax6.set_title('90% Confidence Interval (P95-P05) by Year')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(common_years, rotation=45)\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 7: Average across all years\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    avg_means = [np.mean(stats_dict[label]['mean']) for label in labels_list]\n",
    "    avg_stds = [np.mean(stats_dict[label]['std']) for label in labels_list]\n",
    "    \n",
    "    bars = ax7.bar(x_pos, avg_means, yerr=avg_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax7.set_ylabel('Average LSLR (mm)')\n",
    "    ax7.set_title(f'Average Across All Years\\n({common_years[0]}-{common_years[-1]})')\n",
    "    ax7.set_xticks(x_pos)\n",
    "    ax7.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, avg_means):\n",
    "        height = bar.get_height()\n",
    "        ax7.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{mean:.1f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 8: Contribution percentages (relative to total at final year)\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if 'All (Total)' in stats_dict:\n",
    "        total_final = stats_dict['All (Total)']['mean'][-1]\n",
    "        contributions = []\n",
    "        contrib_labels = []\n",
    "        \n",
    "        for label in labels_list:\n",
    "            if label != 'All (Total)':\n",
    "                final_val = stats_dict[label]['mean'][-1]\n",
    "                pct = (final_val / total_final) * 100 if total_final != 0 else 0\n",
    "                contributions.append(pct)\n",
    "                contrib_labels.append(label)\n",
    "        \n",
    "        bars = ax8.bar(range(len(contributions)), contributions,\n",
    "                       color=[colors[label] for label in contrib_labels],\n",
    "                       alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax8.set_ylabel('Contribution (%)')\n",
    "        ax8.set_title(f'Component Contribution to Total\\n(Final Year: {common_years[-1]})')\n",
    "        ax8.set_xticks(range(len(contributions)))\n",
    "        ax8.set_xticklabels(contrib_labels, rotation=15, ha='right')\n",
    "        ax8.grid(True, alpha=0.3, axis='y')\n",
    "        ax8.axhline(y=100, color='red', linestyle='--', linewidth=2, alpha=0.5, label='100%')\n",
    "        \n",
    "        for bar, pct in zip(bars, contributions):\n",
    "            height = bar.get_height()\n",
    "            ax8.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{pct:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 9: Rate of change (difference between consecutive years)\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    for label in labels_list:\n",
    "        mean_vals = stats_dict[label]['mean']\n",
    "        rates = np.diff(mean_vals) / np.diff(common_years)\n",
    "        ax9.plot(common_years[:-1], rates, marker='o', linewidth=2,\n",
    "                label=label, color=colors[label])\n",
    "    \n",
    "    ax9.set_xlabel('Year')\n",
    "    ax9.set_ylabel('Rate of Change (mm/year)')\n",
    "    ax9.set_title('Rate of LSLR Change')\n",
    "    ax9.legend()\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    ax9.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.suptitle('LSLR Comparison: All vs Components\\n' +\n",
    "                 f'({len(common_years)} years from {common_years[0]} to {common_years[-1]})',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_file = Path(output_dir) / 'lslr_barchart_comparison.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved bar chart comparison to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for label in labels_list:\n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  First year ({common_years[0]}): {stats_dict[label]['mean'][0]:.2f} ± {stats_dict[label]['std'][0]:.2f} mm\")\n",
    "        print(f\"  Final year ({common_years[-1]}): {stats_dict[label]['mean'][-1]:.2f} ± {stats_dict[label]['std'][-1]:.2f} mm\")\n",
    "        print(f\"  Total change: {stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0]:.2f} mm\")\n",
    "        print(f\"  Average: {np.mean(stats_dict[label]['mean']):.2f} mm\")\n",
    "        print(f\"  Average rate: {(stats_dict[label]['mean'][-1] - stats_dict[label]['mean'][0]) / (common_years[-1] - common_years[0]):.2f} mm/year\")\n",
    "    \n",
    "    # Verification: Check if All = LWS + Sterodynamics\n",
    "    if 'All (Total)' in stats_dict and 'LWS' in stats_dict and 'Sterodynamics' in stats_dict:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VERIFICATION: All = LWS + Sterodynamics\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_mean = stats_dict['All (Total)']['mean']\n",
    "        lws_mean = stats_dict['LWS']['mean']\n",
    "        stereo_mean = stats_dict['Sterodynamics']['mean']\n",
    "        sum_mean = lws_mean + stereo_mean\n",
    "        \n",
    "        diff = all_mean - sum_mean\n",
    "        max_diff = np.max(np.abs(diff))\n",
    "        mean_diff = np.mean(np.abs(diff))\n",
    "        \n",
    "        print(f\"Max absolute difference: {max_diff:.6e} mm\")\n",
    "        print(f\"Mean absolute difference: {mean_diff:.6e} mm\")\n",
    "        \n",
    "        if max_diff < 1e-3:\n",
    "            print(\"✅ VERIFICATION PASSED: All = LWS + Sterodynamics\")\n",
    "        else:\n",
    "            print(\"⚠️  WARNING: Significant differences detected\")\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "# Run the comparison\n",
    "compare_lslr_files_barchart(output_dir='./data/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9fd03d-8912-47e3-bb4a-082326257eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable numbagg to avoid NumPy compatibility issues\n",
    "xr.set_options(use_bottleneck=False, use_numbagg=False)\n",
    "\n",
    "def load_sea_level_file(filepath):\n",
    "    \"\"\"Load sea level data from NetCDF file\"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Find the sea level variable\n",
    "    possible_names = ['sea_level_change', 'sealevel_change', 'slr', 'sea_level']\n",
    "    var_name = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name in ds.data_vars:\n",
    "            var_name = name\n",
    "            break\n",
    "    \n",
    "    if var_name is None:\n",
    "        data_vars = [v for v in ds.data_vars if v not in ['lat', 'lon']]\n",
    "        if data_vars:\n",
    "            var_name = data_vars[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find sea level variable in {filepath}\")\n",
    "    \n",
    "    data = ds[var_name]\n",
    "    years = ds['years'].values if 'years' in ds else None\n",
    "    \n",
    "    # Squeeze out locations dimension if present\n",
    "    if 'locations' in data.dims:\n",
    "        data = data.squeeze('locations')\n",
    "    \n",
    "    return data, years, ds, var_name\n",
    "\n",
    "def compare_files_barchart_sum(output_dir='./data/output', file_type='gslr'):\n",
    "    \"\"\"\n",
    "    Create bar chart comparisons of totaled files using SUM statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_dir : str\n",
    "        Directory containing the output files\n",
    "    file_type : str\n",
    "        Either 'lslr' or 'gslr'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"LOADING {file_type.upper()} FILES FOR BAR CHART COMPARISON (SUM)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Define files to compare\n",
    "    files_to_load = {\n",
    "        'All (Total)': f'totaled_output_all_{file_type}.nc',\n",
    "        'LWS': f'totaled_output_lws_{file_type}.nc',\n",
    "        'Sterodynamics': f'totaled_output_sterodynamics_{file_type}.nc'\n",
    "    }\n",
    "    \n",
    "    # Load all files\n",
    "    data_dict = {}\n",
    "    for label, filename in files_to_load.items():\n",
    "        filepath = Path(output_dir) / filename\n",
    "        if filepath.exists():\n",
    "            data, years, ds, var_name = load_sea_level_file(filepath)\n",
    "            data_dict[label] = {\n",
    "                'data': data,\n",
    "                'years': years,\n",
    "                'ds': ds,\n",
    "                'var_name': var_name\n",
    "            }\n",
    "            print(f\"\\n{label}: {filename}\")\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dimensions: {data.dims}\")\n",
    "            print(f\"  Years: {len(years)} points from {years[0]} to {years[-1]}\")\n",
    "        else:\n",
    "            print(f\"\\nWARNING: File not found: {filepath}\")\n",
    "    \n",
    "    if len(data_dict) == 0:\n",
    "        print(\"ERROR: No files could be loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Find common years across all datasets\n",
    "    all_years = [info['years'] for info in data_dict.values()]\n",
    "    common_years = all_years[0]\n",
    "    for years in all_years[1:]:\n",
    "        common_years = np.intersect1d(common_years, years)\n",
    "    \n",
    "    print(f\"\\nCommon years: {len(common_years)} years from {common_years[0]} to {common_years[-1]}\")\n",
    "    \n",
    "    # Calculate statistics for each file at common years\n",
    "    stats_dict = {}\n",
    "    for label, info in data_dict.items():\n",
    "        data = info['data']\n",
    "        years = info['years']\n",
    "        \n",
    "        # Subset to common years\n",
    "        year_indices = [np.where(years == y)[0][0] for y in common_years]\n",
    "        \n",
    "        # Find year dimension\n",
    "        year_dim = None\n",
    "        for dim in data.dims:\n",
    "            if 'year' in dim.lower():\n",
    "                year_dim = dim\n",
    "                break\n",
    "        \n",
    "        if year_dim:\n",
    "            data_subset = data.isel({year_dim: year_indices})\n",
    "        else:\n",
    "            data_subset = data\n",
    "        \n",
    "        # Calculate SUM statistics across samples (instead of mean)\n",
    "        sum_timeseries = data_subset.sum(dim='samples').values\n",
    "        std_timeseries = data_subset.std(dim='samples').values\n",
    "        p05_timeseries = data_subset.quantile(0.05, dim='samples').values\n",
    "        p95_timeseries = data_subset.quantile(0.95, dim='samples').values\n",
    "        median_timeseries = data_subset.quantile(0.5, dim='samples').values\n",
    "        \n",
    "        stats_dict[label] = {\n",
    "            'sum': sum_timeseries,\n",
    "            'std': std_timeseries,\n",
    "            'p05': p05_timeseries,\n",
    "            'p95': p95_timeseries,\n",
    "            'median': median_timeseries,\n",
    "            'data_subset': data_subset\n",
    "        }\n",
    "    \n",
    "    # Create comprehensive bar chart visualization\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Define colors for each dataset\n",
    "    colors = {\n",
    "        'All (Total)': '#2E86AB',\n",
    "        'LWS': '#A23B72',\n",
    "        'Sterodynamics': '#F18F01'\n",
    "    }\n",
    "    \n",
    "    labels_list = list(stats_dict.keys())\n",
    "    n_labels = len(labels_list)\n",
    "    \n",
    "    # Plot 1: Sum values by year (grouped bar chart)\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    x = np.arange(len(common_years))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax1.bar(x + offset, stats_dict[label]['sum'], width, \n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel(f'Total {file_type.upper()} (mm × samples)')\n",
    "    ax1.set_title(f'Total (Sum) {file_type.upper()} by Year')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(common_years, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Final year comparison (sum ± std)\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    final_sums = [stats_dict[label]['sum'][-1] for label in labels_list]\n",
    "    final_stds = [stats_dict[label]['std'][-1] for label in labels_list]\n",
    "    \n",
    "    x_pos = np.arange(n_labels)\n",
    "    bars = ax2.bar(x_pos, final_sums, yerr=final_stds, \n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax2.set_ylabel(f'{file_type.upper()} (mm × samples)')\n",
    "    ax2.set_title(f'Final Year ({common_years[-1]}) Comparison\\n(Sum ± Std Dev)')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, sum_val, std) in enumerate(zip(bars, final_sums, final_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{sum_val:.0f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 3: First year comparison\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    first_sums = [stats_dict[label]['sum'][0] for label in labels_list]\n",
    "    first_stds = [stats_dict[label]['std'][0] for label in labels_list]\n",
    "    \n",
    "    bars = ax3.bar(x_pos, first_sums, yerr=first_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax3.set_ylabel(f'{file_type.upper()} (mm × samples)')\n",
    "    ax3.set_title(f'First Year ({common_years[0]}) Comparison\\n(Sum ± Std Dev)')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (bar, sum_val, std) in enumerate(zip(bars, first_sums, first_stds)):\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + std,\n",
    "                f'{sum_val:.0f}±{std:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Plot 4: Total change (final - first year)\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    total_changes = [stats_dict[label]['sum'][-1] - stats_dict[label]['sum'][0] \n",
    "                     for label in labels_list]\n",
    "    \n",
    "    bars = ax4.bar(x_pos, total_changes,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax4.set_ylabel('Total Change (mm × samples)')\n",
    "    ax4.set_title(f'Total {file_type.upper()} Change\\n({common_years[0]} to {common_years[-1]})')\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, change in zip(bars, total_changes):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{change:.0f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 5: Standard deviation by year\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        ax5.bar(x + offset, stats_dict[label]['std'], width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Std Dev (mm)')\n",
    "    ax5.set_title('Ensemble Spread (Std Dev) by Year')\n",
    "    ax5.set_xticks(x)\n",
    "    ax5.set_xticklabels(common_years, rotation=45)\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 6: Uncertainty range (P95 - P05) by year\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    for i, label in enumerate(labels_list):\n",
    "        offset = (i - n_labels/2 + 0.5) * width\n",
    "        uncertainty = stats_dict[label]['p95'] - stats_dict[label]['p05']\n",
    "        ax6.bar(x + offset, uncertainty, width,\n",
    "                label=label, color=colors[label], alpha=0.8)\n",
    "    \n",
    "    ax6.set_xlabel('Year')\n",
    "    ax6.set_ylabel('Uncertainty Range (mm)')\n",
    "    ax6.set_title('90% Confidence Interval (P95-P05) by Year')\n",
    "    ax6.set_xticks(x)\n",
    "    ax6.set_xticklabels(common_years, rotation=45)\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 7: Average across all years (of sum values)\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    avg_sums = [np.mean(stats_dict[label]['sum']) for label in labels_list]\n",
    "    avg_stds = [np.mean(stats_dict[label]['std']) for label in labels_list]\n",
    "    \n",
    "    bars = ax7.bar(x_pos, avg_sums, yerr=avg_stds,\n",
    "                   color=[colors[label] for label in labels_list],\n",
    "                   alpha=0.8, capsize=10, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax7.set_ylabel(f'Average {file_type.upper()} (mm × samples)')\n",
    "    ax7.set_title(f'Average Sum Across All Years\\n({common_years[0]}-{common_years[-1]})')\n",
    "    ax7.set_xticks(x_pos)\n",
    "    ax7.set_xticklabels(labels_list, rotation=15, ha='right')\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, avg in zip(bars, avg_sums):\n",
    "        height = bar.get_height()\n",
    "        ax7.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{avg:.0f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 8: Contribution percentages (relative to total at final year)\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    if 'All (Total)' in stats_dict:\n",
    "        total_final = stats_dict['All (Total)']['sum'][-1]\n",
    "        contributions = []\n",
    "        contrib_labels = []\n",
    "        \n",
    "        for label in labels_list:\n",
    "            if label != 'All (Total)':\n",
    "                final_val = stats_dict[label]['sum'][-1]\n",
    "                pct = (final_val / total_final) * 100 if total_final != 0 else 0\n",
    "                contributions.append(pct)\n",
    "                contrib_labels.append(label)\n",
    "        \n",
    "        bars = ax8.bar(range(len(contributions)), contributions,\n",
    "                       color=[colors[label] for label in contrib_labels],\n",
    "                       alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax8.set_ylabel('Contribution (%)')\n",
    "        ax8.set_title(f'Component Contribution to Total\\n(Final Year: {common_years[-1]})')\n",
    "        ax8.set_xticks(range(len(contributions)))\n",
    "        ax8.set_xticklabels(contrib_labels, rotation=15, ha='right')\n",
    "        ax8.grid(True, alpha=0.3, axis='y')\n",
    "        ax8.axhline(y=100, color='red', linestyle='--', linewidth=2, alpha=0.5, label='100%')\n",
    "        \n",
    "        for bar, pct in zip(bars, contributions):\n",
    "            height = bar.get_height()\n",
    "            ax8.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{pct:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 9: Rate of change (difference between consecutive years)\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    for label in labels_list:\n",
    "        sum_vals = stats_dict[label]['sum']\n",
    "        rates = np.diff(sum_vals) / np.diff(common_years)\n",
    "        ax9.plot(common_years[:-1], rates, marker='o', linewidth=2,\n",
    "                label=label, color=colors[label])\n",
    "    \n",
    "    ax9.set_xlabel('Year')\n",
    "    ax9.set_ylabel('Rate of Change ((mm × samples)/year)')\n",
    "    ax9.set_title(f'Rate of {file_type.upper()} Change')\n",
    "    ax9.legend()\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    ax9.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.suptitle(f'{file_type.upper()} Comparison (SUM): All vs Components\\n' +\n",
    "                 f'({len(common_years)} years from {common_years[0]} to {common_years[-1]})',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_file = Path(output_dir) / f'{file_type}_barchart_comparison_sum.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved bar chart comparison to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS (SUM)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for label in labels_list:\n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  First year ({common_years[0]}): {stats_dict[label]['sum'][0]:.2f} ± {stats_dict[label]['std'][0]:.2f} mm×samples\")\n",
    "        print(f\"  Final year ({common_years[-1]}): {stats_dict[label]['sum'][-1]:.2f} ± {stats_dict[label]['std'][-1]:.2f} mm×samples\")\n",
    "        print(f\"  Total change: {stats_dict[label]['sum'][-1] - stats_dict[label]['sum'][0]:.2f} mm×samples\")\n",
    "        print(f\"  Average: {np.mean(stats_dict[label]['sum']):.2f} mm×samples\")\n",
    "        print(f\"  Average rate: {(stats_dict[label]['sum'][-1] - stats_dict[label]['sum'][0]) / (common_years[-1] - common_years[0]):.2f} (mm×samples)/year\")\n",
    "    \n",
    "    # Verification: Check if All = LWS + Sterodynamics\n",
    "    if 'All (Total)' in stats_dict and 'LWS' in stats_dict and 'Sterodynamics' in stats_dict:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VERIFICATION: All = LWS + Sterodynamics\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_sum = stats_dict['All (Total)']['sum']\n",
    "        lws_sum = stats_dict['LWS']['sum']\n",
    "        stereo_sum = stats_dict['Sterodynamics']['sum']\n",
    "        sum_sum = lws_sum + stereo_sum\n",
    "        \n",
    "        diff = all_sum - sum_sum\n",
    "        max_diff = np.max(np.abs(diff))\n",
    "        mean_diff = np.mean(np.abs(diff))\n",
    "        \n",
    "        print(f\"Max absolute difference: {max_diff:.6e} mm×samples\")\n",
    "        print(f\"Mean absolute difference: {mean_diff:.6e} mm×samples\")\n",
    "        \n",
    "        if max_diff < 1e-3:\n",
    "            print(\"✅ VERIFICATION PASSED: All = LWS + Sterodynamics\")\n",
    "        else:\n",
    "            print(\"⚠️  WARNING: Significant differences detected\")\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "# Run comparisons for both GSLR and LSLR using SUM\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARING SEA LEVEL TOTALS USING SUM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare GSLR files with SUM\n",
    "gslr_sum_results = compare_files_barchart_sum(output_dir='./data/output', file_type='gslr')\n",
    "\n",
    "# Compare LSLR files with SUM\n",
    "lslr_sum_results = compare_files_barchart_sum(output_dir='./data/output', file_type='lslr')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY (SUM METHOD)\")\n",
    "print(\"=\"*80)\n",
    "if gslr_sum_results:\n",
    "    print(f\"GSLR Final Year Total (All): {gslr_sum_results['All (Total)']['sum'][-1]:.2f} mm×samples\")\n",
    "if lslr_sum_results:\n",
    "    print(f\"LSLR Final Year Total (All): {lslr_sum_results['All (Total)']['sum'][-1]:.2f} mm×samples\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9c559-1bb4-4635-b698-dd25071792b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
