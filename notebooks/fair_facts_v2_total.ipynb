{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df759566-c4d8-4e9d-9cde-ac13f197dfb1",
   "metadata": {},
   "source": [
    "facts-total:\n",
    "- This is a minimal prototype of a total module for summing sealevel rise projections generated from different sources and modules. facts-total is a CLI tool that accepts a path to each netCDF file you would like summed as well as an output path where the summed result will be written. Each input netCDF file represents output from a FACTS sea level component module. It is the responsibility of the user to ensure that the desired and correct files are specified; check that file paths are correct and that each file specified belongs to the same scale ('global' or 'local').\n",
    "\n",
    "- It is possible to run multiple FACTS sea-level components with different default values for common parameters such as pyear-start and pyear-end. If that happens, total will not cause a failure, but will show a message similar to the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce40b51-2dac-4c33-a344-a0cef771229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add a path to the search list\n",
    "sys.path.insert(0, '/discover/nobackup/projects/eis_freshwater/gtamkin/facts2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936d5e34-5ba1-44a4-907e-34a44bce3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /gpfsm/dnb06/projects/p151/gtamkin/facts2.0/notebooks\n",
      "Directory successfully changed to: /gpfsm/dnb06/projects/p151/gtamkin/facts2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get and print the current working directory (optional, for verification)\n",
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "# Change the current working directory to a new path\n",
    "new_directory_path = \"/discover/nobackup/projects/eis_freshwater/gtamkin/facts2.0\" # Example for Linux/macOS\n",
    "# For Windows, you can use forward slashes or a raw string (see below)\n",
    "\n",
    "try:\n",
    "    os.chdir(new_directory_path)\n",
    "    print(f\"Directory successfully changed to: {os.getcwd()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory not found: {new_directory_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb10af8-383b-444d-aa92-e52a19fa40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Logger __main__ (WARNING)>\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import shlex\n",
    "\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import ConcurrentExecutionBackend\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from radical.asyncflow.logging import init_default_logger\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "print(logger)\n",
    "for handler in logger.handlers:\n",
    "    print(f\"Handler: {handler}\")\n",
    "    if isinstance(handler, logging.FileHandler):\n",
    "        print(f\"Log file: {handler.baseFilename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a204ac5-1e36-43b8-bb1b-e240ee98e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2026-02-03 16:29:14.874\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[root]\u001b[0m │ Logger configured successfully - Console: DEBUG, File: disabled (N/A), Structured: disabled, Style: modern\n",
      "\u001b[90m2026-02-03 16:29:14.875\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[execution.backend(concurrent)]\u001b[0m │ ThreadPoolExecutor execution backend started successfully\n",
      "\u001b[90m2026-02-03 16:29:14.875\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGHUP\n",
      "\u001b[90m2026-02-03 16:29:14.875\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGTERM\n",
      "\u001b[90m2026-02-03 16:29:14.876\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGINT\n",
      "\u001b[90m2026-02-03 16:29:14.876\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Started run component\n",
      "\u001b[90m2026-02-03 16:29:14.876\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Starting climate workflow 1 at 1770154154.8769002\n",
      "\u001b[90m2026-02-03 16:29:14.881\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/lws/lslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_lws_lslr.nc\n",
      "\u001b[90m2026-02-03 16:29:14.887\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/lws/gslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_lws_gslr.nc\n",
      "\u001b[90m2026-02-03 16:29:14.888\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/sterodynamics/lslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_sterodynamics_lslr.nc\n",
      "\u001b[90m2026-02-03 16:29:14.889\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/sterodynamics/gslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_sterodynamics_gslr.nc\n",
      "\u001b[90m2026-02-03 16:29:14.890\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/lws/lslr.nc --item=/mnt/total_out/sterodynamics/lslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_all_lslr.nc\n",
      "\u001b[90m2026-02-03 16:29:14.891\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Executing: /usr/local/other/singularity/4.0.3/bin/singularity exec --bind ./data/input:/mnt/total_in --bind ./data/output:/mnt/total_out ./containers/sealevel-facts-total_latest-sandbox facts-total --item=/mnt/total_out/lws/gslr.nc --item=/mnt/total_out/sterodynamics/gslr.nc --pyear-start=2020 --pyear-end=2150 --pyear-step=10 --output-path=/mnt/total_out/totaled_output_all_gslr.nc\n",
      "\u001b[90m2026-02-03 16:29:30.989\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/sterodynamics/lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:30.990\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_sterodynamics_lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.005\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/sterodynamics/gslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.005\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_sterodynamics_gslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.019\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/lws/gslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.019\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_lws_gslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.020\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/lws/lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.020\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_lws_lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.036\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/lws/lslr.nc\n",
      "- /mnt/total_out/sterodynamics/lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.036\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_all_lslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.063\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command output: Hello from FACTS totaling!\n",
      "Files to be totaled:\n",
      "- /mnt/total_out/lws/gslr.nc\n",
      "- /mnt/total_out/sterodynamics/gslr.nc\n",
      "\n",
      "\u001b[90m2026-02-03 16:29:31.064\u001b[0m │ \u001b[93mWARNING\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Command stderr: INFO:facts_total.total_workflow:Totaled projections written to /mnt/total_out/totaled_output_all_gslr.nc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import subprocess\n",
    "\n",
    "async def main():\n",
    "    init_default_logger(logging.DEBUG)\n",
    "\n",
    "    # Create backend and workflow\n",
    "    engine = await ConcurrentExecutionBackend(ThreadPoolExecutor())\n",
    "    flow = await WorkflowEngine.create(engine)\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    def setup_directories():\n",
    "        os.makedirs('./data/output/total', exist_ok=True)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def total_task(component, name):\n",
    "        \"\"\"Facts total task - executes singularity command\"\"\"\n",
    "        if (component == 'all'):\n",
    "            cmd = [\n",
    "                '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "                '--bind', './data/input:/mnt/total_in',\n",
    "                '--bind', './data/output:/mnt/total_out',\n",
    "                './containers/sealevel-facts-total_latest-sandbox',\n",
    "                'facts-total',\n",
    "                '--item=/mnt/total_out/lws/'+name+'.nc',\n",
    "                '--item=/mnt/total_out/sterodynamics/'+name+'.nc',\n",
    "                # ADD ICE COMPONENT IF AVAILABLE:\n",
    "                # '--item=/mnt/total_out/ice/'+name+'.nc',\n",
    "                '--pyear-start=2020',\n",
    "                '--pyear-end=2150',\n",
    "                '--pyear-step=10',\n",
    "                '--output-path=/mnt/total_out/totaled_output_all_'+name+'.nc'\n",
    "            ]\n",
    "        else:\n",
    "            cmd = [\n",
    "                '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "                '--bind', './data/input:/mnt/total_in',\n",
    "                '--bind', './data/output:/mnt/total_out',\n",
    "                './containers/sealevel-facts-total_latest-sandbox',\n",
    "                'facts-total',\n",
    "                '--item=/mnt/total_out/'+component+'/'+name+'.nc',\n",
    "                '--pyear-start=2020',\n",
    "                '--pyear-end=2150',\n",
    "                '--pyear-step=10',\n",
    "                '--output-path=/mnt/total_out/totaled_output_'+component+'_'+name+'.nc'\n",
    "            ]\n",
    "        \n",
    "        # Log the command\n",
    "        cmd_str = shlex.join(cmd)\n",
    "        logger.info(f\"Executing: {cmd_str}\")\n",
    "        \n",
    "        # RUN THE COMMAND ASYNCHRONOUSLY\n",
    "        proc = await asyncio.create_subprocess_exec(\n",
    "            *cmd,\n",
    "            stdout=asyncio.subprocess.PIPE,\n",
    "            stderr=asyncio.subprocess.PIPE\n",
    "        )\n",
    "        \n",
    "        stdout, stderr = await proc.communicate()\n",
    "        \n",
    "        if proc.returncode != 0:\n",
    "            error_msg = stderr.decode() if stderr else \"Unknown error\"\n",
    "            logger.error(f\"Command failed with return code {proc.returncode}: {error_msg}\")\n",
    "            raise RuntimeError(f\"Task failed: {error_msg}\")\n",
    "        \n",
    "        logger.info(f\"Command output: {stdout.decode()}\")\n",
    "        if stderr:\n",
    "            logger.warning(f\"Command stderr: {stderr.decode()}\")\n",
    "            \n",
    "        return {\n",
    "            'command': cmd_str,\n",
    "            'component': component,\n",
    "            'name': name,\n",
    "            'returncode': proc.returncode\n",
    "        }\n",
    "\n",
    "    async def run_climate_workflow(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "\n",
    "        # Setup directories\n",
    "        setup_directories()\n",
    "        \n",
    "        # Start ALL tasks in parallel (don't await yet)\n",
    "        total_future_lws_lslr = total_task('lws','lslr')\n",
    "        total_future_lws_gslr = total_task('lws','gslr')\n",
    "        total_future_sterodynamics_lslr = total_task('sterodynamics','lslr')\n",
    "        total_future_sterodynamics_gslr = total_task('sterodynamics','gslr')\n",
    "        total_future_all_lslr = total_task('all','lslr')\n",
    "        total_future_all_gslr = total_task('all','gslr')\n",
    "\n",
    "        # Wait for ALL tasks to complete in parallel using asyncio.gather\n",
    "        results = await asyncio.gather(\n",
    "            total_future_lws_lslr,\n",
    "            total_future_lws_gslr,\n",
    "            total_future_sterodynamics_lslr,\n",
    "            total_future_sterodynamics_gslr,\n",
    "            total_future_all_lslr,\n",
    "            total_future_all_gslr,\n",
    "            return_exceptions=True  # Continue even if one fails\n",
    "        )\n",
    "        \n",
    "        # Unpack results\n",
    "        (total_result_lws_lslr, \n",
    "         total_result_lws_gslr,\n",
    "         total_result_sterodynamics_lslr,\n",
    "         total_result_sterodynamics_gslr,\n",
    "         total_result_all_lslr,\n",
    "         total_result_all_gslr) = results\n",
    "        \n",
    "        # Check for failures\n",
    "        for i, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                logger.error(f\"Task {i} failed with error: {result}\")\n",
    "        \n",
    "        logger.info(f'ALL TOTAL tasks completed for pipeline {pipeline_id}')\n",
    "        logger.info(f'Climate workflow {pipeline_id} finished at {time.time()}')\n",
    "\n",
    "        return {\n",
    "            'total_result_lws_lslr': total_result_lws_lslr,\n",
    "            'total_result_lws_gslr': total_result_lws_gslr,\n",
    "            'total_result_sterodynamics_lslr': total_result_sterodynamics_lslr,\n",
    "            'total_result_sterodynamics_gslr': total_result_sterodynamics_gslr,\n",
    "            'total_result_all_lslr': total_result_all_lslr,\n",
    "            'total_result_all_gslr': total_result_all_gslr,\n",
    "        }\n",
    "\n",
    "    # Run workflow(s)\n",
    "    results = await run_climate_workflow(1)\n",
    "    logger.info(\"=========All workflows completed successfully=========\")\n",
    "    logger.info(results)\n",
    "    await flow.shutdown()\n",
    "\n",
    "# Just call it with await in Jupyter\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7b96c-7cfd-4244-afc8-84a35798165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable numbagg to avoid NumPy compatibility issues\n",
    "xr.set_options(use_bottleneck=False, use_numbagg=False)\n",
    "\n",
    "def load_sea_level_data(filepath):\n",
    "    \"\"\"Load sea level data from NetCDF file, handling different structures\"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Find the sea level variable (different files may use different names)\n",
    "    possible_names = ['sea_level_change', 'sealevel_change', 'slr', 'sea_level']\n",
    "    var_name = None\n",
    "    \n",
    "    for name in possible_names:\n",
    "        if name in ds.data_vars:\n",
    "            var_name = name\n",
    "            break\n",
    "    \n",
    "    if var_name is None:\n",
    "        # Just take the first non-coordinate variable\n",
    "        data_vars = [v for v in ds.data_vars if v not in ['lat', 'lon']]\n",
    "        if data_vars:\n",
    "            var_name = data_vars[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not find sea level variable in {filepath}\")\n",
    "    \n",
    "    data = ds[var_name]\n",
    "    years = ds['years'].values if 'years' in ds else None\n",
    "    \n",
    "    return data, years, ds\n",
    "\n",
    "def verify_totals(output_dir='./data/output', file_type='lslr'):\n",
    "    \"\"\"\n",
    "    Verify that totaled_output_all_{file_type}.nc = sum of individual component files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_dir : str\n",
    "        Directory containing the output files\n",
    "    file_type : str\n",
    "        Either 'lslr' or 'gslr'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"VERIFYING {file_type.upper()} TOTALS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load the totaled file\n",
    "    total_file = Path(output_dir) / f'totaled_output_all_{file_type}.nc'\n",
    "    total_data, total_years, total_ds = load_sea_level_data(total_file)\n",
    "    \n",
    "    print(f\"Loaded total file: {total_file.name}\")\n",
    "    print(f\"  Shape: {total_data.shape}\")\n",
    "    print(f\"  Dimensions: {total_data.dims}\")\n",
    "    \n",
    "    # Load individual component files\n",
    "    components = ['lws', 'sterodynamics']  # Add 'ice' if you have it\n",
    "    component_data = {}\n",
    "    \n",
    "    for comp in components:\n",
    "        comp_file = Path(output_dir) / comp / f'{file_type}.nc'\n",
    "        if comp_file.exists():\n",
    "            data, years, ds = load_sea_level_data(comp_file)\n",
    "            component_data[comp] = {'data': data, 'years': years, 'ds': ds}\n",
    "            print(f\"Loaded {comp}: {comp_file.name}\")\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dimensions: {data.dims}\")\n",
    "        else:\n",
    "            print(f\"WARNING: Component file not found: {comp_file}\")\n",
    "    \n",
    "    # Align dimensions and sum components\n",
    "    print(\"\\nCalculating sum of components...\")\n",
    "    \n",
    "    # We need to handle different dimension orders\n",
    "    # Total file has: (samples, years, locations)\n",
    "    # Component files might have: (years, samples) for gslr or other orders for lslr\n",
    "    \n",
    "    # Squeeze out location dimension if present (global = 1 location)\n",
    "    if 'locations' in total_data.dims:\n",
    "        total_data_squeeze = total_data.squeeze('locations')\n",
    "    else:\n",
    "        total_data_squeeze = total_data\n",
    "    \n",
    "    # Sum components, handling dimension alignment\n",
    "    manual_sum = None\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        \n",
    "        # Squeeze locations if present\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        \n",
    "        # Ensure dimensions match total\n",
    "        # Transpose if needed to match (samples, years)\n",
    "        if comp_data.dims != total_data_squeeze.dims:\n",
    "            # Try to align dimensions\n",
    "            comp_data = comp_data.transpose(*total_data_squeeze.dims)\n",
    "        \n",
    "        if manual_sum is None:\n",
    "            manual_sum = comp_data.copy()\n",
    "        else:\n",
    "            manual_sum = manual_sum + comp_data\n",
    "        \n",
    "        print(f\"  Added {comp_name}: shape {comp_data.shape}\")\n",
    "    \n",
    "    print(f\"Manual sum shape: {manual_sum.shape}\")\n",
    "    \n",
    "    # Calculate difference\n",
    "    difference = total_data_squeeze - manual_sum\n",
    "    max_diff = float(np.nanmax(np.abs(difference.values)))\n",
    "    mean_diff = float(np.nanmean(np.abs(difference.values)))\n",
    "    \n",
    "    print(f\"\\nDifference Statistics:\")\n",
    "    print(f\"  Max absolute difference: {max_diff:.6e} mm\")\n",
    "    print(f\"  Mean absolute difference: {mean_diff:.6e} mm\")\n",
    "    \n",
    "    if max_diff < 1e-3:  # Less than 0.001 mm difference\n",
    "        print(\"  ✅ VERIFICATION PASSED: Total matches sum of components\")\n",
    "    else:\n",
    "        print(\"  ⚠️  WARNING: Significant differences detected\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Get sample indices for plotting\n",
    "    n_samples = total_data_squeeze.shape[0]\n",
    "    sample_indices = [0, n_samples//2, n_samples-1]  # First, middle, last\n",
    "    \n",
    "    # Plot 1: Time series for selected samples\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    for idx in sample_indices:\n",
    "        ax1.plot(total_years, total_data_squeeze[idx, :], \n",
    "                label=f'Total (sample {idx})', linewidth=2)\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Sea Level Change (mm)')\n",
    "    ax1.set_title(f'Total {file_type.upper()}: Selected Samples')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Individual components for one sample\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    sample_to_plot = 0\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        if comp_data.dims != total_data_squeeze.dims:\n",
    "            comp_data = comp_data.transpose(*total_data_squeeze.dims)\n",
    "        ax2.plot(total_years, comp_data[sample_to_plot, :], \n",
    "                label=comp_name, linewidth=2, marker='o', markersize=4)\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Sea Level Change (mm)')\n",
    "    ax2.set_title(f'Individual Components (sample {sample_to_plot})')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Manual sum vs Total for one sample\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    ax3.plot(total_years, total_data_squeeze[sample_to_plot, :], \n",
    "            label='Total (from file)', linewidth=2, marker='o')\n",
    "    ax3.plot(total_years, manual_sum[sample_to_plot, :], \n",
    "            label='Manual sum', linewidth=2, marker='s', linestyle='--')\n",
    "    ax3.set_xlabel('Year')\n",
    "    ax3.set_ylabel('Sea Level Change (mm)')\n",
    "    ax3.set_title(f'Verification: Total vs Sum (sample {sample_to_plot})')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Ensemble mean comparison\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    total_mean = total_data_squeeze.mean(dim='samples')\n",
    "    manual_sum_mean = manual_sum.mean(dim='samples')\n",
    "    ax4.plot(total_years, total_mean, label='Total mean', linewidth=3)\n",
    "    ax4.plot(total_years, manual_sum_mean, label='Sum mean', \n",
    "            linewidth=3, linestyle='--')\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        if comp_data.dims != total_data_squeeze.dims:\n",
    "            comp_data = comp_data.transpose(*total_data_squeeze.dims)\n",
    "        comp_mean = comp_data.mean(dim='samples')\n",
    "        ax4.plot(total_years, comp_mean, label=f'{comp_name} mean', \n",
    "                linewidth=2, alpha=0.7)\n",
    "    ax4.set_xlabel('Year')\n",
    "    ax4.set_ylabel('Sea Level Change (mm)')\n",
    "    ax4.set_title('Ensemble Means')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Ensemble spread (percentiles)\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    total_p50 = total_data_squeeze.quantile(0.5, dim='samples').values.flatten()\n",
    "    total_p05 = total_data_squeeze.quantile(0.05, dim='samples').values.flatten()\n",
    "    total_p95 = total_data_squeeze.quantile(0.95, dim='samples').values.flatten()\n",
    "    ax5.fill_between(total_years, total_p05, total_p95, alpha=0.3, label='Total 5-95%')\n",
    "    ax5.plot(total_years, total_p50, label='Total median', linewidth=2)\n",
    "    \n",
    "    sum_p50 = manual_sum.quantile(0.5, dim='samples').values.flatten()\n",
    "    sum_p05 = manual_sum.quantile(0.05, dim='samples').values.flatten()\n",
    "    sum_p95 = manual_sum.quantile(0.95, dim='samples').values.flatten()\n",
    "    ax5.plot(total_years, sum_p50, label='Sum median', \n",
    "            linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax5.set_xlabel('Year')\n",
    "    ax5.set_ylabel('Sea Level Change (mm)')\n",
    "    ax5.set_title('Ensemble Spread (5th-95th percentile)')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Absolute difference\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    abs_diff = np.abs(difference.values)\n",
    "    for idx in sample_indices:\n",
    "        ax6.plot(total_years, abs_diff[idx, :], \n",
    "                label=f'Sample {idx}', linewidth=2)\n",
    "    ax6.set_xlabel('Year')\n",
    "    ax6.set_ylabel('Absolute Difference (mm)')\n",
    "    ax6.set_title('|Total - Sum| by Sample')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.set_yscale('log')\n",
    "    \n",
    "    # Plot 7: Contribution by component (stacked area)\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    # Use ensemble mean for stacking\n",
    "    stack_data = []\n",
    "    labels = []\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        if comp_data.dims != total_data_squeeze.dims:\n",
    "            comp_data = comp_data.transpose(*total_data_squeeze.dims)\n",
    "        comp_mean = comp_data.mean(dim='samples').values\n",
    "        stack_data.append(comp_mean)\n",
    "        labels.append(comp_name)\n",
    "    \n",
    "    ax7.stackplot(total_years, *stack_data, labels=labels, alpha=0.7)\n",
    "    ax7.set_xlabel('Year')\n",
    "    ax7.set_ylabel('Sea Level Change (mm)')\n",
    "    ax7.set_title('Component Contributions (Stacked, Ensemble Mean)')\n",
    "    ax7.legend(loc='upper left')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 8: Relative contribution by component\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    total_abs_mean = np.abs(total_mean.values)\n",
    "    for comp_name, comp_dict in component_data.items():\n",
    "        comp_data = comp_dict['data']\n",
    "        if 'locations' in comp_data.dims:\n",
    "            comp_data = comp_data.squeeze('locations')\n",
    "        if comp_data.dims != total_data_squeeze.dims:\n",
    "            comp_data = comp_data.transpose(*total_data_squeeze.dims)\n",
    "        comp_mean = comp_data.mean(dim='samples').values\n",
    "        # Avoid division by zero\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            rel_contrib = 100 * comp_mean / total_abs_mean\n",
    "            rel_contrib[~np.isfinite(rel_contrib)] = 0\n",
    "        ax8.plot(total_years, rel_contrib, label=comp_name, \n",
    "                linewidth=2, marker='o')\n",
    "    ax8.set_xlabel('Year')\n",
    "    ax8.set_ylabel('Relative Contribution (%)')\n",
    "    ax8.set_title('Relative Component Contributions')\n",
    "    ax8.legend()\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    ax8.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Plot 9: Heatmap of differences across all samples\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    im = ax9.imshow(abs_diff, aspect='auto', cmap='viridis', \n",
    "                    interpolation='nearest')\n",
    "    ax9.set_xlabel('Year Index')\n",
    "    ax9.set_ylabel('Sample Index')\n",
    "    ax9.set_title('Heatmap: |Total - Sum| (all samples)')\n",
    "    plt.colorbar(im, ax=ax9, label='Absolute Difference (mm)')\n",
    "    \n",
    "    plt.suptitle(f'{file_type.upper()} Verification: Total vs Sum of Components\\n' + \n",
    "                 f'Max diff: {max_diff:.2e} mm, Mean diff: {mean_diff:.2e} mm',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_file = Path(output_dir) / f'verification_{file_type}_totals.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved verification plot to: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'max_difference': max_diff,\n",
    "        'mean_difference': mean_diff,\n",
    "        'total_data': total_data_squeeze,\n",
    "        'manual_sum': manual_sum,\n",
    "        'difference': difference\n",
    "    }\n",
    "\n",
    "# Run verification for both LSLR and GSLR\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING SEA LEVEL TOTALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify LSLR\n",
    "lslr_results = verify_totals(output_dir='./data/output', file_type='lslr')\n",
    "\n",
    "# Verify GSLR\n",
    "gslr_results = verify_totals(output_dir='./data/output', file_type='gslr')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"LSLR Max Difference: {lslr_results['max_difference']:.6e} mm\")\n",
    "print(f\"GSLR Max Difference: {gslr_results['max_difference']:.6e} mm\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba26308-8eab-469f-8358-3e0443ec51a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    init_default_logger(logging.DEBUG)\n",
    "\n",
    "    # Create backend and workflow\n",
    "    engine = await ConcurrentExecutionBackend(ThreadPoolExecutor())\n",
    "    flow = await WorkflowEngine.create(engine)\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    def setup_directories():\n",
    "        os.makedirs('./data/output/total', exist_ok=True)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def total_task(component, name):\n",
    "        \"\"\"Facts total task\"\"\"\n",
    "        if (component == 'all'):\n",
    "            cmd = [\n",
    "                '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "                '--bind', './data/input:/mnt/total_in',\n",
    "                '--bind', './data/output:/mnt/total_out',\n",
    "                './containers/sealevel-facts-total_latest-sandbox',\n",
    "                'facts-total',\n",
    "                '--item=/mnt/total_out/lws/'+name+'.nc',\n",
    "                '--item=/mnt/total_out/sterodynamics/'+name+'.nc',\n",
    "                '--pyear-start=2020',\n",
    "                '--pyear-end=2150',\n",
    "                '--pyear-step=10',\n",
    "                '--output-path=/mnt/total_out/totaled_output_all_'+name+'.nc'\n",
    "            ]\n",
    "        else:\n",
    "            cmd = [\n",
    "                '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "                '--bind', './data/input:/mnt/total_in',\n",
    "                '--bind', './data/output:/mnt/total_out',\n",
    "                './containers/sealevel-facts-total_latest-sandbox',\n",
    "                'facts-total',\n",
    "                '--item=/mnt/total_out/'+component+'/'+name+'.nc',\n",
    "                '--pyear-start=2020',\n",
    "                '--pyear-end=2150',\n",
    "                '--pyear-step=10',\n",
    "                '--output-path=/mnt/total_out/totaled_output_'+component+'_'+name+'.nc'\n",
    "            ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    async def run_climate_workflow(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "\n",
    "        # Setup directories\n",
    "        setup_directories()\n",
    "        \n",
    "        # Start total tasks \n",
    "        total_future_lws_lslr = total_task('lws','lslr')\n",
    "        total_future_lws_gslr = total_task('lws','gslr')\n",
    "        total_future_sterodynamics_lslr = total_task('sterodynamics','lslr')\n",
    "        total_future_sterodynamics_gslr = total_task('sterodynamics','gslr')\n",
    "        total_future_all_lslr = total_task('all','lslr')\n",
    "        total_future_all_gslr = total_task('all','gslr')\n",
    "\n",
    "        # Wait for FAIR to complete (sterodynamics depends on it)\n",
    "        total_result_lws_lsr = await total_future_lws_lslr\n",
    "        total_result_lws_gslr = await total_future_lws_gslr\n",
    "        total_result_sterodynamics_lslr = await total_future_sterodynamics_lslr\n",
    "        total_result_sterodynamics_gslr = await total_future_sterodynamics_gslr\n",
    "        total_result_all_lsr = await total_future_all_lslr\n",
    "        total_result_all_gslr = await total_future_all_gslr\n",
    "        logger.info(f'TOTAL task completed for pipeline {pipeline_id}')\n",
    "\n",
    "        logger.info(f'Climate workflow {pipeline_id} finished at {time.time()}')\n",
    "\n",
    "        return {\n",
    "            'total_result_lws_lsr': total_result_lws_lsr,\n",
    "            'total_result_lws_gslr': total_result_lws_gslr,\n",
    "            'total_result_sterodynamics_lslr': total_result_sterodynamics_lslr,\n",
    "            'total_result_sterodynamics_gslr': total_result_sterodynamics_gslr,\n",
    "            'total_result_all_lsr': total_result_lws_lsr,\n",
    "            'total_result_all_gslr': total_result_lws_gslr,\n",
    "        }\n",
    "\n",
    "    # Run workflow(s)\n",
    "    results = await run_climate_workflow(1)\n",
    "    logger.info(\"=========All workflows completed successfully=========\")\n",
    "    logger.info(results)\n",
    "    await flow.shutdown()\n",
    "\n",
    "# Just call it with await in Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbfa87-6f68-44fd-953e-7d7c037bad0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:viz]",
   "language": "python",
   "name": "conda-env-viz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
