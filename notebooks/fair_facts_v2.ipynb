{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df759566-c4d8-4e9d-9cde-ac13f197dfb1",
   "metadata": {},
   "source": [
    "facts-total:\n",
    "- This is a minimal prototype of a total module for summing sealevel rise projections generated from different sources and modules. facts-total is a CLI tool that accepts a path to each netCDF file you would like summed as well as an output path where the summed result will be written. Each input netCDF file represents output from a FACTS sea level component module. It is the responsibility of the user to ensure that the desired and correct files are specified; check that file paths are correct and that each file specified belongs to the same scale ('global' or 'local').\n",
    "\n",
    "- It is possible to run multiple FACTS sea-level components with different default values for common parameters such as pyear-start and pyear-end. If that happens, total will not cause a failure, but will show a message similar to the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce40b51-2dac-4c33-a344-a0cef771229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add a path to the search list\n",
    "sys.path.insert(0, '/discover/nobackup/projects/eis_freshwater/gtamkin/facts2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936d5e34-5ba1-44a4-907e-34a44bce3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /gpfsm/dnb06/projects/p151/gtamkin/facts2.0/notebooks\n",
      "Directory successfully changed to: /gpfsm/dnb06/projects/p151/gtamkin/facts2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get and print the current working directory (optional, for verification)\n",
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "# Change the current working directory to a new path\n",
    "new_directory_path = \"/discover/nobackup/projects/eis_freshwater/gtamkin/facts2.0\" # Example for Linux/macOS\n",
    "# For Windows, you can use forward slashes or a raw string (see below)\n",
    "\n",
    "try:\n",
    "    os.chdir(new_directory_path)\n",
    "    print(f\"Directory successfully changed to: {os.getcwd()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory not found: {new_directory_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb10af8-383b-444d-aa92-e52a19fa40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import shlex\n",
    "\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import ConcurrentExecutionBackend\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from radical.asyncflow.logging import init_default_logger\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba26308-8eab-469f-8358-3e0443ec51a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2026-02-02 10:37:44.480\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[root]\u001b[0m │ Logger configured successfully - Console: DEBUG, File: disabled (N/A), Structured: disabled, Style: modern\n",
      "\u001b[90m2026-02-02 10:37:44.481\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[execution.backend(concurrent)]\u001b[0m │ ThreadPoolExecutor execution backend started successfully\n",
      "\u001b[90m2026-02-02 10:37:44.481\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGHUP\n",
      "\u001b[90m2026-02-02 10:37:44.482\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGTERM\n",
      "\u001b[90m2026-02-02 10:37:44.482\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGINT\n",
      "\u001b[90m2026-02-02 10:37:44.483\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Started run component\n",
      "\u001b[90m2026-02-02 10:37:44.483\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Starting climate workflow 1 at 1770046664.4834452\n",
      "\u001b[90m2026-02-02 10:37:44.488\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered task: 'fair_task' with id of task.000001\n",
      "\u001b[90m2026-02-02 10:37:44.488\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered task: 'lws_task' with id of task.000002\n",
      "\u001b[90m2026-02-02 10:37:44.489\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Ready to submit: fair_task with resolved dependencies: []\n",
      "\u001b[90m2026-02-02 10:37:44.489\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Ready to submit: lws_task with resolved dependencies: []\n",
      "\u001b[90m2026-02-02 10:37:44.490\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['fair_task', 'lws_task'] for execution\n",
      "\u001b[90m2026-02-02 10:38:28.574\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000002 is in DONE state\n",
      "\u001b[90m2026-02-02 10:38:46.731\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000001 is in DONE state\n",
      "\u001b[90m2026-02-02 10:38:46.732\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ FAIR task completed for pipeline 1\n",
      "\u001b[90m2026-02-02 10:38:46.732\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered task: 'sterodynamics_task' with id of task.000003\n",
      "\u001b[90m2026-02-02 10:38:46.732\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Linking implicit file(s): from fair_task to sterodynamics_task\n",
      "\u001b[90m2026-02-02 10:38:46.733\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Ready to submit: sterodynamics_task with resolved dependencies: ['fair_task']\n",
      "\u001b[90m2026-02-02 10:38:46.733\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Submitting ['sterodynamics_task'] for execution\n",
      "\u001b[90m2026-02-02 10:41:28.876\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ task.000003 is in DONE state\n",
      "\u001b[90m2026-02-02 10:41:28.877\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Climate workflow 1 finished at 1770046888.8776252\n",
      "\u001b[90m2026-02-02 10:41:28.877\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ All workflows completed successfully\n",
      "\u001b[90m2026-02-02 10:41:28.878\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ {'fair': 'Hello from fair-temperature!\\n', 'lws': 'Hello from ssp-landwaterstorage!\\n', 'sterodynamics': 'Hello from tlm-sterodynamics!\\n'}\n",
      "\u001b[90m2026-02-02 10:41:28.878\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Initiating shutdown\n",
      "\u001b[90m2026-02-02 10:41:28.878\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Shutting down run component\n",
      "\u001b[90m2026-02-02 10:41:28.879\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Run component cancelled\n",
      "\u001b[90m2026-02-02 10:41:28.879\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[execution.backend(concurrent)]\u001b[0m │ Concurrent execution backend shutdown complete\n",
      "\u001b[90m2026-02-02 10:41:28.879\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Shutting down execution backend completed\n",
      "\u001b[90m2026-02-02 10:41:28.879\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Shutdown completed for all components.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    init_default_logger(logging.DEBUG)\n",
    "\n",
    "    # Create backend and workflow\n",
    "    engine = await ConcurrentExecutionBackend(ThreadPoolExecutor())\n",
    "    flow = await WorkflowEngine.create(engine)\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    def setup_directories():\n",
    "        os.makedirs('./data/output/fair', exist_ok=True)\n",
    "        os.makedirs('./data/output/lws', exist_ok=True)\n",
    "        os.makedirs('./data/output/sterodynamics', exist_ok=True)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def fair_task():\n",
    "        \"\"\"FAIR temperature model task\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/fair:/output',\n",
    "            './containers/fair-temperature.sif',\n",
    "            'fair-temperature',\n",
    "            '--pipeline-id=1234',\n",
    "            '--output-oceantemp-file=/output/oceantemp.nc',\n",
    "            '--nsamps=20',\n",
    "            '--output-ohc-file=/output/ohc.nc',\n",
    "            '--output-gsat-file=/output/gsat.nc',\n",
    "            '--output-climate-file=/output/climate.nc',\n",
    "            '--rcmip-file=/input/rcmip/rcmip-emissions-annual-means-v5-1-0.csv',\n",
    "            '--param-file=/input/parameters/fair_ar6_climate_params_v4.0.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def lws_task():\n",
    "        \"\"\"Land Water Storage task - can run independently of FAIR\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/lws:/output',\n",
    "            './containers/ssp-landwaterstorage.sif',\n",
    "            'ssp-landwaterstorage',\n",
    "            '--pipeline-id=1234',\n",
    "            '--nsamps=20',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--pophist-file=/input/UNWPP2012 population historical.csv',\n",
    "            '--reservoir-file=/input/Chao2008 groundwater impoundment.csv',\n",
    "            '--popscen-file=/input/ssp_iam_baseline_popscenarios2100.csv',\n",
    "            '--gwd-file=/input/Konikow2011 GWD.csv',\n",
    "            '--gwd-file=/input/Wada2012 GWD.csv',\n",
    "            '--gwd-file=/input/Pokhrel2012 GWD.csv',\n",
    "            '--fp-file=/input/REL_GROUNDWATER_NOMASK.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def sterodynamics_task(fair_task):\n",
    "        \"\"\"Sterodynamics task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/output/fair:/fair',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/sterodynamics:/output',\n",
    "            '--nv',\n",
    "            './containers/tlm-sterodynamics.sif',\n",
    "            'tlm-sterodynamics',\n",
    "            '--pipeline-id=1234',\n",
    "            '--scenario=ssp585',\n",
    "            '--nsamps=20',\n",
    "            '--model-dir=/input/cmip6/',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--expansion-coefficients-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n18_expcoefs.nc',\n",
    "            '--gsat-rmses-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n17_gsat_rmse.nc',\n",
    "            '--climate-data-file=/fair/climate.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    async def run_climate_workflow(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "\n",
    "        # Setup directories\n",
    "        setup_directories()\n",
    "\n",
    "        # Start FAIR and LWS tasks (they can run in parallel)\n",
    "        fair_future = fair_task()\n",
    "        lws_future = lws_task()\n",
    "\n",
    "        # Wait for FAIR to complete (sterodynamics depends on it)\n",
    "        fair_result = await fair_future\n",
    "        logger.info(f'FAIR task completed for pipeline {pipeline_id}')\n",
    "\n",
    "        # Start sterodynamics task (depends on FAIR output)\n",
    "        sterodynamics_future = sterodynamics_task(fair_future)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        lws_result = await lws_future\n",
    "        sterodynamics_result = await sterodynamics_future\n",
    "\n",
    "        logger.info(f'Climate workflow {pipeline_id} finished at {time.time()}')\n",
    "\n",
    "        return {\n",
    "            'fair': fair_result,\n",
    "            'lws': lws_result,\n",
    "            'sterodynamics': sterodynamics_result\n",
    "        }\n",
    "\n",
    "    # Run workflow(s)\n",
    "    results = await run_climate_workflow(1)\n",
    "    logger.info(\"All workflows completed successfully\")\n",
    "    logger.info(results)\n",
    "    await flow.shutdown()\n",
    "\n",
    "# Just call it with await in Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f5413-9ae7-4043-99c2-f0b90d039b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m2026-02-03 10:52:57.486\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[root]\u001b[0m │ Logger configured successfully - Console: DEBUG, File: disabled (N/A), Structured: disabled, Style: modern\n",
      "\u001b[90m2026-02-03 10:52:57.487\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[execution.backend(concurrent)]\u001b[0m │ ThreadPoolExecutor execution backend started successfully\n",
      "\u001b[90m2026-02-03 10:52:57.487\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGHUP\n",
      "\u001b[90m2026-02-03 10:52:57.487\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGTERM\n",
      "\u001b[90m2026-02-03 10:52:57.488\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Registered signal handler for SIGINT\n",
      "\u001b[90m2026-02-03 10:52:57.488\u001b[0m │ \u001b[96mDEBUG\u001b[0m │ \u001b[38;5;165m[workflow_manager]\u001b[0m │ Started run component\n",
      "\u001b[90m2026-02-03 10:52:57.488\u001b[0m │ \u001b[94mINFO\u001b[0m │ \u001b[38;5;165m[main]\u001b[0m │ Starting climate workflow 1 at 1770133977.4888594\n"
     ]
    }
   ],
   "source": [
    "async def main_emulandice():\n",
    "    init_default_logger(logging.DEBUG)\n",
    "\n",
    "    # Create backend and workflow\n",
    "    engine = await ConcurrentExecutionBackend(ThreadPoolExecutor())\n",
    "    flow = await WorkflowEngine.create(engine)\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    def setup_directories():\n",
    "        os.makedirs('./data/output/fair', exist_ok=True)\n",
    "        os.makedirs('./data/output/lws', exist_ok=True)\n",
    "        os.makedirs('./data/output/sterodynamics', exist_ok=True)\n",
    "        os.makedirs('./data/output/emulandice', exist_ok=True)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def fair_task():\n",
    "        \"\"\"FAIR temperature model task\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/fair:/output',\n",
    "            './containers/fair-temperature-sandbox',\n",
    "            'fair-temperature',\n",
    "            '--pipeline-id=1234',\n",
    "            '--output-oceantemp-file=/output/oceantemp.nc',\n",
    "            '--nsamps=20',\n",
    "            '--output-ohc-file=/output/ohc.nc',\n",
    "            '--output-gsat-file=/output/gsat.nc',\n",
    "            '--output-climate-file=/output/climate.nc',\n",
    "            '--rcmip-file=/input/rcmip/rcmip-emissions-annual-means-v5-1-0.csv',\n",
    "            '--param-file=/input/parameters/fair_ar6_climate_params_v4.0.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def lws_task():\n",
    "        \"\"\"Land Water Storage task - can run independently of FAIR\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/lws:/output',\n",
    "            './containers/ssp-landwaterstorage-sandbox',\n",
    "            'ssp-landwaterstorage',\n",
    "            '--pipeline-id=1234',\n",
    "            '--nsamps=20',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--pophist-file=/input/UNWPP2012 population historical.csv',\n",
    "            '--reservoir-file=/input/Chao2008 groundwater impoundment.csv',\n",
    "            '--popscen-file=/input/ssp_iam_baseline_popscenarios2100.csv',\n",
    "            '--gwd-file=/input/Konikow2011 GWD.csv',\n",
    "            '--gwd-file=/input/Wada2012 GWD.csv',\n",
    "            '--gwd-file=/input/Pokhrel2012 GWD.csv',\n",
    "            '--fp-file=/input/REL_GROUNDWATER_NOMASK.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def sterodynamics_task(fair_task):\n",
    "        \"\"\"Sterodynamics task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/output/fair:/fair',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/sterodynamics:/output',\n",
    "            '--nv',\n",
    "            './containers/tlm-sterodynamics-sandbox',\n",
    "            'tlm-sterodynamics',\n",
    "            '--pipeline-id=1234',\n",
    "            '--scenario=ssp585',\n",
    "            '--nsamps=20',\n",
    "            '--model-dir=/input/cmip6/',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--expansion-coefficients-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n18_expcoefs.nc',\n",
    "            '--gsat-rmses-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n17_gsat_rmse.nc',\n",
    "            '--climate-data-file=/fair/climate.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def emulandice_ais_task(fair_task):\n",
    "        \"\"\"Emulandice AIS task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input/:ro',\n",
    "            '--bind', './data/output:/output',\n",
    "            '--nv',\n",
    "            './containers/emulandice-sandbox',\n",
    "            'ais',\n",
    "            '--pipeline-id=1234',\n",
    "            '--fprint-wais-file=\"/input/FPRINT/fprint_wais.nc',\n",
    "            '--fprint-eais-file=\"/input/FPRINT/fprint_eais.nc',\n",
    "            '--input-data-file=\"/output/fair/gsat.nc',\n",
    "            '--location-file=\"/input/location.lst',\n",
    "            '--output-gslr-file=\"/output/emulandice/gslr.nc',\n",
    "            '--output-lslr-file=\"/output/emulandice/lslr.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def emulandice_gris_task(fair_task):\n",
    "        \"\"\"Emulandice GRIS task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input/:ro',\n",
    "            '--bind', './data/output:/output',\n",
    "            '--nv',\n",
    "            './containers/emulandice-sandbox',\n",
    "            'gris',\n",
    "            '--pipeline-id=1234',\n",
    "            '--fprint-gis-file=\"/input/FPRINT/fprint_gis.nc',\n",
    "            '--input-data-file=\"/output/fair/gsat.nc',\n",
    "            '--location-file=\"/input/location.lst',\n",
    "            '--output-gslr-file=\"/output/emulandice/gslr.nc',\n",
    "            '--output-lslr-file=\"/output/emulandice/lslr.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "  # --fprint-glacier-dir=\"/input/FPRINT\" \\\n",
    "  # --fprint-map-file=\"/input/fingerprint_region_map.csv\" \\\n",
    "  # --input-data-file=\"/input/gsat.nc\" \\\n",
    "  # --location-file=\"/input/location.lst\" \\\n",
    "  # --output-gslr-file=\"/output/gslr.nc\" \\\n",
    "  # --output-lslr-file=\"/output/lslr.nc\" \\\n",
    "  # --output-glacier-dir=\"/output/glacier\"\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def emulandice_glacier_task(fair_task):\n",
    "        \"\"\"Emulandice glacier task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input/:ro',\n",
    "            '--bind', './data/output:/output',\n",
    "            '--nv',\n",
    "            './containers/emulandice-sandbox',\n",
    "            'glaciers',\n",
    "            '--pipeline-id=1234',\n",
    "            '--fprint-glacier-dir=\"/input/FPRINT',\n",
    "            '--input-data-file=\"/output/fair/gsat.nc',\n",
    "            '--location-file=\"/input/location.lst',\n",
    "            '--output-gslr-file=\"/output/emulandice/gslr.nc',\n",
    "            '--output-lslr-file=\"/output/emulandice/lslr.nc',\n",
    "            '--output-glacier-dir=\"/output/glacier'\n",
    "        ]\n",
    "        print(cmd)\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    \n",
    "    async def run_climate_workflow(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "\n",
    "        # Setup directories\n",
    "        setup_directories()\n",
    "        \n",
    "        # emulandice_future = emulandice_ais_task()\n",
    "        emulandice_future = emulandice_glacier_task()\n",
    "        emulandice_result = await emulandice_future\n",
    "        logger.info(f'EMULANDICE task completed for pipeline {pipeline_id}')\n",
    "        \n",
    "        # Start FAIR and LWS tasks (they can run in parallel)\n",
    "        fair_future = fair_task()\n",
    "        lws_future = lws_task()\n",
    "\n",
    "        # Wait for FAIR to complete (sterodynamics depends on it)\n",
    "        fair_result = await fair_future\n",
    "        logger.info(f'FAIR task completed for pipeline {pipeline_id}')\n",
    "\n",
    "        # Start sterodynamics task (depends on FAIR output)\n",
    "        sterodynamics_future = sterodynamics_task(fair_future)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        lws_result = await lws_future\n",
    "        sterodynamics_result = await sterodynamics_future\n",
    "\n",
    "        logger.info(f'Climate workflow {pipeline_id} finished at {time.time()}')\n",
    "\n",
    "        return {\n",
    "            'fair': fair_result,\n",
    "            'lws': lws_result,\n",
    "            'sterodynamics': sterodynamics_result,\n",
    "            'emulandice': emulandice_result\n",
    "        }\n",
    "\n",
    "    # Run workflow(s)\n",
    "    results = await run_climate_workflow(1)\n",
    "    logger.info(\"All workflows completed successfully\")\n",
    "    logger.info(results)\n",
    "    await flow.shutdown()\n",
    "\n",
    "# Just call it with await in Jupyter\n",
    "await main_emulandice()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981da7d-7a27-4076-8862-4c4c8dc11e07",
   "metadata": {},
   "source": [
    "Revised Example from ChatGSFC - 01/20/2026 - 10:16 AM:\n",
    "- https://chat.gsfc.nasa.gov/c/25924100-fa4e-4543-b5dd-debc29cfe648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ea4a2-e1ac-4c55-923a-fb52c92d4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_inputs():\n",
    "    required_files = [\n",
    "        './containers/fair-temperature.sif',\n",
    "        './containers/ssp-landwaterstorage.sif',\n",
    "        './containers/tlm-sterodynamics.sif',\n",
    "        './data/input/rcmip/rcmip-emissions-annual-means-v5-1-0.csv',\n",
    "        # ... add other critical files\n",
    "    ]\n",
    "    \n",
    "    missing = [f for f in required_files if not os.path.exists(f)]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Missing required files: {missing}\")\n",
    "\n",
    "async def main():\n",
    "    init_default_logger(logging.DEBUG)\n",
    "\n",
    "    # Create backend and workflow\n",
    "    engine = await ConcurrentExecutionBackend(ThreadPoolExecutor())\n",
    "    flow = await WorkflowEngine.create(engine)\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    def setup_directories():\n",
    "        os.makedirs('./data/output/fair', exist_ok=True)\n",
    "        os.makedirs('./data/output/lws', exist_ok=True)\n",
    "        os.makedirs('./data/output/sterodynamics', exist_ok=True)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def fair_task():\n",
    "        \"\"\"FAIR temperature model task\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/fair:/output',\n",
    "            './containers/fair-temperature.sif',\n",
    "            'fair-temperature',\n",
    "            '--pipeline-id=1234',\n",
    "            '--output-oceantemp-file=/output/oceantemp.nc',\n",
    "            '--nsamps=20',\n",
    "            '--output-ohc-file=/output/ohc.nc',\n",
    "            '--output-gsat-file=/output/gsat.nc',\n",
    "            '--output-climate-file=/output/climate.nc',\n",
    "            '--rcmip-file=/input/rcmip/rcmip-emissions-annual-means-v5-1-0.csv',\n",
    "            '--param-file=/input/parameters/fair_ar6_climate_params_v4.0.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def lws_task():\n",
    "        \"\"\"Land Water Storage task - can run independently of FAIR\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/lws:/output',\n",
    "            './containers/ssp-landwaterstorage.sif',\n",
    "            'ssp-landwaterstorage',\n",
    "            '--pipeline-id=1234',\n",
    "            '--nsamps=20',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--pophist-file=/input/UNWPP2012 population historical.csv',\n",
    "            '--reservoir-file=/input/Chao2008 groundwater impoundment.csv',\n",
    "            '--popscen-file=/input/ssp_iam_baseline_popscenarios2100.csv',\n",
    "            '--gwd-file=/input/Konikow2011 GWD.csv',\n",
    "            '--gwd-file=/input/Wada2012 GWD.csv',\n",
    "            '--gwd-file=/input/Pokhrel2012 GWD.csv',\n",
    "            '--fp-file=/input/REL_GROUNDWATER_NOMASK.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    @flow.executable_task\n",
    "    async def sterodynamics_task(fair_task):\n",
    "        \"\"\"Sterodynamics task - depends on FAIR output\"\"\"\n",
    "        cmd = [\n",
    "            '/usr/local/other/singularity/4.0.3/bin/singularity', 'exec',\n",
    "            '--bind', './data/output/fair:/fair',\n",
    "            '--bind', './data/input:/input',\n",
    "            '--bind', './data/output/sterodynamics:/output',\n",
    "            '--nv',\n",
    "            './containers/tlm-sterodynamics.sif',\n",
    "            'tlm-sterodynamics',\n",
    "            '--pipeline-id=1234',\n",
    "            '--scenario=ssp585',\n",
    "            '--nsamps=20',\n",
    "            '--model-dir=/input/cmip6/',\n",
    "            '--location-file=/input/location.lst',\n",
    "            '--output-lslr-file=/output/lslr.nc',\n",
    "            '--output-gslr-file=/output/gslr.nc',\n",
    "            '--expansion-coefficients-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n18_expcoefs.nc',\n",
    "            '--gsat-rmses-file=/input/scmpy2LM_RCMIP_CMIP6calpm_n17_gsat_rmse.nc',\n",
    "            '--climate-data-file=/fair/climate.nc'\n",
    "        ]\n",
    "        return shlex.join(cmd)\n",
    "\n",
    "    async def run_climate_workflow(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "\n",
    "        # Setup directories\n",
    "        setup_directories()\n",
    "\n",
    "        # Start FAIR and LWS tasks (they can run in parallel)\n",
    "        fair_future = fair_task()\n",
    "        lws_future = lws_task()\n",
    "\n",
    "        # Wait for FAIR to complete (sterodynamics depends on it)\n",
    "        fair_result = await fair_future\n",
    "        logger.info(f'FAIR task completed for pipeline {pipeline_id}')\n",
    "\n",
    "        # Start sterodynamics task (depends on FAIR output)\n",
    "        sterodynamics_future = sterodynamics_task(fair_future)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        lws_result = await lws_future\n",
    "        sterodynamics_result = await sterodynamics_future\n",
    "\n",
    "        logger.info(f'Climate workflow {pipeline_id} finished at {time.time()}')\n",
    "\n",
    "        return {\n",
    "            'fair': fair_result,\n",
    "            'lws': lws_result,\n",
    "            'sterodynamics': sterodynamics_result\n",
    "        }\n",
    "\n",
    "    async def run_climate_workflow2(pipeline_id):\n",
    "        \"\"\"Run the complete climate workflow2\"\"\"\n",
    "        logger.info(f'Starting climate workflow {pipeline_id} at {time.time()}')\n",
    "        \n",
    "        try:\n",
    "            # Setup and validate\n",
    "            setup_directories()\n",
    "            validate_inputs()\n",
    "            \n",
    "            # Start FAIR and LWS tasks (parallel)\n",
    "            fair_future = fair_task(pipeline_id)\n",
    "            lws_future = lws_task(pipeline_id)\n",
    "            \n",
    "            # Wait for FAIR (sterodynamics depends on it)\n",
    "            fair_result = await fair_future\n",
    "            logger.info(f'FAIR task completed for pipeline {pipeline_id}')\n",
    "            \n",
    "            # Start sterodynamics (depends on FAIR)\n",
    "            sterodynamics_future = sterodynamics_task(pipeline_id, fair_future)\n",
    "            \n",
    "            # Wait for remaining tasks\n",
    "            lws_result, sterodynamics_result = await asyncio.gather(\n",
    "                lws_future, \n",
    "                sterodynamics_future\n",
    "            )\n",
    "            \n",
    "            logger.info(f'Climate workflow {pipeline_id} completed at {time.time()}')\n",
    "            \n",
    "            return {\n",
    "                'pipeline_id': pipeline_id,\n",
    "                'fair': fair_result,\n",
    "                'lws': lws_result,\n",
    "                'sterodynamics': sterodynamics_result,\n",
    "                'status': 'success'\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f'Workflow {pipeline_id} failed: {str(e)}', exc_info=True)\n",
    "            return {\n",
    "                'pipeline_id': pipeline_id,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }    # Run workflow(s)\n",
    "    \n",
    "    results = await run_climate_workflow(1)\n",
    "    logger.info(\"Workflow#1 completed successfully\")\n",
    "    logger.info(results)\n",
    "\n",
    "    results = await run_climate_workflow2(1)\n",
    "    logger.info(\"Workflow#2 completed successfully\")\n",
    "    logger.info(results)\n",
    "\n",
    "    await flow.shutdown()\n",
    "\n",
    "# Just call it with await in Jupyter\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a2bfb-d26d-4399-b852-92103184ef57",
   "metadata": {},
   "source": [
    "Overview"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9a9d3b2-778d-4c98-97cb-75bd6365563e",
   "metadata": {},
   "source": [
    "Output from ChatGSFC review of this notebook on ~01/01/2026:\n",
    "\n",
    "This is an excellent data assimilation research workflow! You've implemented a comprehensive system for:\n",
    "1.\tIntegrating observations into ERA5 background fields\n",
    "2.\tRunning GraphCast with modified initial conditions\n",
    "3.\tAnalyzing the impact on model predictions\n",
    "This is exactly the type of Neural State Estimation research that advances both traditional data assimilation and machine learning weather prediction.\n",
    "Key Strengths of Your Implementation\n",
    "Methodology\n",
    "•\tPressure level windowing (±10 hPa) follows good DA practices\n",
    "•\tCell averaging handles multiple observations per grid cell appropriately\n",
    "•\tDirect replacement approach is clean for initial experiments\n",
    "•\tComprehensive visualization for validation\n",
    "Analysis Pipeline\n",
    "•\tSource modification comparison (ERA5 vs ERA5+OBS)\n",
    "•\tPrediction impact assessment (GraphCast output differences)\n",
    "•\tMulti-level capability (500, 850, 925 hPa)\n",
    "Research Insights From Your Results\n",
    "Temperature Field Modifications\n",
    "Your plots show that observation-based modifications create:\n",
    "•\tLocalized temperature adjustments where observations differ from ERA5\n",
    "•\tSpatially coherent patterns suggesting realistic observation influence\n",
    "•\tMagnitude-appropriate changes (±0.5K range is meteorologically reasonable)\n",
    "Prediction Impact\n",
    "The prediction differences (±0.05K) indicate:\n",
    "•\tPropagation of initial condition changes through GraphCast\n",
    "•\tPhysical consistency in how the neural model responds to modifications\n",
    "•\tPotential for systematic bias correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a107c-c706-4ca5-a4b5-5d88186a9351",
   "metadata": {},
   "source": [
    "Specific Prototype Goal:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f383874e-dbcd-415a-9744-17e234ece771",
   "metadata": {},
   "source": [
    "After running GraphCast with a specific ERA5 source input file (i.e., source-era5_date-2022-01-01_res-1.0_levels-13_steps-01), modify this input with observational values (i.e., e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4) for a specific variable (i.e., temperature) at the same time (i.e., 220101_00z) and pressure value (i.e., 850 hPa) across levels. Rerun GraphCast and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1343df-4cde-429d-9750-dc6105765431",
   "metadata": {},
   "source": [
    "Workflow (GI=Graphcast Initial Source file, OB=Obs_*_ges):  \n",
    "1. As per conversation with Amal & Mark, \n",
    "2.\tFor each Pressure level in GI\n",
    "    * Aggregate OB values between +/-10 of GI level \n",
    "    * For example, where GI=850, get all OB value between 840 and 860\n",
    "    * Average these OB values\n",
    "3.  Replace the corresponding GI value with this average\n",
    "4.\tSave results as new NetCDF GI file \n",
    "5.\tRun GraphCast prediction with new GI file\n",
    "6.\tCompare prediction results with results from original GI file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526fcab-720a-46c1-bb11-b5fac9e949d7",
   "metadata": {},
   "source": [
    "Notes from Amal/Mark discussion: \n",
    "1. The 'Observation\" column in the OB file contains the raw variable values\n",
    "2. Kx index needs to be involved, but not for 1st prototype\n",
    "3.\tUse range of +/- 10 when mapping OBS pressure to GI.  So, if GI is 850, take OBS 840 to 860\n",
    "4.\tConventional (u,v,q,t,s) variables are more important in the short-term than non-conventional\n",
    "5.  Radiosondes have a range of data because they collect data in a moving column\n",
    "6.\tERA5/GI is a subset of pressure levels in OBS (13 vs. > 13)\n",
    "7.\tMap OBS temperature to 1D Temperature in GI, not 2TM\n",
    "8.\tOverride existing values in GI with average range, not all values between levels\n",
    "9.\tThe landmask variable [1,0] indicates whether cell is over land or not (not used in prototype)\n",
    "10.\tIterate with one variable replacement at a time staring with Pressure = 850\n",
    "11.\tTime [-3..3] delta from Xz (not used for prototype because it will be in 6hr batches like GI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd16ef2-5c0e-495f-ac4b-6c1beaed4a84",
   "metadata": {},
   "source": [
    "ToDo:  \n",
    "1. Add support for multiple levels\n",
    "2. Add support for multiple variables\n",
    "3. Add support for multiple time steps\n",
    "4. Enhance QA\n",
    "5. Add visualization for scattered and gridded values\n",
    "6. Containerize workflow functionality\n",
    "7. Make inputs configurable (e.g., variable, pressure level(s) of interest, time, etc.)\n",
    "8. Replace Data Dictionary below with configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdc905-8005-44c5-8a4a-7248855d17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import xarray as xr\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt # Optional: for visualization\n",
    "import cartopy.crs as ccrs\n",
    "import hvplot.xarray\n",
    "from pathlib import Path\n",
    "import subprocess,os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f79cb-536c-41a0-9055-1963f54564c8",
   "metadata": {},
   "source": [
    "Specify input files:\n",
    "     OB_file = Global observation file that contains the Temperature parameter at a specific timestep and pressure level (850 hPa)\n",
    "     GI_file = Global ERA5 source input file for GraphCast at the same timestep (superset of parameters at 13 levels)\n",
    "     GI_OBS_file  = GI_file containing Temperature values overridden by corresponding lat/lon cell averages from the 840-860 level range in OB_file\n",
    "\n",
    "NOTES/ASSUMPTIONS: \n",
    "- Since the input files have the same lat/lon values, regridding is not necessary.  \n",
    "- The OB_file usually contains multiple levels & parameter values per lat/lon cell\n",
    "- We are collecting these values within a window of level +/- 10 degrees as specified by Amal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdb49c-29f5-4752-b948-0d7be154f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec1af1-f9fd-4662-8790-73a47b8765f4",
   "metadata": {},
   "source": [
    "<!-- /discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_aura_t_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_ges.20220101_00z.bin\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_gps_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_prof_t_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_prof_uv_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_ps_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_q_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_tcp_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4\n",
    "/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_uv_ges.20220101_00z.nc4 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cad5c5-0921-4b06-9e1f-db2debb7f713",
   "metadata": {},
   "source": [
    "Data Dictionary \n",
    "- Modify values in the next two cells to direct Notebook\n",
    "- See comments for variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35bf2f-54dd-4c43-b521-2364672d4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Indices into dataset wih [example value]\n",
    "index_short_name = 0 #['t']\n",
    "index_long_name = 1 #['Temperature']\n",
    "index_level_of_interest = 2 # level value in dataset [850] \n",
    "index_GI_level = 3 # level scalar index in dataset [10] \n",
    "index_lower_bound = 4 # upper bound of window range above 'index_level_of_interest' [10]\n",
    "index_upper_bound = 5 # lower bound of window range below 'index_level_of_interest' [10]\n",
    "index_OB_scale_factor = 6 # align level value with OBS units [100]\n",
    "index_OB_file = 7 # index of OB file in OB dataset catalog where key = variable+level\n",
    "index_GI_file = 8 # index of GI file in GI dataset catalog where key = variable+level\n",
    "index_GI_OBS_file = 9 # index of GI OBS file in GI OBS dataset catalog where key = variable+level\n",
    "index_GI_PRED_file = 10 # index of GI PRED file (original) in GI PRED dataset catalog where key = variable+level\n",
    "index_GI_OBS_PRED_file = 11 # index of GI PRED OBS file (obs-modified GI) in GI PRED dataset catalog where key = variable+level\n",
    "\n",
    "ds_obs = {} # dataset catalog for obs [OBS] files\n",
    "ds_gis = {} # dataset catalog for original GraphCast input (GI)\n",
    "ds_gi_mods = {} # dataset catalog for modified GraphCast input (GI)\n",
    "cell_averages_obs = {} # collection of averaged observation values\n",
    "cell_averages_gi = {} # collection of GI cells to be updated with cell_averages_obs\n",
    "subdir = '20260108b' # directory name for output\n",
    "container = '/discover/nobackup/projects/QEFM/qefm-core/../containers/qefm-core-debian-all-aifs-20250609-sandbox' # Graphcast runtime\n",
    "override = True # # Flag indicating whether to overwrite outputs (set to False for faster execution)\n",
    "show_scatter_plot = True # Flag for scatter plot of observation values\n",
    "current_dd = None\n",
    "\n",
    "output_dir = '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/' # root output directory\n",
    "os.makedirs(output_dir, exist_ok=True) # create output path it non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b552b1c-5735-4e4a-a267-0658db5fd31b",
   "metadata": {},
   "source": [
    "Define metadata for run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd75c8-828e-4eed-99aa-bcd7d3e197c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_850 = [\n",
    "  ['t', # short name\n",
    "  'temperature', # long name\n",
    "  850, # primary level of interest in OBS file (hPa)\n",
    "  10, # level index in GI ERA5 (int)\n",
    "  10, # lower bound (window around primary level (degrees)\n",
    "  10, # upper bound (window around primary level (degrees)\n",
    "  100, # OBS scale factor\n",
    "  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_850.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/qefm/models/checkpoints/graphcast/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_850.nc',\n",
    " ],\n",
    "]\n",
    "\n",
    "dd_single = [\n",
    "  ['t', # short name\n",
    "  'temperature', # long name\n",
    "  500, # primary level of interest in OBS file (hPa)\n",
    "  7, # level index in GI ERA5 (int)\n",
    "  10, # lower bound (window around primary level (degrees)\n",
    "  10, # upper bound (window around primary level (degrees)\n",
    "  100, # OBS scale factor\n",
    "  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_500.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/qefm/models/checkpoints/graphcast/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_500.nc',\n",
    " ],\n",
    "]\n",
    "\n",
    "dd_multi = [\n",
    "  ['t', # short name\n",
    "  'temperature', # long name\n",
    "  500, # primary level of interest in OBS file (hPa)\n",
    "  7, # level index in GI ERA5 (int)\n",
    "  10, # lower bound (window around primary level (degrees)\n",
    "  10, # upper bound (window around primary level (degrees)\n",
    "  100, # OBS scale factor\n",
    "  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_500.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/qefm/models/checkpoints/graphcast/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_500.nc',\n",
    " ],\n",
    "  ['t', # short name\n",
    "  'temperature', # long name\n",
    "  850, # primary level of interest in OBS file (hPa)\n",
    "  10, # level index in GI ERA5 (int)\n",
    "  10, # lower bound (window around primary level (degrees)\n",
    "  10, # upper bound (window around primary level (degrees)\n",
    "  100, # OBS scale factor\n",
    "  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_850.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/qefm/models/checkpoints/graphcast/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_850.nc',\n",
    " ],\n",
    "  ['t', # short name\n",
    "  'temperature', # long name\n",
    "  925, # primary level of interest in OBS file (hPa)\n",
    "  11, # level index in GI ERA5 (int)\n",
    "  10, # lower bound (window around primary level (degrees)\n",
    "  10, # upper bound (window around primary level (degrees)\n",
    "  100, # OBS scale factor\n",
    "  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_925.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/qefm/models/checkpoints/graphcast/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',\n",
    "  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/'+subdir+'/pred-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_925.nc',\n",
    " ],\n",
    " #  ['t', # short name\n",
    " #  'temperature', # long name\n",
    " #  1000, # primary level of interest in OBS file (hPa)\n",
    " #  12, # level index in GI ERA5 (int)\n",
    " #  10, # lower bound (window around primary level (degrees)\n",
    " #  10, # upper bound (window around primary level (degrees)\n",
    " #  100, # OBS scale factor\n",
    " #  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_t_ges.20220101_00z.nc4', # OB\n",
    " #  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc', # GI\n",
    " #  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_1000.nc',\n",
    " # ],\n",
    " # ['q', # short name\n",
    " #  'specific_humidity', # long name\n",
    " #  850, # primary level of interest in OBS file (hPa)\n",
    " #  10, # level index in GI ERA5 (int)\n",
    " #  10, # lower bound (window around primary level (degrees)\n",
    " #  10, # upper bound (window around primary level (degrees)\n",
    " #  100, # OBS scale factor\n",
    " #  '/discover/nobackup/projects/gmao/merra21c/TSE_staging/e5303_m21c_jan18/archive/obs/Y2022/M01/D01/H00/e5303_m21c_jan18.diag_conv_q_ges.20220101_00z.nc4', # OB\n",
    " #  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc',# GI\n",
    " #  '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_q_850.nc',\n",
    " # ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ce90f-329f-4065-b131-e078094d2ca1",
   "metadata": {},
   "source": [
    "Show scatter plot of OB values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3811e84-10ec-401a-a602-acd5ae3f5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_OB_scatter_plot(obs_path, long_name):\n",
    "    \n",
    "    ds_ob = xr.open_dataset(obs_path)\n",
    "    observation_values = ds_ob[\"Observation\"].values\n",
    "    lats = ds_ob[\"Latitude\"].values\n",
    "    lons = ds_ob[\"Longitude\"].values\n",
    "    times = ds_ob[\"Time\"].values\n",
    "    values = observation_values\n",
    "    \n",
    "    # 1: Define a single dimension for the unstructured data ---\n",
    "    combined_data = xr.DataArray(\n",
    "        data=observation_values,        # This is 1D data\n",
    "        dims=['nobs'],             # Specify the single dimension name\n",
    "        coords={                        # Attach 1D coordinates to that dimension\n",
    "            'lat': (('nobs',), lats),\n",
    "            'lon': (('nobs',), lons),\n",
    "            'time': (('nobs',), times)\n",
    "        },\n",
    "        name='Observations'\n",
    "    )\n",
    "    \n",
    "    # 2. Create the plot using matplotlib and cartopy for a map\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "    #ax.set_extent([-130, -60, 20, 55])\n",
    "    \n",
    "    #ax.coastlines(resolution='50m')\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    \n",
    "    # 3. Use a SCATTER plot for 1D, unstructured data\n",
    "    # The 'c' argument provides the color mapping based on the observation value\n",
    "    scatter = ax.scatter(lons, lats, c=values, cmap='viridis', s=1, transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add a color bar\n",
    "    plt.colorbar(scatter, label=long_name, ax=ax)\n",
    "    #plt.colorbar(scatter, label=f'{combined_data.name} ({combined_data.units})', ax=ax)\n",
    "    \n",
    "    plt.title(f'Observation Scatter Plot ({values.size} points)')\n",
    "    plt.figtext(0.5, 0.01, f'Observation Plot \\n [{obs_path}]', ha=\"center\", fontsize=10, color=\"blue\")\n",
    "    #(f'Observation Plot \\n [{OB_file}] ({values.size} points)')\n",
    "    plt.show()\n",
    "\n",
    "    return ds_ob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350627e0-6472-40f3-a767-68a40a9b485c",
   "metadata": {},
   "source": [
    "Plot the differences between OB (ERA+OBS) and GI (ERA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012e62a-460f-429e-8981-90f959867042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_era5_obs_differences(era5_file, era5_obs_file, output_dir=None, \n",
    "                             levels=None, parameters=None, \n",
    "                             time_index=0, batch_index=0,\n",
    "                             vmin=-0.5, vmax=0.5, cmap='coolwarm',\n",
    "                             figsize_per_plot=(4, 3), save_plots=True):\n",
    "    \"\"\"\n",
    "    Create difference plots between ERA5 and ERA5+OBS data in rows by level and parameter.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    era5_file : str\n",
    "        Path to original ERA5 file\n",
    "    era5_obs_file : str  \n",
    "        Path to ERA5+OBS modified file\n",
    "    output_dir : str, optional\n",
    "        Directory to save plots (default: same as era5_obs_file directory)\n",
    "    levels : list, optional\n",
    "        Pressure levels to plot (default: all available)\n",
    "    parameters : list, optional\n",
    "        Variables to plot (default: ['temperature', 'specific_humidity'])\n",
    "    time_index : int\n",
    "        Time step index to plot (default: 0)\n",
    "    batch_index : int\n",
    "        Batch index to plot (default: 0)\n",
    "    vmin, vmax : float\n",
    "        Color scale limits for difference plots\n",
    "    cmap : str\n",
    "        Colormap for difference plots\n",
    "    figsize_per_plot : tuple\n",
    "        Size of each subplot (width, height)\n",
    "    save_plots : bool\n",
    "        Whether to save plots to files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing difference datasets and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    # ds_era5 = xr.open_dataset(era5_file)\n",
    "    # ds_era5_obs = xr.open_dataset(era5_obs_file)\n",
    "    ds_era5 = ds_gis[f\"{short_name}_{str(level_of_interest)}_ds\"]\n",
    "    ds_era5_obs = ds_gi_mods[f\"{short_name}_{str(level_of_interest)}_ds\"]\n",
    "    \n",
    "    # Set default parameters if not specified\n",
    "    if parameters is None:\n",
    "        # Find common 3D variables between datasets\n",
    "        common_vars = []\n",
    "        for var in ['temperature', 'specific_humidity', 'geopotential', \n",
    "                   'u_component_of_wind', 'v_component_of_wind']:\n",
    "            if var in ds_era5.data_vars and var in ds_era5_obs.data_vars:\n",
    "                if 'level' in ds_era5[var].dims:\n",
    "                    common_vars.append(var)\n",
    "        parameters = common_vars\n",
    "    \n",
    "    # Set default levels if not specified\n",
    "    if levels is None:\n",
    "        levels = ds_era5.level.values\n",
    "    \n",
    "    # Set output directory\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(era5_obs_file).parent\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Storage for results\n",
    "    results = {\n",
    "        'differences': {},\n",
    "        'statistics': {},\n",
    "        'plots_saved': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Creating plots for {len(parameters)} parameters and {len(levels)} levels...\")\n",
    "    \n",
    "    # Create plots for each parameter\n",
    "    for param_idx, param in enumerate(parameters):\n",
    "        print(f\"Processing parameter: {param}\")\n",
    "        \n",
    "        # Check if parameter exists in both datasets\n",
    "        if param not in ds_era5.data_vars or param not in ds_era5_obs.data_vars:\n",
    "            print(f\"Warning: {param} not found in both datasets, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Check if parameter has level dimension\n",
    "        if 'level' not in ds_era5[param].dims:\n",
    "            print(f\"Warning: {param} has no level dimension, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Filter levels that exist for this parameter\n",
    "        available_levels = ds_era5[param].level.values\n",
    "        plot_levels = [lvl for lvl in levels if lvl in available_levels]\n",
    "        \n",
    "        if not plot_levels:\n",
    "            print(f\"Warning: No matching levels found for {param}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate figure size\n",
    "        n_levels = len(plot_levels)\n",
    "        fig_width = figsize_per_plot[0] * n_levels\n",
    "        fig_height = figsize_per_plot[1]\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(1, n_levels, \n",
    "                                figsize=(fig_width, fig_height),\n",
    "                                subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        \n",
    "        # Handle case where only one level (axes not a list)\n",
    "        if n_levels == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Storage for this parameter's data\n",
    "        param_diffs = {}\n",
    "        param_stats = {}\n",
    "        \n",
    "        # Plot each level\n",
    "        for level_idx, level in enumerate(plot_levels):\n",
    "            ax = axes[level_idx]\n",
    "            \n",
    "            try:\n",
    "                # Extract data for this level and time\n",
    "                era5_data = ds_era5[param].sel(level=level).isel(time=time_index, batch=batch_index)\n",
    "                era5_obs_data = ds_era5_obs[param].sel(level=level).isel(time=time_index, batch=batch_index)\n",
    "                \n",
    "                # Calculate difference (ERA5 - ERA5+OBS)\n",
    "                diff = era5_data - era5_obs_data\n",
    "                \n",
    "                # Store difference data\n",
    "                param_diffs[level] = diff\n",
    "                \n",
    "                # Calculate statistics\n",
    "                stats = {\n",
    "                    'mean': float(diff.mean().values),\n",
    "                    'std': float(diff.std().values),\n",
    "                    'min': float(diff.min().values),\n",
    "                    'max': float(diff.max().values),\n",
    "                    'rmse': float(np.sqrt((diff**2).mean()).values)\n",
    "                }\n",
    "                param_stats[level] = stats\n",
    "                \n",
    "                # Create plot\n",
    "                im = diff.plot(ax=ax, \n",
    "                              transform=ccrs.PlateCarree(),\n",
    "                              vmin=vmin, vmax=vmax, \n",
    "                              cmap=cmap,\n",
    "                              add_colorbar=False)\n",
    "                \n",
    "                # Add map features\n",
    "                ax.coastlines(resolution='50m', alpha=0.5)\n",
    "                ax.gridlines(draw_labels=False, alpha=0.3)\n",
    "                \n",
    "                # Set title for subplot\n",
    "                ax.set_title(f'{level} hPa\\n'\n",
    "                           f'Mean: {stats[\"mean\"]:.3f}\\n'\n",
    "                           f'RMSE: {stats[\"rmse\"]:.3f}', \n",
    "                           fontsize=8)\n",
    "                \n",
    "                print(f\"  Level {level} hPa: Mean diff = {stats['mean']:.4f}, \"\n",
    "                      f\"RMSE = {stats['rmse']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {param} at {level} hPa: {e}\")\n",
    "                ax.text(0.5, 0.5, f'Error\\n{level} hPa', \n",
    "                       transform=ax.transAxes, ha='center', va='center')\n",
    "        \n",
    "        # Add overall title and colorbar\n",
    "        param_clean = param.replace('_', ' ').title()\n",
    "        fig.suptitle(f'{param_clean} Differences (ERA5 - ERA5+OBS)\\n'\n",
    "                    f'Time: {ds_era5.time.values[time_index]} | '\n",
    "                    f'File: {Path(era5_obs_file).name}', \n",
    "                    fontsize=10, y=0.95)\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.tight_layout()\n",
    "        cbar = plt.colorbar(im, ax=axes, orientation='horizontal', \n",
    "                           pad=0.1, shrink=0.8, aspect=30)\n",
    "        cbar.set_label(f'{param_clean} Difference', fontsize=9)\n",
    "        \n",
    "        # Save plot\n",
    "        if save_plots:\n",
    "            plot_filename = f'diff_{param}_levels_era5_vs_era5obs_{short_name}_{str(level_of_interest)}.png'\n",
    "            plot_path = output_dir / plot_filename\n",
    "            plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "            results['plots_saved'].append(str(plot_path))\n",
    "            print(f\"Plot saved: {plot_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Store results\n",
    "        results['differences'][param] = param_diffs\n",
    "        results['statistics'][param] = param_stats\n",
    "    \n",
    "    # Create summary statistics table\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for param in results['statistics']:\n",
    "        print(f\"\\n{param.upper().replace('_', ' ')}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"{'Level (hPa)':<12} {'Mean':<8} {'RMSE':<8} {'Min':<8} {'Max':<8}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for level in sorted(results['statistics'][param].keys(), reverse=True):\n",
    "            stats = results['statistics'][param][level]\n",
    "            print(f\"{level:<12} {stats['mean']:<8.3f} {stats['rmse']:<8.3f} \"\n",
    "                  f\"{stats['min']:<8.3f} {stats['max']:<8.3f}\")\n",
    "    \n",
    "    # Close datasets\n",
    "    ds_era5.close()\n",
    "    ds_era5_obs.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_single_parameter_all_levels(era5_file, era5_obs_file, parameter='temperature',\n",
    "                                   levels=None, time_index=0, batch_index=0,\n",
    "                                   figsize=(15, 3), save_plot=True, output_dir=None):\n",
    "    \"\"\"\n",
    "    Create a single row of plots for one parameter across all levels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    era5_file : str\n",
    "        Path to original ERA5 file\n",
    "    era5_obs_file : str\n",
    "        Path to ERA5+OBS modified file\n",
    "    parameter : str\n",
    "        Variable name to plot\n",
    "    levels : list, optional\n",
    "        Pressure levels to plot (default: all available)\n",
    "    time_index : int\n",
    "        Time step index to plot\n",
    "    batch_index : int\n",
    "        Batch index to plot\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    save_plot : bool\n",
    "        Whether to save the plot\n",
    "    output_dir : str, optional\n",
    "        Directory to save plot\n",
    "    \"\"\"\n",
    "    \n",
    "    return plot_era5_obs_differences(\n",
    "        era5_file=era5_file,\n",
    "        era5_obs_file=era5_obs_file,\n",
    "        output_dir=output_dir,\n",
    "        levels=levels,\n",
    "        parameters=[parameter],\n",
    "        time_index=time_index,\n",
    "        batch_index=batch_index,\n",
    "        figsize_per_plot=(figsize[0]/len(levels) if levels else 3, figsize[1]),\n",
    "        save_plots=save_plot\n",
    "    )\n",
    "\n",
    "def plot_single_parameter_at_level(era5_file, era5_obs_file, parameter='temperature',\n",
    "                                   levels=None, time_index=0, batch_index=0,\n",
    "                                   figsize=(15, 15), save_plot=True, output_dir=None):\n",
    "#                                   figsize=(15, 3), save_plot=True, output_dir=None):\n",
    "    \"\"\"\n",
    "    Create a single row of plots for one parameter across all levels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    era5_file : str\n",
    "        Path to original ERA5 file\n",
    "    era5_obs_file : str\n",
    "        Path to ERA5+OBS modified file\n",
    "    parameter : str\n",
    "        Variable name to plot\n",
    "    levels : list, optional\n",
    "        Pressure levels to plot (default: all available)\n",
    "    time_index : int\n",
    "        Time step index to plot\n",
    "    batch_index : int\n",
    "        Batch index to plot\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    save_plot : bool\n",
    "        Whether to save the plot\n",
    "    output_dir : str, optional\n",
    "        Directory to save plot\n",
    "    \"\"\"\n",
    "    \n",
    "    return plot_era5_obs_differences(\n",
    "        era5_file=era5_file,\n",
    "        era5_obs_file=era5_obs_file,\n",
    "        output_dir=output_dir,\n",
    "        levels=levels,\n",
    "        parameters=[parameter],\n",
    "        time_index=time_index,\n",
    "        batch_index=batch_index,\n",
    "        figsize_per_plot=(figsize[0]/len(levels) if levels else 3, figsize[1]),\n",
    "        save_plots=save_plot\n",
    "    )\n",
    "# Example usage functions for your specific data\n",
    "def analyze_temperature_modifications(era5_file, era5_obs_file, output_dir=None):\n",
    "    \"\"\"\n",
    "    Analyze temperature modifications across multiple pressure levels.\n",
    "    \"\"\"\n",
    "    temp_levels = [200, 300, 500, 700, 850, 925, 1000]  # Common atmospheric levels\n",
    "    \n",
    "    results = plot_era5_obs_differences(\n",
    "        era5_file=era5_file,\n",
    "        era5_obs_file=era5_obs_file,\n",
    "        output_dir=output_dir,\n",
    "        levels=temp_levels,\n",
    "        parameters=['temperature'],\n",
    "        vmin=-1.0, vmax=1.0,  # Adjust range for temperature\n",
    "        figsize_per_plot=(3, 2.5)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_all_modifications(era5_file, era5_obs_file, output_dir=None):\n",
    "    \"\"\"\n",
    "    Analyze all available parameter modifications.\n",
    "    \"\"\"\n",
    "    results = plot_era5_obs_differences(\n",
    "        era5_file=era5_file,\n",
    "        era5_obs_file=era5_obs_file,\n",
    "        output_dir=output_dir,\n",
    "        parameters=['temperature', 'specific_humidity', 'geopotential'],\n",
    "        figsize_per_plot=(2.5, 2)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# # Usage example for your data:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Your file paths\n",
    "#     era5_original = '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/input/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc'\n",
    "#     era5_modified = '/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/graphcast/source-era5_date-2022-01-01_res-1.0_levels-13_steps-01_obs_t_850.nc'\n",
    "    \n",
    "#     # Analyze temperature modifications\n",
    "#     results = analyze_temperature_modifications(\n",
    "#         era5_file=era5_original,\n",
    "#         era5_obs_file=era5_modified,\n",
    "#         output_dir='/discover/nobackup/projects/QEFM/qefm-core/data/NSE/output/plots'\n",
    "#     )\n",
    "    \n",
    "#     # Print summary\n",
    "#     print(\"\\nAnalysis complete!\")\n",
    "#     print(f\"Plots saved: {len(results['plots_saved'])}\")\n",
    "#     for plot_path in results['plots_saved']:\n",
    "#         print(f\"  - {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a718b33-f749-4f4e-8dde-1c0e5089075a",
   "metadata": {},
   "source": [
    "Calculate average value per cell for points that fall within range of the level window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9924596-c73d-4845-b968-c1db0559ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_per_cell(ds_ob, variable, level_of_interest, level_index, lower_bound, upper_bound, scale_factor):\n",
    "    level_of_interest = level_of_interest\n",
    "    level_index_GI = level_index\n",
    "\n",
    "    unscaled_lower_bound = int(level_of_interest) - int(lower_bound)\n",
    "    unscaled_upper_bound = int(level_of_interest) + int(upper_bound)\n",
    "    lower_bound = unscaled_lower_bound * int(scale_factor)\n",
    "    upper_bound = unscaled_upper_bound * int(scale_factor)\n",
    "    \n",
    "    print(\"\\nFilter window: \", lower_bound, \"-\", upper_bound)\n",
    "    filtered_df = ds_ob[['Latitude', 'Longitude', 'Pressure', 'Observation']].to_dataframe()\n",
    "    \n",
    "    #print(filtered_df.head())\n",
    "    filtered_df = filtered_df[(filtered_df['Pressure'] >= lower_bound) & (filtered_df['Pressure'] <= upper_bound)].copy()\n",
    "#    print(filtered_df.head())\n",
    "    \n",
    "    # Calculate the maximum value of the 'observation' column within this range\n",
    "    max_obs = filtered_df['Observation'].max()\n",
    "    min_obs = filtered_df['Observation'].min()\n",
    "    print(f\"The Min observation value for Pressure between {lower_bound} and {upper_bound} is: {min_obs}\")\n",
    "    print(f\"The Max observation value for Pressure between {lower_bound} and {upper_bound} is: {max_obs}\")\n",
    "    \n",
    "    # 1. Use .loc when adding new columns to the copied DataFrame\n",
    "    # Round Latitude and Longitude to the nearest 1.0 degree to define grid cells\n",
    "    filtered_df.loc[:, 'lat_grid'] = filtered_df['Latitude'].round()\n",
    "    filtered_df.loc[:, 'lon_grid'] = (filtered_df['Longitude'] % 360).round()\n",
    "    #TODO:  Consider applying weights here\n",
    "    # 2. Group by the new grid coordinates and calculate the mean\n",
    "    cell_averages = filtered_df.groupby(['lat_grid', 'lon_grid'])['Observation'].mean().reset_index()\n",
    "    \n",
    "    # 3. Optional: Rename columns for clarity\n",
    "    avg_observation_label = \"Avg_Observation_\"+variable+\"_\"+str(level_of_interest)\n",
    "    cell_averages.columns = ['Latitude', 'Longitude', avg_observation_label]\n",
    "    \n",
    "#    print('\\n'+ str(cell_averages.head()))\n",
    "    return cell_averages\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0392bc-2d83-4a3d-861d-47b966a3d72d",
   "metadata": {},
   "source": [
    "Identify cells to be overriden with avg values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def36749-def0-4005-8b77-bb1d1823029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cells(ds_gi, variable, cell_averages, level_of_interest):\n",
    "    # Initialize an empty list to store the GI values\n",
    "    gi_background_values = []\n",
    "    \n",
    "    # Ensure the GI level dimension has the exact value you need\n",
    "    # If 'level' is an int array like [850, ...], this works:\n",
    "    if level_of_interest not in ds_gi.level.values:\n",
    "         raise ValueError(f\"Level {int(level_of_interest)} not found in GI dataset levels: {ds_gi.level.values}\")\n",
    "    \n",
    "    # Loop through each averaged observation cell\n",
    "    for index, row in cell_averages.iterrows():\n",
    "        lat_val = row['Latitude']\n",
    "        lon_val = row['Longitude']\n",
    "    #    if (index == 0): \n",
    "    #        print(\"First row in GI:\\n\", row)\n",
    "            # print(lat_val)\n",
    "            # print(lon_val)\n",
    "        \n",
    "        # Use .sel() with method='nearest' if your rounded grid centers don't perfectly align \n",
    "        # with the exact GI coordinates (which are likely 90, 89, ..., -90)\n",
    "        gi_val = ds_gi.sel(\n",
    "            lat=lat_val, \n",
    "            lon=lon_val, \n",
    "            level=level_of_interest, # Select the specific level you filtered by\n",
    "            time=ds_gi.time.values[0], # Select the first (or relevant) time step\n",
    "            method='nearest' # Ensures it finds the closest GI grid cell value\n",
    "        ).temperature.values\n",
    "        \n",
    "        gi_background_values.append(gi_val)\n",
    "#        if (index == 0): \n",
    "#            print(\"First average in GI:\\n\", lat_val, lon_val, level_of_interest, gi_val)\n",
    "        \n",
    "    # print(\"GI Min/MaxOb: \" + str(min(gi_background_values)) + \" \" + str(max(gi_background_values)) + \" Delta= \" + str(max(gi_background_values) - min(gi_background_values)))\n",
    "    print(\"Number of Points to modify: \" + str(len(gi_background_values)))\n",
    "    \n",
    "    # Add the GI values back to your DataFrame\n",
    "    cell_averages[f\"GI_Background_{variable}_{level_of_interest}\"] = np.array(gi_background_values)\n",
    "#    ds_gis[f\"GI_Background_{short_name}\"] = ds_gi\n",
    "    \n",
    "    #print(\"New cell_averages:\\n\", cell_averages['GI_Background_Temp'].head())\n",
    "    ob_bias_label = 'Observation_Bias_'+variable+'_'+str(level_of_interest)\n",
    "    avg_obs_label =  'Avg_Observation_'+variable+'_'+str(level_of_interest)\n",
    "    gi_background_label =  'GI_Background_'+variable+'_'+str(level_of_interest)\n",
    "    #print(ob_bias_label, avg_obs_label, avg_obs_label, gi_background_label)\n",
    "    cell_averages[ob_bias_label] = cell_averages[avg_obs_label] - cell_averages[gi_background_label]\n",
    "    \n",
    "#    print(cell_averages.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ecd25a-ff7a-4458-91a2-2ecc8515ac8a",
   "metadata": {},
   "source": [
    "Override corresponding values in GI with OBS avg values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b1e70-31b2-49ed-a2a3-a40046195036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def override_cells(ds_gi, variable, cell_averages, level_of_interest, output_path):\n",
    "    # 1. Create a deep copy of GI to avoid modifying the original in-memory data\n",
    "    ds_gi_modified = ds_gi.copy(deep=True)\n",
    "    \n",
    "    # 2. Assign the new values to the dataset\n",
    "    # We assume 'level_of_interest' (e.g., 850) matches a coordinate in ds_gi.level\n",
    "    #level_of_interest = 850 \n",
    "    \n",
    "    # Iterate through the averaged cells and update the 'temperature' variable\n",
    "    for index, row in cell_averages.iterrows():\n",
    "        # .loc allows assignment based on coordinate labels\n",
    "        # if (index == 0): \n",
    "        #     print(row)\n",
    "        ds_gi_modified.temperature.loc[{\n",
    "            'batch': 0, \n",
    "            'time': ds_gi.time.values[0], \n",
    "            'level': level_of_interest,\n",
    "            'lat': row['Latitude'], \n",
    "            'lon': row['Longitude']\n",
    "        }] = row['Avg_Observation_'+variable+\"_\"+str(level_of_interest)]\n",
    "    \n",
    "    # 3. Write the modified dataset to a new NetCDF file\n",
    "    ds_gi_modified.to_netcdf(output_path)\n",
    "    \n",
    "    print(f\"File saved successfully to {output_path}\")\n",
    "    return ds_gi_modified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7480517-4446-4a21-9e6c-cefb686c4b37",
   "metadata": {},
   "source": [
    "Calculate difference between datasets for a specifc variable and level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890df2e-b366-49bb-8356-d09eb6eabc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diff (ds1, ds2, variable_name, level_of_interest, level_index):\n",
    "    \n",
    "    if variable_name in ds1 and variable_name in ds2:\n",
    "        # Calculate the difference: file2 - file1\n",
    "        diff = ds2[variable_name] - ds1[variable_name]\n",
    "    \n",
    "        var1 = ds1[variable_name].isel(time=0).sel(level=level_of_interest)\n",
    "        var2 = ds2[variable_name].isel(time=0).sel(level=level_of_interest)\n",
    "    \n",
    "        diff = var1 - var2\n",
    "    else:\n",
    "        print(f\"Variable '{variable_name}' not found in both files. Check variable names.\")\n",
    "    \n",
    "    difference=diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e54e67-c3eb-4cfb-8e7d-86214a11fee3",
   "metadata": {},
   "source": [
    "Run GraphCast to create new Prediction based on modified input state (GI OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f0457-448c-4baf-964f-ccfa5c406317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graphcast (container, gi_obs_path, gi_obs_pred_path):\n",
    "\n",
    "    if not Path(gi_obs_pred_path).exists() or override:\n",
    "        print(\"Run GraphCast now to create: \", gi_obs_pred_path)\n",
    "        # Construct the command\n",
    "        # 'time' is a shell-builtin, so shell=True is required to use it directly like this\n",
    "        command = (\n",
    "            f\"time /usr/local/other/singularity/4.0.3/bin/singularity exec --nv \"\n",
    "            f\"-B /home/gtamkin,/discover/nobackup/projects/QEFM/qefm-core,/discover/nobackup/gtamkin \"\n",
    "            f\"{container} python /discover/nobackup/projects/QEFM/qefm-core/qefm/models/src/FMGraphCast/fm_graphcast_nse.py \"\n",
    "            f\"{gi_obs_path} {gi_obs_pred_path}\"\n",
    "        )\n",
    "    \n",
    "        # Run the command\n",
    "        subprocess.run(command, shell=True)\n",
    "    else:\n",
    "        print(\"GraphCast prediction exists and override is False. Skipping: \" + gi_obs_pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a298ee-c809-4890-bec7-86c5c3be0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#        MAIN WORKFLOW                          #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f538017-8ff2-43bf-bd90-943187ce02a7",
   "metadata": {},
   "source": [
    "Load observational Temperature parameter values at a specific timestep (20220101_00z) and pressure level window (lower_bound, upper_bound).  Then calculate the mean of these Temperature observational values per cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdb153-18d0-456d-bb97-283663b29296",
   "metadata": {},
   "source": [
    "Load ERA5 Temperature parameter values at a specific timestep (20220101_00z) and pressure level window (lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb8ef4-b199-48e2-bce2-c5af09110fa2",
   "metadata": {},
   "source": [
    "Loop through the cell averages and create a corresponding array to override the GI file wth.  Check the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22144f0-9084-45f0-8f21-1824c95840bb",
   "metadata": {},
   "source": [
    "Loop through lat/lon cells of GI file and replace values with the OBS average per cell calculated above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98afba-35a8-442c-9fab-1ded7821db8c",
   "metadata": {},
   "source": [
    "Calculate difference statistics between original ERA5 source and obs-modified source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca313d13-cff7-4cd1-9e1e-7f1ca955be46",
   "metadata": {},
   "source": [
    "Run GraphCast to produce OBs-augmented prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94176535-6624-4d1e-8df6-1439b59d5cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_dd = dd_multi\n",
    "for entry in current_dd:\n",
    "    short_name   = entry[index_short_name]\n",
    "    long_name    = entry[index_long_name]\n",
    "    obs_path     = entry[index_OB_file]\n",
    "    gi_path      = entry[index_GI_file]\n",
    "    level_of_interest          = entry[index_level_of_interest]\n",
    "    level_index  = entry[index_GI_level]\n",
    "    lower_bound  = entry[index_lower_bound]\n",
    "    upper_bound  = entry[index_upper_bound] \n",
    "    scale_factor = entry[index_OB_scale_factor] \n",
    "    gi_obs_path  = entry[index_GI_OBS_file] \n",
    "    gi_pred_path = entry[index_GI_PRED_file] \n",
    "    gi_obs_pred_path    = entry[index_GI_OBS_PRED_file] \n",
    "    \n",
    "    print(f\"Processing {long_name} ({short_name}) at {level_of_interest}hPa...\")\n",
    "    print(f\" - Observation File: {obs_path}\")\n",
    "    print(f\" - ERA5 Input File:  {gi_path}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Open OB dataset - don't forget to close if unneeded\n",
    "    ds_ob = xr.open_dataset(obs_path)\n",
    "    key_index = f\"{short_name}_{str(level_of_interest)}\"\n",
    "    ds_obs[f\"{key_index}_ds\"] = ds_ob\n",
    "\n",
    "    # Calculate average value per cell at prirmary lovel of interest windo\n",
    "    cell_averages_ob = calculate_avg_per_cell(ds_ob, short_name, level_of_interest, level_index, lower_bound, upper_bound, scale_factor)\n",
    "    cell_averages_obs[f\"{key_index}_ds\"] = cell_averages_ob\n",
    "    \n",
    "    # Open GI dataset - don't forget to close if unneeded\n",
    "    ds_gi = xr.open_dataset(gi_path)\n",
    "    ds_gis[f\"{key_index}_ds\"] = ds_gi\n",
    "   \n",
    "    gi_cell_averages = filter_cells(ds_gi, short_name, cell_averages_ob, level_of_interest)\n",
    "    \n",
    "    ds_gi_mods[f\"{key_index}_ds\"] = override_cells(ds_gi, short_name, cell_averages_ob, level_of_interest, gi_obs_path)\n",
    "\n",
    "    calculate_diff(ds_gi, ds_gi_mods[f\"{key_index}_ds\"], long_name, level_of_interest, level_index)\n",
    "\n",
    "    run_graphcast (container, gi_obs_path, gi_obs_pred_path)\n",
    "    \n",
    "    # Plot variable on current level:\n",
    "    temp_results = plot_single_parameter_at_level(\n",
    "        era5_file=short_name,\n",
    "        era5_obs_file=short_name,\n",
    "        levels=[level_of_interest],\n",
    "        parameter=long_name,\n",
    "        output_dir=output_dir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b747da0-0b0a-4c69-907a-df6119b57cb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef160fb0-8763-43ad-b470-495bfe5dcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a59f3d-b8f4-4b14-96ad-cf056f38943a",
   "metadata": {},
   "source": [
    "Quality Assurance plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d16f6-0562-4331-beab-3fe56ac270b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_scatter_plot == True: \n",
    "    show_OB_scatter_plot(obs_path, long_name)\n",
    "    show_scatter_plot = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0daf59-62af-450a-9df5-dca8c8d0df0d",
   "metadata": {},
   "source": [
    "Compare Prediction results in output netcdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b6184-bab4-4cd1-a6b9-d09607255f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_multi_level_impact_optimized(ds_original, ds_modified, levels=[500, 850, 925], \n",
    "                                       parameter='temperature', figsize=(15, 4)):\n",
    "    \"\"\"\n",
    "    Optimized analysis of multi-level observation impacts with single-row visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds_original : xarray.Dataset\n",
    "        Original ERA5 dataset\n",
    "    ds_modified : xarray.Dataset  \n",
    "        Modified ERA5+OBS dataset\n",
    "    levels : list\n",
    "        Pressure levels to analyze\n",
    "    parameter : str\n",
    "        Variable to analyze\n",
    "    figsize : tuple\n",
    "        Figure size for plots\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results with statistics and plots\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Analyzing {parameter} impact across levels: {levels}\")\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {'statistics': {}, 'plots': None}\n",
    "    \n",
    "    # Set up single-row plot\n",
    "    n_levels = len(levels)\n",
    "    fig, axes = plt.subplots(1, n_levels, figsize=figsize,\n",
    "                            subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Handle single level case\n",
    "    if n_levels == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Process each level\n",
    "    for i, level in enumerate(levels):\n",
    "        \n",
    "        # Extract data for this level (first time step, first batch)\n",
    "        orig_data = ds_original[parameter].sel(level=level).isel(time=0, batch=0)\n",
    "        mod_data = ds_modified[parameter].sel(level=level).isel(time=0, batch=0)\n",
    "        \n",
    "        # Calculate impact (difference)\n",
    "        impact = mod_data - orig_data\n",
    "        \n",
    "        # Compute comprehensive statistics\n",
    "        stats = {\n",
    "            'mean_impact': float(impact.mean()),\n",
    "            'std_impact': float(impact.std()), \n",
    "            'rmse_impact': float(np.sqrt((impact**2).mean())),\n",
    "            'max_impact': float(impact.max()),\n",
    "            'min_impact': float(impact.min()),\n",
    "            'cells_modified': int((impact != 0).sum()),\n",
    "            'total_cells': int(impact.size)\n",
    "        }\n",
    "        \n",
    "        # Derived metrics\n",
    "        stats['modification_fraction'] = stats['cells_modified'] / stats['total_cells']\n",
    "        stats['impact_consistency'] = (abs(stats['mean_impact']) / stats['std_impact'] \n",
    "                                     if stats['std_impact'] != 0 else float('inf'))\n",
    "        \n",
    "        # Verify RMSE relationship\n",
    "        expected_rmse = np.sqrt(stats['mean_impact']**2 + stats['std_impact']**2)\n",
    "        stats['rmse_verification'] = abs(stats['rmse_impact'] - expected_rmse) < 1e-6\n",
    "        \n",
    "        # Classification\n",
    "        if abs(stats['mean_impact']) > 2 * stats['std_impact']:\n",
    "            stats['impact_type'] = 'Systematic bias correction'\n",
    "        elif stats['std_impact'] > 2 * abs(stats['mean_impact']):\n",
    "            stats['impact_type'] = 'Spatially variable corrections'\n",
    "        else:\n",
    "            stats['impact_type'] = 'Mixed systematic and variable'\n",
    "            \n",
    "        results['statistics'][level] = stats\n",
    "        \n",
    "        # Create plot for this level\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot impact with appropriate color scale\n",
    "        vmax = max(abs(stats['min_impact']), abs(stats['max_impact']))\n",
    "        vmin = -vmax\n",
    "        \n",
    "        im = impact.plot(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                        cmap='coolwarm', vmin=vmin, vmax=vmax,\n",
    "                        add_colorbar=False)\n",
    "        \n",
    "        # Add map features\n",
    "        ax.coastlines(resolution='50m', alpha=0.7, linewidth=0.5)\n",
    "        ax.gridlines(draw_labels=False, alpha=0.3)\n",
    "        \n",
    "        # Title with key statistics\n",
    "        ax.set_title(f'{level} hPa\\n'\n",
    "                    f'Mean: {stats[\"mean_impact\"]:.3f}K\\n'\n",
    "                    f'STD: {stats[\"std_impact\"]:.3f}K\\n',\n",
    "                    # f'RMSE: {stats[\"rmse_impact\"]:.3f}K',\n",
    "                    fontsize=10)\n",
    "        \n",
    "        # Remove axis labels for cleaner look\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    \n",
    "    # Add overall title and colorbar\n",
    "    param_title = parameter.replace('_', ' ').title()\n",
    "    fig.suptitle(f'{param_title} Observation Impact Analysis\\n'\n",
    "                f'ERA5+OBS - ERA5 Differences', fontsize=12, y=0.98)\n",
    "    \n",
    "    # Add single colorbar for all subplots\n",
    "    plt.tight_layout()\n",
    "    cbar = plt.colorbar(im, ax=axes, orientation='horizontal', \n",
    "                       pad=0.1, shrink=0.8, aspect=40)\n",
    "    cbar.set_label(f'{param_title} Change (K)', fontsize=10)\n",
    "    \n",
    "    results['plots'] = fig\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-LEVEL IMPACT ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Level':<8} {'Mean':<8} {'STD':<8} {'RMSE':<8} {'Modified':<8} {'Type':<25}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for level in levels:\n",
    "        stats = results['statistics'][level]\n",
    "        print(f\"{level:<8} {stats['mean_impact']:<8.3f} {stats['std_impact']:<8.3f} \"\n",
    "              f\"{stats['rmse_impact']:<8.3f} {stats['cells_modified']:<8} \"\n",
    "              f\"{stats['impact_type']:<25}\")\n",
    "    \n",
    "    print(\"\\nKey Interpretations:\")\n",
    "    print(\"- Mean: Systematic bias correction magnitude\")  \n",
    "    print(\"- STD:  Spatial variability of corrections\")\n",
    "    print(\"- RMSE: Total impact magnitude (√(Mean² + STD²))\")\n",
    "    print(\"- Modified: Number of grid cells with non-zero changes\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_rmse_vs_std_components(results, levels=[500, 850, 925]):\n",
    "    \"\"\"\n",
    "    Create focused comparison of RMSE decomposition\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Extract statistics\n",
    "    mean_values = [results['statistics'][level]['mean_impact'] for level in levels]\n",
    "    std_values = [results['statistics'][level]['std_impact'] for level in levels]\n",
    "    rmse_values = [results['statistics'][level]['rmse_impact'] for level in levels]\n",
    "    \n",
    "    # Plot 1: Components comparison\n",
    "    x = np.arange(len(levels))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax1.bar(x - width, np.abs(mean_values), width, label='|Mean| (Systematic)', alpha=0.8)\n",
    "    ax1.bar(x, std_values, width, label='STD (Variability)', alpha=0.8)\n",
    "    ax1.bar(x + width, rmse_values, width, label='RMSE (Total)', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Pressure Level (hPa)')\n",
    "    ax1.set_ylabel('Temperature Impact (K)')\n",
    "    ax1.set_title('RMSE Decomposition by Level')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(levels)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: RMSE verification\n",
    "    calculated_rmse = [np.sqrt(mean**2 + std**2) for mean, std in zip(mean_values, std_values)]\n",
    "    \n",
    "    ax2.scatter(rmse_values, calculated_rmse, s=100, alpha=0.7)\n",
    "    ax2.plot([0, max(rmse_values)], [0, max(rmse_values)], 'r--', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Actual RMSE')\n",
    "    ax2.set_ylabel('Calculated RMSE (√(Mean² + STD²))')\n",
    "    ax2.set_title('RMSE Verification')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annotate points\n",
    "    for i, level in enumerate(levels):\n",
    "        ax2.annotate(f'{level} hPa', (rmse_values[i], calculated_rmse[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage with your existing workflow data\n",
    "def run_optimized_analysis():\n",
    "    \"\"\"\n",
    "    Run optimized analysis using your existing datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using your existing data structures\n",
    "    levels_to_analyze = [500, 850, 925]\n",
    "    \n",
    "    for level in levels_to_analyze:\n",
    "        key_index = f\"t_{level}\"\n",
    "        \n",
    "        if f\"{key_index}_ds\" in ds_gis and f\"{key_index}_ds\" in ds_gi_mods:\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"ANALYZING LEVEL {level} hPa\")\n",
    "            print('='*60)\n",
    "            \n",
    "            # Run single-level analysis\n",
    "            results = analyze_multi_level_impact_optimized(\n",
    "                ds_original=ds_gis[f\"{key_index}_ds\"],\n",
    "                ds_modified=ds_gi_mods[f\"{key_index}_ds\"], \n",
    "                levels=[level],\n",
    "                parameter='temperature',\n",
    "                figsize=(6, 4)\n",
    "            )\n",
    "    \n",
    "    # Run multi-level comparison if you have aggregated dataset\n",
    "    if 'aggregated_ds' in globals():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"MULTI-LEVEL AGGREGATED ANALYSIS\")\n",
    "        print('='*60)\n",
    "        \n",
    "        multi_results = analyze_multi_level_impact_optimized(\n",
    "            ds_original=ds_gis[f\"t_{levels_to_analyze[0]}_ds\"],  # Use any as template\n",
    "            ds_modified=aggregated_ds,\n",
    "            levels=levels_to_analyze,\n",
    "            parameter='temperature',\n",
    "            figsize=(15, 4)\n",
    "        )\n",
    "        \n",
    "        # Show RMSE decomposition\n",
    "        compare_rmse_vs_std_components(multi_results, levels_to_analyze)\n",
    "        \n",
    "        return multi_results\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Execute the optimized analysis\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_optimized_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecf5cb-3226-4179-a182-42f0d50c6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_prediction_comparison_optimized(gi_pred_path, gi_obs_pred_path, \n",
    "                                       level_of_interest, level_index, \n",
    "                                       variable_name='temperature',\n",
    "                                       figsize=(18, 5)):\n",
    "    \"\"\"\n",
    "    Optimized function to plot Original, Modified, and Difference predictions in one row.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gi_pred_path : str\n",
    "        Path to original GraphCast prediction\n",
    "    gi_obs_pred_path : str\n",
    "        Path to observation-modified GraphCast prediction\n",
    "    level_of_interest : int\n",
    "        Pressure level of interest (hPa)\n",
    "    level_index : int\n",
    "        Index of the pressure level in dataset\n",
    "    variable_name : str\n",
    "        Variable to plot (default: 'temperature')\n",
    "    figsize : tuple\n",
    "        Figure size (width, height)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains datasets and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading and comparing predictions at {level_of_interest} hPa...\")\n",
    "    \n",
    "    # Load datasets\n",
    "    try:\n",
    "        ds_original = xr.open_dataset(gi_pred_path)\n",
    "        ds_modified = xr.open_dataset(gi_obs_pred_path)\n",
    "        print(\"✓ Datasets loaded successfully\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"✗ Error loading files: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract temperature data at specified level\n",
    "    if 'level' in ds_original[variable_name].dims:\n",
    "        temp_original = ds_original[variable_name].isel(level=level_index, time=0, batch=0)\n",
    "        temp_modified = ds_modified[variable_name].isel(level=level_index, time=0, batch=0)\n",
    "    else:\n",
    "        temp_original = ds_original[variable_name].isel(time=0, batch=0)\n",
    "        temp_modified = ds_modified[variable_name].isel(time=0, batch=0)\n",
    "    \n",
    "    # Calculate difference\n",
    "    temp_difference = temp_original - temp_modified\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'mean_diff': float(temp_difference.mean()),\n",
    "        'std_diff': float(temp_difference.std()),\n",
    "        'rmse_diff': float(np.sqrt((temp_difference**2).mean())),\n",
    "        'max_diff': float(temp_difference.max()),\n",
    "        'min_diff': float(temp_difference.min()),\n",
    "        'original_mean': float(temp_original.mean()),\n",
    "        'modified_mean': float(temp_modified.mean())\n",
    "    }\n",
    "    \n",
    "    print(f\"Statistics: Mean diff = {stats['mean_diff']:.4f}K, \"\n",
    "          f\"STD diff = {stats['std_diff']:.4f}K\")\n",
    "          # f\"STD diff = {stats['std_diff']:.4f}K, \"\n",
    "          # f\"RMSE diff = {stats['rmse_diff']:.4f}K\")\n",
    "    \n",
    "    # Create single-row subplot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize,\n",
    "                            subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    # Common plot settings\n",
    "    plot_configs = [\n",
    "        {\n",
    "            'data': temp_original,\n",
    "            'title': f'Original GraphCast\\n{level_of_interest} hPa\\nMean: {stats[\"original_mean\"]:.2f}K',\n",
    "            'cmap': 'RdYlBu_r',\n",
    "            'vmin': None, 'vmax': None\n",
    "        },\n",
    "        {\n",
    "            'data': temp_modified, \n",
    "            'title': f'Modified GraphCast\\n{level_of_interest} hPa\\nMean: {stats[\"modified_mean\"]:.2f}K',\n",
    "            'cmap': 'RdYlBu_r',\n",
    "            'vmin': None, 'vmax': None\n",
    "        },\n",
    "        {\n",
    "            'data': temp_difference,\n",
    "            'title': f'Difference (Orig - Mod)\\n{level_of_interest} hPa\\nMean: {stats[\"mean_diff\"]:.4f}K',\n",
    "            'cmap': 'coolwarm',\n",
    "            'vmin': -0.05, 'vmax': 0.05\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Create plots\n",
    "    images = []\n",
    "    for i, (ax, config) in enumerate(zip(axes, plot_configs)):\n",
    "        \n",
    "        # Plot data\n",
    "        im = config['data'].plot(\n",
    "            ax=ax, \n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=config['cmap'],\n",
    "            vmin=config['vmin'],\n",
    "            vmax=config['vmax'],\n",
    "            add_colorbar=False\n",
    "        )\n",
    "        images.append(im)\n",
    "        \n",
    "        # Add map features\n",
    "        ax.coastlines(resolution='50m', alpha=0.7, linewidth=0.5)\n",
    "        ax.gridlines(draw_labels=(i==0), alpha=0.3, x_inline=False, y_inline=False)\n",
    "        ax.set_global()\n",
    "        \n",
    "        # Set title\n",
    "        ax.set_title(config['title'], fontsize=11, pad=10)\n",
    "        \n",
    "        # Remove axis labels for cleaner look\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    \n",
    "    # Add overall title\n",
    "    fig.suptitle(f'GraphCast Prediction Comparison - {variable_name.title()}\\n'\n",
    "                f'Level: {level_of_interest} hPa | '\n",
    "                f'Difference Stats: Mean={stats[\"mean_diff\"]:.3f}K, STD={stats[\"std_diff\"]:.3f}K',\n",
    "                # f'Difference Stats: Mean={stats[\"mean_diff\"]:.3f}K, STD={stats[\"std_diff\"]:.3f}K, RMSE={stats[\"rmse_diff\"]:.3f}K',\n",
    "                fontsize=12, y=0.95)\n",
    "    \n",
    "    # Add individual colorbars\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Colorbar for temperature plots (first two)\n",
    "    temp_cbar = plt.colorbar(images[0], ax=axes[:2], orientation='horizontal', \n",
    "                            pad=0.05, shrink=0.8, aspect=30)\n",
    "    temp_cbar.set_label(f'{variable_name.title()} (K)', fontsize=10)\n",
    "    \n",
    "    # Colorbar for difference plot\n",
    "    diff_cbar = plt.colorbar(images[2], ax=axes[2], orientation='horizontal',\n",
    "                            pad=0.05, shrink=0.8, aspect=15)\n",
    "    diff_cbar.set_label('Temperature Difference (K)', fontsize=10)\n",
    "    \n",
    "    # Add file paths as footnote\n",
    "    plt.figtext(0.02, 0.02, \n",
    "                f'Original: {Path(gi_pred_path).name}\\n'\n",
    "                f'Modified: {Path(gi_obs_pred_path).name}',\n",
    "                fontsize=8, color='gray', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Cleanup\n",
    "    ds_original.close()\n",
    "    ds_modified.close()\n",
    "    \n",
    "    return {\n",
    "        'statistics': stats,\n",
    "        'figure': fig,\n",
    "        'temp_original': temp_original,\n",
    "        'temp_modified': temp_modified,\n",
    "        'temp_difference': temp_difference\n",
    "    }\n",
    "\n",
    "def plot_multi_level_predictions(prediction_files, level_configs, \n",
    "                                variable_name='temperature', figsize=(20, 12)):\n",
    "    \"\"\"\n",
    "    Plot prediction comparisons for multiple levels in a grid layout.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prediction_files : dict\n",
    "        Dictionary with 'original' and levels as keys, file paths as values\n",
    "    level_configs : list\n",
    "        List of tuples: [(level_hPa, level_index), ...]\n",
    "    variable_name : str\n",
    "        Variable to plot\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    \n",
    "    n_levels = len(level_configs)\n",
    "    fig, axes = plt.subplots(n_levels, 3, figsize=figsize,\n",
    "                            subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    \n",
    "    if n_levels == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, (level_hPa, level_idx) in enumerate(level_configs):\n",
    "        \n",
    "        if level_hPa not in prediction_files:\n",
    "            continue\n",
    "            \n",
    "        # Load data\n",
    "        ds_orig = xr.open_dataset(prediction_files['original'])\n",
    "        ds_mod = xr.open_dataset(prediction_files[level_hPa])\n",
    "        \n",
    "        # Extract and plot\n",
    "        temp_orig = ds_orig[variable_name].isel(level=level_idx, time=0, batch=0)\n",
    "        temp_mod = ds_mod[variable_name].isel(level=level_idx, time=0, batch=0) \n",
    "        temp_diff = temp_orig - temp_mod\n",
    "        \n",
    "        plot_data = [temp_orig, temp_mod, temp_diff]\n",
    "        titles = [f'Original\\n{level_hPa} hPa', \n",
    "                 f'Modified\\n{level_hPa} hPa', \n",
    "                 f'Difference\\n{level_hPa} hPa']\n",
    "        cmaps = ['RdYlBu_r', 'RdYlBu_r', 'coolwarm']\n",
    "        vlims = [(None, None), (None, None), (-0.05, 0.05)]\n",
    "        \n",
    "        for col, (data, title, cmap, vlim) in enumerate(zip(plot_data, titles, cmaps, vlims)):\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            im = data.plot(ax=ax, transform=ccrs.PlateCarree(),\n",
    "                          cmap=cmap, vmin=vlim[0], vmax=vlim[1],\n",
    "                          add_colorbar=False)\n",
    "            \n",
    "            ax.coastlines(resolution='50m', alpha=0.7, linewidth=0.5)\n",
    "            ax.gridlines(alpha=0.3)\n",
    "            ax.set_global()\n",
    "            ax.set_title(title, fontsize=10)\n",
    "        \n",
    "        ds_orig.close()\n",
    "        ds_mod.close()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Multi-Level GraphCast Prediction Analysis', y=0.98, fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Usage with your existing workflow\n",
    "def run_optimized_prediction_plots():\n",
    "    \"\"\"\n",
    "    Run optimized prediction plotting using your existing variables\n",
    "    \"\"\"\n",
    "# ds_obs = {} # dataset catalog for obs [OBS] files\n",
    "# ds_gis = {} # dataset catalog for original GraphCast input (GI)\n",
    "# ds_gi_mods = {} # dataset catalog for modified GraphCast input (GI)\n",
    "    \n",
    "    for entry in current_dd:\n",
    "        short_name   = entry[index_short_name]\n",
    "        long_name    = entry[index_long_name]\n",
    "        gi_pred_path = entry[index_GI_PRED_file] \n",
    "        gi_obs_pred_path    = entry[index_GI_OBS_PRED_file] \n",
    "        level_of_interest   = entry[index_level_of_interest]\n",
    "        level_index  = entry[index_GI_level]\n",
    "\n",
    "        # Single level comparison\n",
    "        results = plot_prediction_comparison_optimized(\n",
    "            gi_pred_path=gi_pred_path,\n",
    "            gi_obs_pred_path=gi_obs_pred_path,\n",
    "            level_of_interest=level_of_interest,\n",
    "            level_index=level_index,\n",
    "            variable_name='temperature',\n",
    "            figsize=(18, 5)\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "    \n",
    "# Usage with your existing workflow\n",
    "def _run_optimized_prediction_plots():\n",
    "    \"\"\"\n",
    "    Run optimized prediction plotting using your existing variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Single level comparison\n",
    "    results = plot_prediction_comparison_optimized(\n",
    "        gi_pred_path=gi_pred_path,\n",
    "        gi_obs_pred_path=gi_obs_pred_path,\n",
    "        level_of_interest=level_of_interest,\n",
    "        level_index=level_index,\n",
    "        variable_name='temperature',\n",
    "        figsize=(18, 5)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# # Execute the optimized plotting\n",
    "# if __name__ == \"__main__\":\n",
    "#     results = run_optimized_prediction_plots()\n",
    "    \n",
    "#     if results:\n",
    "#         print(\"\\n\" + \"=\"*50)\n",
    "#         print(\"PREDICTION COMPARISON COMPLETE\")\n",
    "#         print(\"=\"*50)\n",
    "#         print(\"Key Statistics:\")\n",
    "#         for key, value in results['statistics'].items():\n",
    "#             print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425d675-eb31-47a0-b8b9-1b4367a6ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    results = run_optimized_prediction_plots()\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREDICTION COMPARISON COMPLETE\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Key Statistics:\")\n",
    "        for key, value in results['statistics'].items():\n",
    "            print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbbbe5-3bde-40c1-9229-65c32d944256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b08e93-da3b-43d0-a619-3ab316c5aa12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:viz]",
   "language": "python",
   "name": "conda-env-viz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
